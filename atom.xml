<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Ricky Ting&#39;s Blog</title>
  <icon>https://www.gravatar.com/avatar/4492b8f6628f8336b7f13bd4cb84b846</icon>
  <subtitle>当时只道是寻常</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://ricky-ting.github.io/"/>
  <updated>2020-01-04T07:17:13.514Z</updated>
  <id>https://ricky-ting.github.io/</id>
  
  <author>
    <name>Ricky-Ting</name>
    <email>Ricky.Ting@outlook.com Ricky.B.Ting@gmail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Digital Image Processing Review</title>
    <link href="https://ricky-ting.github.io/2020/01/04/Digital-Image-Processing-Review/"/>
    <id>https://ricky-ting.github.io/2020/01/04/Digital-Image-Processing-Review/</id>
    <published>2020-01-04T07:16:00.000Z</published>
    <updated>2020-01-04T07:17:13.514Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数字图像处理"><a href="#数字图像处理" class="headerlink" title="数字图像处理"></a>数字图像处理</h1><h2 id="课程概述"><a href="#课程概述" class="headerlink" title="课程概述"></a>课程概述</h2><h3 id="参考教材"><a href="#参考教材" class="headerlink" title="参考教材"></a>参考教材</h3><ul><li>数字图像处理(冈萨雷斯)</li></ul><h3 id="考核"><a href="#考核" class="headerlink" title="考核"></a>考核</h3><ol><li><p>三个作业(15+15+10=40%)</p></li><li><p>期末考试(60%)</p></li></ol><p>课程主页：<a href="http://lamda.nju.edu.cn/chenyuhui/dip19/dip19.html" target="_blank" rel="noopener">http://lamda.nju.edu.cn/chenyuhui/dip19/dip19.html</a></p><h2 id="CH1-数字图像处理概述"><a href="#CH1-数字图像处理概述" class="headerlink" title="CH1 数字图像处理概述"></a>CH1 数字图像处理概述</h2><p>采样：用有限的样本数目去近似无限的现实物理信号；或简而言之，有限近似无限</p><p>量化：用离散计算机表示去近似连续的现实物理信号；或简而言之，离散近似连续</p><p>把物理世界表示到计算机中来是数字图像获取的关键</p><p>有大量细节的图像，需要的量化级数较少</p><p><strong>最佳量化:</strong>使量化误差最小的量化方法, 使用公式推导</p><h2 id="CH2-空间域图像处理"><a href="#CH2-空间域图像处理" class="headerlink" title="CH2 空间域图像处理"></a>CH2 空间域图像处理</h2><h3 id="图像内插"><a href="#图像内插" class="headerlink" title="图像内插"></a>图像内插</h3><ul><li><p>最近邻内插法</p></li><li><p>双线性内插法</p><ul><li><p>用4个最近邻去估计给定位置的灰度</p></li><li><p>$v(x,y) = ax + by + cxy + d$</p></li><li><p>求解由4个等式组成的方程组</p></li></ul></li><li><p>双三次内插法</p><ul><li><p>用16个最近邻去估计给定位置的灰度</p></li><li><p>$v(x,y) = \sum<em>{i=0}^3 \sum</em>{j=0}^3 a_{ij}x^i y^j$</p></li><li><p>求解由16个等式组成的方程组</p></li></ul></li></ul><h3 id="像素间的基本关系"><a href="#像素间的基本关系" class="headerlink" title="像素间的基本关系"></a>像素间的基本关系</h3><ul><li><p>相邻像素</p><ul><li><p>4邻域：上下左右， $N_4(p) = {(x-1,y), (x+1,y), (x,y-1), (x, y+1)}$</p></li><li><p>4对角邻域, $N_D(p) = {(x-1,y-1), (x-1,y+1), (x+1, y-1), (x+1,y+1)}$</p></li><li><p>8邻域: $N_D(p) + N_4(p)$ </p></li></ul></li><li><p>邻接性、连通性、区域和边界</p><ul><li><p>邻接性</p><ul><li><p>4邻接： 如果$q$ 在$N_4(p)$ 集合中，且$q$ 的灰度与$p$ 的灰度都在集合$V$中，则$q$ 和$p$ 是4邻接的</p></li><li><p>8邻接：如果$q$ 在$N_D(p)$ 集合中，且$q$ 的灰度与$p$ 的灰度都在集合$V$中，则$q$ 和$p$ 是8邻接的</p></li><li><p>$m$邻接（混合邻接）：$q$ 的灰度与$p$的灰度都在集合$V$中, 且 ( $q$在$N_4(p)$中，或者 $q$在$N_D(p)$中，且$N_4(p) \wedge N_4(q)$的灰度都不在集合$V$中)，则$q$和$p$是$m$邻接的</p></li></ul></li><li><p>连通性</p><ul><li>从$(x,y)$ 到 $(s,t)$ 的路称为通路， 如果$(x,y)=(s,t)$,则此通路称为闭合通路</li></ul></li><li><p>连通集</p><ul><li><p>对于$S$中任何像素$p$, $S$中连通到该像素的像素集叫做$S$的连通分量</p></li><li><p>如果$S$仅有一个连通分量，则集合$S$叫做连通集 </p></li></ul></li><li><p>区域</p><ul><li><p>令$R$是图像中的像素子集。如果$R$ 是连通集，则称$R$为一个区域</p></li><li><p>如果两个区域的联合形成一个连通集，那它们是邻接区域。</p></li><li><p>假设图像包括$K$个不连接的区域，即$R_1,…,R_k$,且不接触边界。</p><ul><li><p>$K$个区域的并集$R_u$, 称为前景</p></li><li><p>它们的补集$(R_u)^c$,称为背景</p></li></ul></li></ul></li><li><p>边界</p><ul><li><p>一个区域$R$的边界(也称为边缘或轮廓线)是区域中像素的集合</p><ul><li><p>这些点与$R$补集中的点邻近</p></li><li><p>这些点至少有一个背景邻点</p></li></ul></li><li><p>用8联通来定义</p></li><li><p>边界:一个有限区域的边界(通常)形成一 条闭合通路，是个“整体”概念</p></li><li><p>边缘:具有某些导数值(超过预先设定的阈 值)的像素形成，是个“局部”概念;</p></li><li><p>边界只考察其邻点是否属于集合V，属于二 值判断。边缘考察灰度级的差别，粒度更细 。边缘可能不闭合。</p></li><li><p>什么时候边缘=边界?二值图像</p></li></ul></li></ul></li><li><p>距离度量</p><ul><li><p>满足以下条件：</p><ul><li><p>$D(p,q) \ge 0$,  且$D[p,q] =0  \Leftrightarrow  p=q $ </p></li><li><p>$D(p,q) = D(q,p)$</p></li><li><p>$D(p,z) \leq D(p,q) + D(q,z)$</p></li></ul></li><li><p>常用距离</p><ul><li><p>欧氏距离</p></li><li><p>$D_4$ 距离(曼哈顿距离)</p></li><li><p>$D_8$ 距离(棋盘距离)：$D_8(p,q) = \max(|x-s|, |y-t|) $ </p></li></ul></li></ul></li></ul><h3 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h3><p>图像增强是领域特殊的。</p><p>两大类方法：</p><ul><li><p>空间域方法：图像平面本身，对图像的像素直接处理。 </p><ul><li>直观、离散。</li></ul></li><li><p>变换域方法：空间域 $\rightarrow$  变换域 $\rightarrow$ 处理 $\rightarrow$  空间域</p><ul><li>频域(傅里叶变换)， 连续。</li></ul></li></ul><p>空间域方法是直接对像素操作的过程</p><p>$g(x,y)= T(f(x,y))$, $T$ 为操作算子，定义在$(x,y)$ 的邻域。</p><p>边界怎么办？ 忽略外部、填充</p><p>两种类型</p><ul><li><p>空间滤波</p><ul><li>空间滤波器：邻域、预定义的操作</li></ul></li><li><p>灰度变换</p><ul><li><p>邻域大小为1的空间滤波</p></li><li><p>灰度变换函数： $s= T(r)$</p></li><li><p>函数可以存储在1维数组中，通过查表实现 映射</p></li></ul></li></ul><h3 id="基本灰度变换"><a href="#基本灰度变换" class="headerlink" title="基本灰度变换"></a>基本灰度变换</h3><p>三类基本函数：线性函数、对数函数、幂律函数</p><p>值越低，颜色越深</p><h4 id="图像反转"><a href="#图像反转" class="headerlink" title="图像反转"></a>图像反转</h4><p>$S = L - 1-r, L= 2^b$</p><p>增强嵌入在暗区域中的白色或灰色细节</p><h4 id="对数变换"><a href="#对数变换" class="headerlink" title="对数变换"></a>对数变换</h4><p>$s = c \log (1+r)$</p><ul><li><p>为什么$1+r$, 因为 $(0,0)$</p></li><li><p>低灰度值拉伸</p></li><li><p>高灰度值压缩</p></li></ul><h4 id="幂律变换"><a href="#幂律变换" class="headerlink" title="幂律变换"></a>幂律变换</h4><p>$s = c r^{\gamma}$</p><ul><li><p>低灰度值拉伸  难道不是看$\gamma$ 大于1还是小于1吗？</p></li><li><p>高灰度值压缩</p></li><li><p>可以调整$\gamma$</p></li><li><p>伽马变换</p></li><li><p>$\gamma$ 越小，对比度越低，细节越多</p></li></ul><h4 id="分段线性函数"><a href="#分段线性函数" class="headerlink" title="分段线性函数"></a>分段线性函数</h4><p>可以只拉伸某些灰度级上的对比度</p><ul><li><p>对比拉伸变换</p><ul><li>单调递增</li></ul></li><li><p>线性函数</p><ul><li>$r_1 = s_1, r_2 = s_2$ </li></ul></li><li><p>阈值处理函数</p><ul><li>$r_1 = r_2,s_1 =0, s_2 = L-1$</li></ul></li><li><p>灰度级分层</p><ul><li>突出特定灰度范围的亮度</li></ul></li><li>比特平面分层<ul><li>突出特定比特的作用<ul><li>8比特图像可认为由8个1比特平面组成</li></ul></li><li>高阶比特平面包含视觉上重要的数据</li><li>低阶比特平面贡献了更精细的灰度细节</li></ul></li></ul><h3 id="灰度直方图"><a href="#灰度直方图" class="headerlink" title="灰度直方图"></a>灰度直方图</h3><ul><li><p>图像中每种灰度级的像素个数</p></li><li><p>灰度直方图的横坐标是灰度级，纵坐标表示该灰度级出现的频率。</p></li></ul><p>阈值面积函数A(D)</p><ul><li><p>连续图像中具有灰度级$\ge D$ 的轮廓线所 包围的面积</p></li><li><p>$A(D) = \int_D^{\infty} H(p) dp $</p></li></ul><p>概率密度函数(PDF)</p><ul><li><p>归一化到单位面积的直方图</p></li><li><p>$PDF = P(D) = \frac{1}{A_0} H(D)$ </p></li></ul><p>累积分布函数(CDF)</p><ul><li>归一化后灰度级$\le D$的轮廓线所包围的面积</li></ul><p>定义</p><ul><li><p>严格定义: $H(D) = - \frac{d}{dD}A(D)$ </p></li><li><p>数字图像时，简化为$H(D) = A(D) - A(D+1)$ </p></li></ul><p>应用</p><ul><li><p>图像快速检测</p><ul><li>可以利用灰度直方图来判断一幅图像是否合理的利用了全部被允许的灰度级范围，从而及早发现数字化中出现的问题</li></ul></li><li><p>分割前景背景</p><ul><li>以直方图两峰之间的谷地T为阈值来确 定边界，可把图像分为前景背景两部分</li></ul></li><li><p>面积计算</p></li></ul><h3 id="直方图处理"><a href="#直方图处理" class="headerlink" title="直方图处理"></a>直方图处理</h3><ul><li><p>直方图均衡化</p></li><li><p>直方图匹配</p></li><li><p>局部直方图均衡化</p></li><li><p>直方图统计量用于局部图像增强</p></li></ul><h4 id="直方图均衡化"><a href="#直方图均衡化" class="headerlink" title="直方图均衡化"></a>直方图均衡化</h4><p>直方图呈均匀分布时，对比度会有明显增强。通过灰度变换函数，将原图像直方图的分布均衡化，这一过程称为直方图均衡化。</p><ul><li><p>输入图像灰度值概率密度$p_r(r)$</p></li><li><p>变换函数$s= T(r)$</p></li><li><p>输出图像灰度值概率密度$p_s(s)$</p></li></ul><p>$p_s(s) = p_r(r) |\frac{dr}{ds}| = p_r(r) |(\frac{ds}{dr})^{-1}| = p_r(T^{-1}(s))\frac{1}{T’(T^{-1}(s))}$</p><p>变换函数 </p><ul><li><p>连续：</p><ul><li>$s = T(r) = (L-1)\int_0^r p_r(w) dw$</li></ul></li><li><p>离散： </p><ul><li><p>$p_r(r_k) = \frac{n_k}{MN}$ , $k=0,1,2,…,L-1$ </p></li><li><p>$s_k  = T(r<em>k) = (L-1) \sum</em>{j=0}^k p_r(r_j)$</p></li></ul></li></ul><h4 id="直方图匹配-规定化"><a href="#直方图匹配-规定化" class="headerlink" title="直方图匹配(规定化)"></a>直方图匹配(规定化)</h4><ul><li><p>均匀直方图的基本增强有时并不是最终目标。 我们通常希望可以处理后的图像具有某种指定 的直方图形状。</p></li><li><p>这种用于产生处理后有特殊直方图的图像的方法，叫做直方图匹配或直方图规定化处理。</p></li><li><p>输出直方图分布不要求均匀，要求为某个特定分布</p></li></ul><p>核心思想：以平衡化直方图图像为桥梁</p><p>先把A转化成均衡化图像B， 再把B转化成图像C。</p><h4 id="局部直方图处理"><a href="#局部直方图处理" class="headerlink" title="局部直方图处理"></a>局部直方图处理</h4><ul><li><p>中小区域的细节容易被忽略</p></li><li><p>如果不希望对整体图像增强，只希望对局部进行增强怎么办?</p></li><li><p>以图像中每个像素的邻域中灰度分布 为基础设计变换函数</p></li></ul><p>步骤：</p><ul><li><p>定义一个领域，并不断平移中心位置</p><ol><li><p>在每一个位置，计算该邻域中点的直方图</p><ul><li>许多元素为0</li></ul></li><li><p>利用直方图均衡化或直方图匹配得到变换函数</p></li><li><p>将变换函数作用到邻域中心像素</p></li></ol></li><li><p>移动重复上述过程</p></li></ul><h4 id="在图像增强中使用直方图统计"><a href="#在图像增强中使用直方图统计" class="headerlink" title="在图像增强中使用直方图统计"></a>在图像增强中使用直方图统计</h4><p>灰度平均值： $m = \sum_{i=0}^{L-1} r_i p(r_i)$</p><p>n阶距: $\mu<em>n(r) = \sum</em>{i=0}^{L-1} (r_i -m)^np(r_i)$ </p><p>采样均值: $m = \frac{1}{MN} \sum<em>{x=0}^{M-1} \sum</em>{y=0}^{N-1}f(x,y)$</p><p>采样方差: $\sigma^2 = \frac{1}{MN} \sum<em>{x=0}^{M-1} \sum</em>{y=0}^{N-1}[f(x,y)- m]^2$</p><ul><li><p>均值和方差常用于局部增强</p></li><li><p>局部均值和局部方差</p><ul><li><p>$m<em>{S</em>{xy}} = \sum_{i=0}^{L-1} r<em>i p</em>{S_{xy}}(r_i)$</p></li><li><p>$\sigma^2<em>{S</em>{xy}} = \sum_{i=0}^{L-1} (r<em>i - m</em>{S<em>{xy}})^2p</em>{S_{xy}}(r_i)$ </p></li><li><p>$S_{xy}$ 表示像素$(x,y)$的近邻集合</p></li><li><p>许多灰度值频率为0</p></li></ul></li></ul><h3 id="空间滤波"><a href="#空间滤波" class="headerlink" title="空间滤波"></a>空间滤波</h3><ul><li><p>空间滤波基础</p><ul><li><p>空间滤波机理</p></li><li><p>空间相关与卷积</p></li></ul></li><li><p>平滑空间滤波器</p><ul><li><p>平滑线性滤波器</p></li><li><p>统计排序滤波器</p></li></ul></li><li><p>锐化空间滤波器</p><ul><li><p>拉普拉斯算子</p></li><li><p>梯度</p></li></ul></li><li><p>混合空间增强法</p></li></ul><h4 id="空间滤波机理"><a href="#空间滤波机理" class="headerlink" title="空间滤波机理"></a>空间滤波机理</h4><ul><li><p>空间滤波器</p><ul><li><p>邻域(矩形)</p></li><li><p>预定义的操作</p></li></ul></li><li><p>$m \times n$ 的模板</p><ul><li><p>$m=2a+1, n= 2b+1$</p></li><li><p>最小为$3 \times 3$</p></li></ul></li><li><p>滤波操作</p><ul><li><p>$g(x,y) = \sum<em>{s=-a}^a \sum</em>{t=-b}^b w(s,t)f(x+s,y+t)$</p></li><li><p>$x$和$y$ 是可变的</p></li></ul></li><li><p>线性空间滤波 $\leftrightarrow$ 频率域滤波</p></li></ul><h4 id="空间相关与卷积"><a href="#空间相关与卷积" class="headerlink" title="空间相关与卷积"></a>空间相关与卷积</h4><ul><li><p>相关(Correlation)</p><ul><li>平移滤波器模板，计算每个位置乘积之和</li></ul></li><li><p>卷积(Convolution)</p><ul><li>与相关相似，但滤波器要旋转180度</li></ul></li><li><p>实际中未必严格区分</p></li><li><p>$m \times n$的滤波器与图像做相关操作</p><ul><li>$w(x,y) \star f(x,y) = \sum<em>{s=-a}^a \sum</em>{t=-b}^b w(s,t)f(x+s,y+t)$</li></ul></li><li><p>$m \times n$的滤波器与图像做卷积操作</p><ul><li>$w(x,y) \bigstar f(x,y) = \sum<em>{s=-a}^a \sum</em>{t=-b}^b w(s,t)f(x-s,y-t)$</li></ul></li></ul><h4 id="线性滤波的向量表示"><a href="#线性滤波的向量表示" class="headerlink" title="线性滤波的向量表示"></a>线性滤波的向量表示</h4><ul><li><p>把滤波器和灰度值拉成向量</p><ul><li><p>$R = w_1z_1 + w_2z<em>2 + … + w</em>{mn}z<em>{mn} = \sum</em>{k=1}^{mn}w_kz_k = \bf{w}^T\bf{z} $ </p></li><li><p>$\bf{w}$ 是$m \times n$ 的滤波器系数</p></li><li><p>$\bf{z}$是相应图像的灰度值</p></li></ul></li></ul><h4 id="空间滤波器模板"><a href="#空间滤波器模板" class="headerlink" title="空间滤波器模板"></a>空间滤波器模板</h4><ul><li><p>计算平均灰度</p><ul><li>$R = \frac{1}{9} \sum_{i=1}^9 z_i$</li></ul></li><li><p>两变量的连续函数(高斯)</p><ul><li><p>$h(x,y) = e^{-\frac{x^2+y^2}{2 \sigma^2}}$ </p></li><li><p>$w_1 = h(-1,-1), w_2 = h(-1,0), .., w_9 =h(1,1)$</p></li></ul></li><li><p>非线性滤波器</p><ul><li>更加强大</li></ul></li></ul><h4 id="平滑线性滤波器"><a href="#平滑线性滤波器" class="headerlink" title="平滑线性滤波器"></a>平滑线性滤波器</h4><ul><li><p>均值滤波器</p><ul><li><p>优点：降低噪声</p></li><li><p>缺点：边缘模糊</p></li><li><p>$R=\frac{1}{9} \sum_{i=1}^9 z_i$ </p></li><li><p>先求和，再归一化</p></li></ul></li><li><p>加权线性滤波器</p><ul><li><p>非均匀权重</p></li><li><p>降低模糊</p></li></ul></li></ul><h4 id="统计排序滤波器"><a href="#统计排序滤波器" class="headerlink" title="统计排序滤波器"></a>统计排序滤波器</h4><ul><li><p>非线性滤波器</p><ul><li><p>对滤波器覆盖的像素排序</p></li><li><p>用排序决定的值替代中心像素</p></li></ul></li><li><p>中值滤波器</p><ul><li>10、15、20、20、20、20、20、25、100</li></ul></li><li><p>最大值滤波器</p><ul><li>max</li></ul></li><li><p>最小值滤波器</p><ul><li>min</li></ul></li></ul><h4 id="锐化空间滤波器"><a href="#锐化空间滤波器" class="headerlink" title="锐化空间滤波器"></a>锐化空间滤波器</h4><ul><li><p>目的</p><ul><li>突出灰度的过渡部分</li></ul></li><li><p>应用广泛</p><ul><li>电子印刷、医学成像、工业检测、制导</li></ul></li></ul><h4 id="数学基础"><a href="#数学基础" class="headerlink" title="数学基础"></a>数学基础</h4><ul><li><p>一阶微分的性质</p><ul><li><p>在恒定灰度区域为零</p></li><li><p>在突变（斜坡、台阶）的起点非零</p></li><li><p>沿着斜坡非零</p></li></ul></li><li><p>二阶微分的性质</p><ul><li><p>在恒定灰度区域为零</p></li><li><p>在突变（斜坡、台阶）的起点和终点非零</p></li><li><p>沿着恒定斜率斜坡为零</p></li></ul></li><li><p>一维函数$f(x)$</p><ul><li><p>一阶微分</p><ul><li>$\frac{\partial f}{\partial x} = f(x+1) - f(x)$</li></ul></li><li><p>二阶微分</p><ul><li>$\frac{\partial^2 f}{\partial x^2} = f(x+1) + f(x-1)-2f(x)$</li></ul></li></ul></li></ul><h4 id="直观的结论"><a href="#直观的结论" class="headerlink" title="直观的结论"></a>直观的结论</h4><ul><li><p>数字图像的边缘类似于斜坡</p></li><li><p>一阶微分产生较粗的边缘</p><ul><li>沿斜坡的微分一直非零</li></ul></li><li><p>二阶微分产生两个有间距的双边缘</p><ul><li>由零分开、单像素宽</li></ul></li><li><p>二阶微分在增强细节方面比一阶微分好！</p></li></ul><h4 id="使用二阶微分对图像锐化"><a href="#使用二阶微分对图像锐化" class="headerlink" title="使用二阶微分对图像锐化"></a>使用二阶微分对图像锐化</h4><ul><li><p>各向同性滤波器</p><ul><li>旋转图像 $\rightarrow$ 滤波 = 滤波 $\rightarrow $ 旋转结果</li></ul></li><li><p>拉普拉斯算子</p><ul><li><p>$\nabla^2 f = \frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2}$</p></li><li><p>线性算子</p></li></ul></li><li><p>离散拉普拉斯算子</p><ul><li><p>$\frac{\partial^2 f}{\partial x^2} = f(x+1,y) + f(x-1,y) - 2f(x,y)$</p></li><li><p>$\frac{\partial^2 f}{\partial y^2} = f(x,y+1) + f(x,y-1) -2 f(x,y)$</p></li><li><p>标准形式, 中心为-4， 四联通邻域为-1</p></li><li><p>对角线形式，中心为-8， 八连通邻域为-1</p></li></ul></li><li><p>拉普拉斯算子结果叠加到图像中</p><ul><li><p>$g(x,y) = f(x,y) + c[\nabla^2 f(x,y)]$</p></li><li><p>采用负的中心系数，$c=-1$</p></li><li><p>采用正的中心系数，$c=1$</p></li></ul></li></ul><h4 id="非锐化掩蔽"><a href="#非锐化掩蔽" class="headerlink" title="非锐化掩蔽"></a>非锐化掩蔽</h4><ul><li><p>从原图像减去一幅非锐化版本</p><ol><li><p>模糊原图像</p></li><li><p>从原图像减去模糊图像，得到模板</p></li><li><p>将模板加到原图像</p></li></ol></li><li><p>具体公式</p><ul><li><p>$g_{mask}(x,y) = f(x,y) - \bar{f}(x,y)$</p></li><li><p>$g(x,y) = f(x,y) + k \times g_{mask}(x,y)$</p></li><li><p>模糊图像$\bar{f}(x,y)$</p></li><li><p>非锐化掩蔽$k=1$; 高提升滤波$k&gt;1$</p></li></ul></li></ul><h4 id="使用一阶微分对图像锐化"><a href="#使用一阶微分对图像锐化" class="headerlink" title="使用一阶微分对图像锐化"></a>使用一阶微分对图像锐化</h4><ul><li><p>利用梯度的大小</p><ul><li><p>梯度：最大变化率的方向</p><ul><li>线性算子 $\nabla f \equiv grad(f) $</li></ul></li><li><p>大小</p><ul><li>非线性 $M(x,y) = mag(\nabla f) = \sqrt{g_x^2+g_y^2}$</li></ul></li><li><p>近似计算</p><ul><li>$M(x,y) \approx |g_x| + |g_y|$</li></ul></li></ul></li></ul><h4 id="算术操作增强"><a href="#算术操作增强" class="headerlink" title="算术操作增强"></a>算术操作增强</h4><ul><li><p>算术/逻辑操作主要以像素对像素为基础在两幅或多幅图像间进行。</p></li><li><p>四大类：</p><ul><li>加法</li><li>加法运算常用于减少图像中的随机噪声<ul><li>定理：对$M$幅加性噪声图像进行平均，可以使图像的平方信噪比提高$M$倍。</li></ul></li></ul></li><li>减法<ul><li>用来突出细节</li></ul></li><li>乘法<ul><li>通常用来进行掩模运算<ul><li>除法</li></ul></li><li>通常可以用来归一化</li></ul></li></ul><h3 id="空间域图像增强-Part-IV"><a href="#空间域图像增强-Part-IV" class="headerlink" title="空间域图像增强(Part IV)"></a>空间域图像增强(Part IV)</h3><ul><li><p>集合操作</p></li><li><p>逻辑操作</p></li><li><p>空间操作</p><ul><li><p>单像素操作</p></li><li><p>邻域操作</p></li><li><p>几何空间变换</p></li><li><p>图像配准</p></li></ul></li><li><p>灰度内插</p></li></ul><h4 id="灰度图像的集合操作"><a href="#灰度图像的集合操作" class="headerlink" title="灰度图像的集合操作"></a>灰度图像的集合操作</h4><ul><li><p>灰度图像集合$A$</p></li><li><p>元素为三元组$(x,y,z)$</p><ul><li>$x$和$y$是空间坐标,$z$是灰度</li></ul></li><li><p>集合$A$的补集(大小不变)</p><ul><li><p>$A^C = {(x,y,K-z)| (x,y,z)\in A}$</p></li><li><p>$K = 2^k -1$为灰度级数，$k$为比特数</p></li></ul></li><li><p>集合$A$和$B$的并集</p><ul><li>$ A \cup B = { \max\limits_{z}{(a,b)} \ a\in A, b\in B }$</li></ul></li></ul><h4 id="逻辑操作"><a href="#逻辑操作" class="headerlink" title="逻辑操作"></a>逻辑操作</h4><ul><li><p>二值图像</p><ul><li>前景(1值)、背景(0值)</li></ul></li><li><p>OR、AND、NOT逻辑操作</p><ul><li>集合的并、交和求补操作</li></ul></li><li><p>属于$A$不属于$B$ 操作</p></li><li><p>XOR操作</p></li><li><p>功能完备操作</p><ul><li>AND、OR和NOT</li></ul></li></ul><h4 id="单像素操作"><a href="#单像素操作" class="headerlink" title="单像素操作"></a>单像素操作</h4><ul><li><p>以灰度为基础改变单个像素的值</p><ul><li>灰度变换</li></ul></li></ul><h4 id="邻域操作"><a href="#邻域操作" class="headerlink" title="邻域操作"></a>邻域操作</h4><ul><li><p>由输入坐标$(x,y)$的邻域像素决定</p><ul><li>空间滤波</li></ul></li></ul><p>单像素操作、邻域操作对单幅图像做处理，不改变像素的空间位置</p><p>算术/逻辑运算对多幅图像做处理，也不改变像素的空间位置</p><h4 id="几何变换"><a href="#几何变换" class="headerlink" title="几何变换"></a>几何变换</h4><ul><li><p>几何变换改变像素的空间位置使得图像得到增强</p></li><li><p>橡皮膜操作</p><ul><li><p>在橡皮膜上印刷一幅图像</p></li><li><p>然后拉伸橡皮膜</p></li></ul></li><li><p>几何变换包含两个独立的算法：空间变换算法和灰度内插算法</p><ul><li><p>空间变换：描述每个像素空间位置的变换</p></li><li><p>灰度内插：确定变换后图像像素的灰度级</p></li></ul></li><li><p>图像的每个坐标点$(v,w)$ 变换到新坐标点$(x,y)$ </p><ul><li><p>$(x,y) = T{(v,w)}$</p></li><li><p>图像坐标是离散的，网格的。变换后的坐标点可能不落在网格点上。</p></li></ul></li><li><p>空间变换需要满足一个条件</p><ul><li><p>保持图像中曲线型特征的连续性和各物体的连通性</p></li><li><p>简而言之的话——相邻的输入产生相邻的输出</p></li></ul></li><li><p>任意的空间变换会弄乱图像内容，或者内容支离破碎</p></li><li><p>一个常用的空间变换：仿射变换(Affine Transformation)</p></li></ul><h4 id="仿射变换"><a href="#仿射变换" class="headerlink" title="仿射变换"></a>仿射变换</h4><ul><li><p>仿射变换(Affine Transformation)包括了旋转、伸缩、平移、倾斜等变换</p><ul><li><p>$x = t<em>{11}v + t</em>{21}w + t_{31}$</p></li><li><p>$y = t<em>{12}v + t</em>{22}w + t_{32}$ </p></li><li><p>$t<em>{31}$和$t</em>{32}$ 刻画了平移量</p></li><li><p>$t<em>{11}$和$t</em>{22}$ 刻画了伸缩比例</p></li><li><p>$t<em>{12}$和$t</em>{21}$ 刻画了倾斜程度</p></li><li><p>整体组合刻画了平移、旋转角度、倾斜程度</p></li></ul></li><li><p>优点</p><ul><li><p>保持共线性(co-linearity)</p><ul><li>共线的点变换后依然共线</li></ul></li><li><p>保持距离比例(ratios of distance)</p><ul><li>线的中心变换后依然是线的中心</li></ul></li></ul></li><li><p>几种变换</p><ul><li><p>恒等变换</p><ul><li>$x=v$, $y = w$</li></ul></li><li><p>伸缩变换</p><ul><li>$x= c_x v$, $y = c_y w$</li></ul></li><li><p>旋转变换</p><ul><li>$x = v \cos{\theta} - w \sin{\theta}$ , $y = v \sin{\theta} + w \cos{\theta}$</li></ul></li><li><p>平移变换</p><ul><li>$x=v + t_x$, $y = w + t_y$</li></ul></li><li><p>(垂直)倾斜变换</p><ul><li>$x=v+s_v w$, $y = w$</li></ul></li><li><p>(水平)倾斜变换</p><ul><li>$x=v$, $y = s_h v + w$</li></ul></li></ul></li><li><p>变换公式</p><ul><li><p>$x= t<em>{11}v + t</em>{21}w + t_{31}$</p></li><li><p>$y = t<em>{12}v + t</em>{22}w + t_{32}$ </p></li><li><p>矩阵形式：</p><ul><li>$[x \ y \ 1] = [v \ w \ 1] T_1 T_2 \cdot \cdot \cdot$</li></ul></li></ul></li><li><p>逆仿射变换</p><ul><li><p>$T = T_1T_2T_3$</p></li><li><p>$T^{-1} = T_3^{-1} T_2^{-1} T_1^{-1}$</p></li><li><p>基本变换矩阵都是可逆矩阵 </p></li></ul></li><li><p>前向影射</p><ul><li><p>根据输入$(v,w)$,计算输出$(x,y) = T{(v,w)}$</p></li><li><p>多个输入对应一个输出、空白输出</p></li></ul></li><li><p>反向映射</p><ul><li><p>根据输出$(x,y)$,寻找输入$(v,w) = T^{-1}{(v,w)}$</p></li><li><p>灰度内插</p></li><li><p>更加有效</p></li></ul></li></ul><p>图像配准</p><ul><li><p>问题定义</p><ul><li><p>输入图像、输出图像（参考图像）</p></li><li><p>估计变换函数</p></li></ul></li><li><p>实际应用</p><ul><li><p>相似时间内不同设备的图像</p></li><li><p>相同设备不同时间拍摄的图像</p></li></ul></li><li><p>约束点</p><ul><li>输入图像和输出图像中位置已知的相应点</li></ul></li></ul><p>点匹配法</p><ul><li><p>在图像中寻找对应的点</p></li><li><p>如何将图像A、B对齐？</p></li><li><p>寻找匹配点</p></li><li><p>图像A中的n个点：P</p></li><li><p>图像B中的n个点：Q</p></li><li><p>寻找最优仿射变换</p><ul><li>$Q=PT$</li></ul></li><li><p>求解线性方程</p></li><li><p>求解最小二乘</p><ul><li>$\min<em>{T} || Q-PT||</em>{F}^2$</li></ul></li><li>闭合解：$T = (P^T P)^{-1}P^T Q$</li></ul><p>线性内插</p><p>双线性内插</p><h2 id="频率域图像增强，傅里叶变换"><a href="#频率域图像增强，傅里叶变换" class="headerlink" title="频率域图像增强，傅里叶变换"></a>频率域图像增强，傅里叶变换</h2><p>傅里叶级数：任何周期函数都可以表示为不同频率的正弦函数和/或余弦函数加权之和。</p><p>傅里叶变换：非周期函数也可以表示为不同频率的正弦函数和/或余弦函数加权之后的积分。</p><p>欧拉公式：$e^{j \theta} = \cos \theta + j \sin \theta $ </p><p>在0处的连续单位冲激：$\delta(t) = \begin{cases} \infty &amp; \text{if } t= 0\ 0 &amp;  \text{if } t \not= 0 \end{cases}$, 且满足 $\int_{-\infty}^{\infty} \delta(t) dt =1$</p><p>采样性质: $\int_{-\infty}^{\infty} f(t) \delta(t) dt = f(0)$</p><p>在$t_0$处的连续单位冲激：$\delta(t-t_0)$</p><p>在0处的离散单位冲激: $\delta(x) = \begin{cases} 1 &amp; x=0 \ 0 &amp; x \not= 0\end{cases}$ ，且满足$\sum\limits_{x=-\infty}^{\infty} \delta(x) = 1$</p><p>采样性质$\sum\limits_{x=-\infty}^{\infty} f(x) \delta(x) = f(0)$ </p><p>在$x_0$处的离散单位冲激$\delta(x-x_0)$</p><h3 id="冲激串："><a href="#冲激串：" class="headerlink" title="冲激串："></a>冲激串：</h3><p>无穷个以$\Delta T$ 为间距的周期性冲激之和</p><p>$s<em>{\Delta T} = \sum\limits</em>{n = -\infty}^{\infty} \delta(t-n\Delta T)$, $\delta$ 可以是连续的，也可以是离散的</p><h3 id="傅里叶级数"><a href="#傅里叶级数" class="headerlink" title="傅里叶级数"></a>傅里叶级数</h3><p>傅里叶级数可以理解为把$f(t)$ 在$e^{j \frac{2 \pi n}{T}t}$ 生成的空间中表示出来，其中基向量两两正交，所以系数就是$<f(t), e^{j="" \frac{2\pi="" n}{t}t}="">$ </f(t),></p><p>$f(t)$是周期为$T$的周期函数</p><p>$f(t) = \sum\limits_{n= -\infty}^{infty} c_n e^{j \frac{2 \pi n}{T}t}$, 其中 $c<em>n = \frac{1}{T} \int</em>{-T/2}^{T/2} f(t) e^{-j \frac{2 \pi n}{T}t} dt$ </p><h3 id="连续函数的傅里叶变换"><a href="#连续函数的傅里叶变换" class="headerlink" title="连续函数的傅里叶变换"></a>连续函数的傅里叶变换</h3><p>$\Im{f(t)} = \int_{-\infty}^{\infty} f(t) e^{-j2 \pi \mu t} dt$, 区中$\mu$ 是连续变量</p><p>表示成$\mu$ 的函数: $F(\mu) = \int_{-\infty}^{\infty} f(t) e^{-j 2 \pi \mu t} dt$ , $\mu$ 表示频率，单位是$Hz$ </p><p>傅里叶反变换：$f(t) = \int_{-\infty}^{\infty}F(\mu) e^{j2 \pi \mu t} d \mu$ </p><p>盒状函数的傅里叶变换：$F(\mu) = AW \frac{\sin (\pi \mu W)}{(\pi \mu W)}$ </p><p>$sinc(m) = \frac{\sin (\pi m)}{(\pi m)}$ </p><p>连续单位冲激的傅里叶变换：$F(\mu) = \int<em>{-\infty}^{\infty} \delta(t) e^{-j 2 \pi \mu t} dt = \int</em>{-\infty}^{\infty} e^{-j 2 \pi \mu t} \delta(t)  dt = e^{-j2 \pi \mu 0} = e^0 = 1$</p><p>$t_0$ 处连续单位冲激的傅里叶变换：$F(\mu) = e^{-j2 \pi \mu t_0} = \cos(2 \pi \mu t_0) - j \sin(2 \pi \mu t_0)$ </p><p>$f(t)$的傅里叶变换为$F(\mu)$, $F(t)$ 的傅里叶变换为$f(-\mu)$ </p><p>$\delta(t-t_0) \rightarrow  e^{-j2 \pi \mu t_0}$,  $e^{-j 2\pi t_0 t} \rightarrow \delta(-\mu - t_0)$, $\rightarrow$代表傅里叶变换</p><p>$\delta(t-t_0) \rightarrow e^{-j 2 \pi \mu t_0}$ , $e^{j 2 \pi a t} \rightarrow \delta(-\mu +a) = \delta(\mu -a)$ </p><h3 id="冲激串"><a href="#冲激串" class="headerlink" title="冲激串"></a>冲激串</h3><p>$s<em>{\Delta T}(t) = \sum\limits</em>{n = - \infty}^{\infty} \delta(t-n \Delta T)$</p><p>傅里叶级数：$s<em>{\Delta T}(t) = \frac{1}{\Delta T} \sum\limits</em>{n = -\infty}^{\infty} e^{j \frac{2 \pi n}{\Delta T}t}$ </p><p>傅里叶变换： $\Im{e^{j \frac{2 \pi n}{\Delta T}t} } = \delta(\mu - \frac{n}{\Delta T})$. 所以 $S(\mu) = \frac{1}{\Delta T} \sum\limits_{n=-\infty}^{\infty} \delta(\mu - \frac{n}{\Delta T})$ </p><h3 id="连续卷积"><a href="#连续卷积" class="headerlink" title="连续卷积"></a>连续卷积</h3><p>连续函数的卷积：$f(t) \star h(t) = \int_{-\infty}^{\infty} f(\tau) h(t - \tau) d \tau$, $t$是位移，负号表示反转</p><p>平移性质:$\Im{h(t - \tau) } = H(\mu) e^{-j2 \pi \mu \tau}$ </p><p>$\Im{ f(t) \star h(t) } = H(\mu) F(\mu)$</p><h3 id="卷积定理"><a href="#卷积定理" class="headerlink" title="卷积定理"></a>卷积定理</h3><ul><li>空间域卷积的傅里叶变换 $\Leftrightarrow$ 傅里叶变换在频率域的乘积 ： $f(t) \star h(t) \Leftrightarrow H(\mu) F(\mu) $</li><li>空间域乘积的傅里叶变换$\Leftrightarrow$ 傅里叶变换在频率域的卷积：$f(t)h(t) \Leftrightarrow H(\mu) \star F(\mu)$ </li></ul><h3 id="连续函数采样"><a href="#连续函数采样" class="headerlink" title="连续函数采样"></a>连续函数采样</h3><p>$\tilde{f}(t) = f(t) s<em>{\Delta T} (t) = \sum\limits</em>{n = - \infty} ^{\infty} f(t) \delta(t - n \Delta T)$ </p><p>采样值：$f<em>k = \int</em>{-\infty}^{\infty}f(t) \delta(t-k \Delta T) dt = f(k \Delta T)$ </p><p>$\tilde{F}(\mu) = \Im{\tilde{f}(t) } = \Im{f(t)s_{\Delta T}(t) } = F(\mu) \star S(\mu)$ </p><h3 id="采样定理"><a href="#采样定理" class="headerlink" title="采样定理"></a>采样定理</h3><p>带限函数$f(t)$: 傅里叶变换后非零频率属于$[-\mu<em>{\max}, \mu</em>{\max}]$ </p><p>采样定理：如果以超过函数最高频率的两倍采样率来获得样本，连续的带限函数可以完美地从它的样本集来恢复。</p><p>奈奎斯特频率：$2\mu_{\max}$ </p><p>混淆：在实际中，不可以避免，因为即使原函数是带限的，但采样仍然是有限的。有限长度采样会引入无限频率分量。</p><h3 id="抗混淆"><a href="#抗混淆" class="headerlink" title="抗混淆"></a>抗混淆</h3><ul><li>一个带限函数一定是从$-\infty$ 扩展到$\infty$</li><li>没有有限持续时间的函数是带限的</li><li>有限长度的采样，混淆是不可避免的。</li><li>抗混淆<ul><li>事先防止或减轻混淆</li><li>平滑输入函数，减少高频分量<ul><li>图像散焦</li></ul></li></ul></li></ul><h3 id="由样本恢复原函数"><a href="#由样本恢复原函数" class="headerlink" title="由样本恢复原函数"></a>由样本恢复原函数</h3><ul><li>频率域操作<ul><li>$F(\mu) = H(\mu) \tilde{F}(\mu)$</li></ul></li><li>空间域操作<ul><li>$f(t) = \int_{-\infty}^{\infty}F(\mu) e^{j 2 \pi \mu t} d \mu$</li><li>$f(t) = \Im^{-1}{F(\mu) } = \Im^{-1}{H(\mu)\tilde{F}(\mu) } = h(t) \star \tilde{f}(t)$</li><li>化简<ul><li>$\tilde{f}(t) = f(t) s<em>{\Delta T}(t) = \sum\limits</em>{n = -\infty}^{\infty} f(t) \delta(t-n\Delta T)$</li><li>$h(t) = \frac{\sin(\pi t / \Delta T)}{\pi t / \Delta T}$</li></ul></li><li>函数内插：$f(t) = \sum\limits_{n = - \infty}^{\infty}f(n \Delta T) sinc[(t-n\Delta T)/n \Delta T]$<ul><li>无限个样本的内插，但实际中只能近似，如灰度内插</li><li>$t= k \Delta T$ 时， $f(t) = f(k \Delta T)$ </li></ul></li></ul></li></ul><h3 id="扩展：超越采样定理"><a href="#扩展：超越采样定理" class="headerlink" title="扩展：超越采样定理"></a>扩展：超越采样定理</h3><ul><li>压缩感知<ul><li>稀疏</li></ul></li><li>矩阵补全<ul><li>低秩</li></ul></li></ul><h3 id="离散傅里叶变换-DFT"><a href="#离散傅里叶变换-DFT" class="headerlink" title="离散傅里叶变换(DFT)"></a>离散傅里叶变换(DFT)</h3><ul><li>对$\tilde{F}(\mu)$的一个周期为$[0,1/\Delta T]$采样<ul><li>$\mu = \frac{m}{M \Delta T}$,  $m=0,1,2,…,M-1$ </li></ul></li><li>考虑$M$个样本构造的$\tilde{F}(\mu)$<ul><li>$\tilde{F}(\mu) = \sum_{n=0}^{M-1} f_n e^{-j 2 \pi \mu n \Delta T}$  </li></ul></li><li>离散傅里叶变换(DFT)<ul><li>$F<em>m = \sum</em>{n=0}^{M-1}f_n e^{-j 2 \pi m n /M}$, $m=0,1,2,…,M-1$ </li></ul></li><li><p>离散傅里叶反变换(IDFT)</p><ul><li>$f<em>n = \frac{1}{M} \sum</em>{m=0}^{M-1}F_me ^{j 2 \pi m n /M}$, $n=0,1,2,…,M-1$</li><li>表达式不依赖采样间隔、频率间隔</li><li>适用于任何均匀取样的有限离散样本集</li></ul></li><li><p>无限周期、周期为$M$</p><ul><li>$F(u) = F(u+kM)$, $f(x) = f(x+kM)$</li></ul></li></ul><p>离散卷积：</p><ul><li>$f(x) \star h(x) = \sum\limits_{m=0}^{M-1} f(m) h(x-m)$</li><li>$x=0,1,2,…,M-1$</li><li>周期函数，也被称为循环卷积</li><li>卷积定理仍然成立</li></ul><h3 id="图像中的混淆"><a href="#图像中的混淆" class="headerlink" title="图像中的混淆"></a>图像中的混淆</h3><ul><li>有限长度的采样，混淆是不可避免的<ul><li>一维、二维…..</li></ul></li><li>空间混淆<ul><li>欠采样</li><li>锯齿、伪高光、虚假模式</li></ul></li><li>时间混淆<ul><li>图像系列中的时间间隔有关</li><li>例如电影中车轮倒转</li></ul></li></ul><h3 id="图像采样"><a href="#图像采样" class="headerlink" title="图像采样"></a>图像采样</h3><ul><li>图像放大<ul><li>可以理解为过采样</li><li>整数倍放大：水平和垂直方向像素复制</li><li>一般情况：图像缩小$\rightarrow$ 灰度内插</li></ul></li><li>图像缩小<ul><li>可以理解为欠采样</li><li>整数倍缩小：水平和垂直方向行列删除</li><li>一般情况：图像放大$\rightarrow$ 灰度内插</li></ul></li></ul><h3 id="莫尔模式"><a href="#莫尔模式" class="headerlink" title="莫尔模式"></a>莫尔模式</h3><p>两个近似等间隔的光栅产生的差拍模式</p><h3 id="二维离散傅里叶变换对"><a href="#二维离散傅里叶变换对" class="headerlink" title="二维离散傅里叶变换对"></a>二维离散傅里叶变换对</h3><ul><li>二维离散傅里叶变换(DFT)<ul><li>$F(u,v) = \sum\limits<em>{x=0}^{M-1} \sum\limits</em>{y=0}^{N-1} f(x,y) e^{-j 2 \pi (ux/M + vy/N)}$</li><li>$u=0,1,…,M-1$, $v=0,1,…,N-1$</li><li>$f(x,y)$是大小为$M \times N$的数字图像</li></ul></li><li>二维离散傅里叶变换(IDFT)<ul><li>$F(u,v) = \frac{1}{MN} \sum\limits<em>{u=0}^{M-1} \sum\limits</em>{v=0}^{N-1} F(u,v) e^{j2 \pi (ux/M + vy/N)}$</li><li>$x=0,1,…,M-1$, $y=0,1,…,N-1$ </li></ul></li></ul><h3 id="平移和旋转"><a href="#平移和旋转" class="headerlink" title="平移和旋转"></a>平移和旋转</h3><ul><li>平移性<ul><li>$f(x-x_0,y-y_0) \Leftrightarrow F(u,v) e^{- j 2 \pi ( x_0 u/M + y_0 v / N)}$</li><li>$f(x,y) e^{j 2 \pi (u_0 x /M + v_0 y / N)} \Leftrightarrow F(u-u_0, v-v_0)$</li><li>平移不影响幅值</li><li>中心化：<ul><li>$f(x,y)(-1)^{x+y} \Leftrightarrow F(u-M/2,v-N/2)$ </li></ul></li></ul></li><li>旋转性<ul><li>$f(x,y)$ 旋转$\theta_0$, 则$F(u,v)$旋转相同的角度。</li></ul></li><li>对称性<ul><li>实函数$f(x,y)$的傅里叶变换是共轭对称<ul><li>$F^{*}(u,v) = F(-u,-v)$</li></ul></li><li>虚函数$f(x,y)$的傅里叶变换是共轭反对称<ul><li>$F^* (-u,-v) = - F(u,v)$</li></ul></li></ul></li></ul><h3 id="傅里叶谱和相角"><a href="#傅里叶谱和相角" class="headerlink" title="傅里叶谱和相角"></a>傅里叶谱和相角</h3><ul><li>幅度(傅里叶谱)<ul><li>$|F(u,v| = [R^2(u,v) + I^2 (u,v)]^{1/2}$</li></ul></li><li>相角$[- \pi, \pi]$<ul><li>$\phi(u,v) = \arctan{[\frac{I(u,v)}{R(u,v)}]}$</li></ul></li><li>功率谱<ul><li>$P(u,v) = |F(u,v)|^2$</li></ul></li><li>实函数$f(x,y)$的傅里叶变换是共轭对称<ul><li>$F^* (u,v) = F(-u,-v)$</li><li>傅里叶谱是关于原点偶对称<ul><li>$|F(u,v)| = |F(-u,-v)|$</li></ul></li><li>相角是关于原点奇对称<ul><li>$\phi(u,v) = - \phi(-u,-v)$</li></ul></li></ul></li></ul><p>$|F(0,0)| = MN |\bar{f}(x,y|$, $F(0,0)$ 被称作直流分量(频率为0)</p><p>傅里叶谱决定了正弦波的幅度，表示灰度</p><p>相角表示正弦波的位移，携带了定位信息</p><p>图像平移不改变傅里叶谱</p><p>图像旋转$\theta_0$, 谱图旋转同样的角度： $f(r,\theta + \theta_0) \Leftrightarrow F(\omega, \phi+\theta_0)$ </p><h3 id="0填充"><a href="#0填充" class="headerlink" title="0填充"></a>0填充</h3><ul><li>$f(x)$有$A$个样本，$g(x)$有$B$个样本</li><li>对样本后面补0，使其长度为$P$</li><li>缠绕错误可以避免，如果：$P \ge A+B-1$</li><li>要让卷积定理和直接卷积一致，需要0填充</li></ul><h2 id="Ch08"><a href="#Ch08" class="headerlink" title="Ch08"></a>Ch08</h2><p>提纲：</p><ul><li>频率域滤波<ul><li>频率域性质</li><li>频率域滤波基础</li><li>空间和频率域对应关系</li></ul></li><li>平滑图像<ul><li>理想低通滤波器</li><li>巴特沃斯低通滤波器</li><li>高斯低通滤波器</li></ul></li></ul><h3 id="频率域性质"><a href="#频率域性质" class="headerlink" title="频率域性质"></a>频率域性质</h3><p>图像空间特征和频率分量的一般性关系</p><ul><li>变化最慢的分量，与平均灰度成正比</li><li>低频对应于图像中缓慢变化的灰度(墙)</li><li>高频对应于图像中剧烈变化的灰度(边缘)</li></ul><p>频率域滤波：</p><ul><li>空间域   —-傅里叶变换—&gt; 频率域 —-滤波—&gt; 频率域 —傅里叶反变换—&gt; 空间域</li></ul><p>傅里叶变换：</p><ul><li>$F(u,v) = |F(u,v)|e^{j \phi(u,v)}$</li><li>幅度(傅里叶谱) $|F(u,v)|$、 相角$\phi(u,v)$ </li><li>视觉分析难以利用相角</li><li>傅里叶谱可以大致刻画图像</li></ul><p>频率域滤波基础</p><ul><li>基本公式： $g(x,y) = \Im^{-1} [H(u,v) F(u,v)]$ <ul><li>$F(u,v)= \Im[f(x,y)]$ 是图像$f(x,y)$的DFT</li><li>$H(u,v)$是滤波函数(滤波器)</li><li>$H$实对称, $f$是实数 $\Rightarrow$  $g$是实数<ul><li>但存在计算误差，忽略$g$中虚数</li></ul></li><li>假设$F(u,v)$已经中心化<ul><li>$f(x,y) (-1)^{x+y} \Leftrightarrow F(u-M/2, v-N/2)$ </li></ul></li><li>只需要考虑中心对称的$H(u,v)$ </li></ul></li></ul><p>低通滤波器：衰减高频而通过低频，模糊图像. 低频对应于图像中缓慢变换的灰度</p><p>高通滤波器：衰减低频而通过高频，强化细节。高频对应于图像中剧烈变换的灰度。</p><p>二维0填充</p><ul><li>f(x,y) 是 $A \times B$大小的图像</li><li>$h(x,y)$是$C \times D$大小的图像</li><li>缠绕错误可以避免，如果对$f$和$h$进行补零， 其中$P \ge A+C-1$, $Q \ge B+D-1$</li><li>选择偶数会让计算更快</li></ul><h3 id="如何对频域滤波器0填充"><a href="#如何对频域滤波器0填充" class="headerlink" title="如何对频域滤波器0填充"></a>如何对频域滤波器0填充</h3><ul><li>第一种方案：<ul><li>频域滤波器  —傅里叶反变换—&gt; 图像 —0填充—&gt; 图像 —傅里叶变换—&gt; 频域滤波器</li><li>缺点：频率域出现波动</li></ul></li><li>第二种方案(更常用)<ol><li>对图像进行0填充，并计算傅里叶变换</li><li>设计与填充后图像一样大的频域滤波器<ul><li>并不能完全避免缠绕错误</li><li>实际效果很好，比第一种方案更佳</li></ul></li></ol></li></ul><h3 id="空间滤波器一般流程"><a href="#空间滤波器一般流程" class="headerlink" title="空间滤波器一般流程"></a>空间滤波器一般流程</h3><ol><li>给定一幅大小为$M \times N$ 的输入图像$f(x,y)$, 选择填充参数$P$和$Q$。 典型地，我们选择$P=2M$ 和 $Q=2N$ </li><li>对$f(x,y)$ 添加必要数量的0， 形成大小为$P \times Q$ 的填充后图像$f_p (x,y)$ </li><li>用$(-1)^{x+y}$ 乘以$f_p(x,y)$ 移到其变换的中心</li><li>计算来自步骤3的图像的DFT，得到$F(u,v)$</li><li>生成一个实的、对称的滤波函数$H(u,v)$, 其大小为$P \times Q$, 中心在$(\frac{P}{2}, \frac{Q}{2})$ 处。用阵列相乘形成乘积$G(u,v) = H(u,v) F(u,v)$ </li><li>得到处理后的图像：$g_p(x,y) = { real[\Im^{-1}[G(u,v)] ] } (-1)^{x+y}$</li><li>通过$g_p(x,y)$的左上象限提取$M \times N$ 区域，得到最终处理结果$g(x,y)$ </li></ol><p>零相移滤波器</p><ul><li>假设滤波器为实数<ul><li>$g(x,y) = \Im^{-1} [H(u,v)F(u,v)]$</li><li>$g(x,y) = \Im^{-1} [H(u,v)R(u,v) + jH(u,v)I(u,v)]$<ul><li>其中: $F(u,v) = R(u,v) + j I(u,v)$</li></ul></li><li>相角保持不变</li></ul></li></ul><h3 id="频率域滤波器-gt-空间滤波器"><a href="#频率域滤波器-gt-空间滤波器" class="headerlink" title="频率域滤波器-&gt; 空间滤波器"></a>频率域滤波器-&gt; 空间滤波器</h3><ul><li>构造各种频率域滤波器做实验<ul><li>频率域滤波器更加直观</li></ul></li><li>选择合适的频率域滤波器</li><li>构造空间滤波器来近似频率域滤波器<ul><li>通常构造”较小”的空间滤波器</li><li>空间滤波器更易实现，更高效</li></ul></li></ul><ul><li>一维频率域高斯滤波器<ul><li>$H(u) = A e^{-u^2 / 2 \sigma^2}$</li></ul></li><li>空间域对应的滤波器<ul><li>$h(x) = \sqrt{2 \pi} \sigma A e^{-2 \pi^2 \sigma^2 x^2}$</li></ul></li><li>标准差的反向关系</li></ul><ul><li>利用高斯函数构造高通滤波器<ul><li>$H(u) = A e^{-u^2 / 2 \sigma_1^2} - B e^{-u^2 / 2 \sigma_2^2}$</li></ul></li><li>空间域对应的滤波器<ul><li>$h(x) = \sqrt{2 \pi} \sigma_1 A e^{-2 \pi^2 \sigma_1^2 x^2} - \sqrt{2 \pi} \sigma_2 B e^{-2 \pi^2 \sigma_2^2 x^2}$</li></ul></li></ul><h3 id="理想低通滤波器"><a href="#理想低通滤波器" class="headerlink" title="理想低通滤波器"></a>理想低通滤波器</h3><ul><li>$H(u,v) = \begin{cases} 1 &amp; \text{ if } D(u,v) \le D_0 \ 0 &amp; \text{ if } D(u,v) &gt; D_0 \end{cases}$<ul><li>$D_0$ 为某常数，被称为截止频率</li><li>$D(u,v)$ 为$(u,v)$ 到中心的距离<ul><li>$D(u,v) = [(u-P/2)^2 + (v-Q/2)^2]^{1/2}$ </li></ul></li></ul></li><li>理想<ul><li>低频完全保留</li><li>高频完全抑制</li></ul></li><li>透视图<ul><li>圆柱体</li></ul></li><li>硬件无法实现</li><li>傅里叶变换的功率分布<ul><li>总功率：$P<em>T = \sum\limits</em>{u=0}^{P-1} \sum\limits_{v=0}^{Q-1} P(u,v)$<ul><li>其中：$P(u,v) = |F(u,v)|^2 = R^2(u,v) + I^2 (u,v)$</li></ul></li><li>半径为$D_0$的圆包含的功率百分比<ul><li>$\alpha = 100 [\sum\limits_u \sum\limits_v P(u,v) / P_T ]$</li><li>$(u,v)$ 属于圆内</li></ul></li></ul></li></ul><p>有振铃现象</p><p>振铃效应是一种出现在信号快速转换时，附加在转换边缘上导致失真的信号。而在图像或影像上，振铃效应会导致出现在边缘附近的环带或像是”鬼影”的环状伪影</p><h3 id="巴特沃斯低通滤波器"><a href="#巴特沃斯低通滤波器" class="headerlink" title="巴特沃斯低通滤波器"></a>巴特沃斯低通滤波器</h3><ul><li>$n$ 阶巴特沃斯(Butterworth)低通滤波器<ul><li>$H(u,v) = \frac{1}{1+ [D(u,v)/D_0]^{2n}}$</li><li>$D(u,v)$ 为$(u,v)$到中心的距离</li><li>$D_0$ 为截止频率</li></ul></li></ul><p>没有振铃(ringing)现象</p><p>$n=2$是比较好的折中</p><h3 id="高斯低通滤波器"><a href="#高斯低通滤波器" class="headerlink" title="高斯低通滤波器"></a>高斯低通滤波器</h3><ul><li>数学定义<ul><li>$H(u,v) =e ^{-D^2(u,v)}/ 2 \sigma^2$</li></ul></li><li>令$\sigma = D_0$ <ul><li>$H(u,v) = e^{-D^2(u,v)/2D_0^2}$</li><li>$D_0$ 为截止频率</li><li>当$D(u,v) = D_0$, $H(u,v) = 0.607$ </li></ul></li></ul><p>高斯函数的傅里叶变换依然是高斯</p><p>没有振铃现象</p><p>巴特沃斯低通滤波器比高斯低通滤波器更模糊</p><h2 id="Ch09"><a href="#Ch09" class="headerlink" title="Ch09"></a>Ch09</h2><p>提纲</p><ul><li>锐化图像<ul><li>理想高通、巴特沃斯、高斯高通滤波器</li><li>频率域拉普拉斯算子</li><li>频率域非锐化掩蔽</li><li>同态滤波</li></ul></li><li>选择性滤波<ul><li>带阻滤波器、带通滤波器</li><li>陷波滤波器</li></ul></li><li>实现</li></ul><p>如何构造高通滤波器：</p><ul><li>从低通滤波器构造高通滤波器<ul><li>$H<em>{HP} (u,v) = 1- H</em>{LP}(u,v) $</li><li>$H_{LP}(u,v)$是高通滤波器</li></ul></li><li>理想高通滤波器</li><li>巴特沃斯高通滤波器</li><li>高斯高通滤波器</li></ul><h3 id="理想高通滤波器"><a href="#理想高通滤波器" class="headerlink" title="理想高通滤波器"></a>理想高通滤波器</h3><ul><li>数学定义： 略过</li><li>理想<ul><li>低频完全抑制</li><li>高频完全保留</li></ul></li><li>硬件无法实现</li><li>产生了振铃现象</li><li>随着$D_0$的增大，振铃有所缓解</li></ul><h3 id="巴特沃斯高通滤波器"><a href="#巴特沃斯高通滤波器" class="headerlink" title="巴特沃斯高通滤波器"></a>巴特沃斯高通滤波器</h3><ul><li>轻微振铃现象</li><li>对比理想高通，巴特沃斯高通滤波器，更清晰，失真小， 对小物体的识别能力相当</li></ul><h3 id="高斯高通滤波器"><a href="#高斯高通滤波器" class="headerlink" title="高斯高通滤波器"></a>高斯高通滤波器</h3><ul><li>高斯滤波的结果更清晰一些</li></ul><h3 id="频率域的拉普拉斯算子"><a href="#频率域的拉普拉斯算子" class="headerlink" title="频率域的拉普拉斯算子"></a>频率域的拉普拉斯算子</h3><ul><li>拉普拉斯算子<ul><li>$\nabla^2f  =  \frac{\partial^2 f}{\partial x^2}+ \frac{\partial^2 f}{\partial y^2}$</li></ul></li><li>傅里叶变换<ul><li>$\nabla^2 f(t,z) \Leftrightarrow -4\pi^2 (\mu^2 + \nu^2) F(\mu,\nu)$</li></ul></li><li>频域滤波器<ul><li>$H(u,v) = - 4 \pi^2 (u^2+v^2)$</li></ul></li><li>频域滤波器(中心化)<ul><li>$H(u,v) = -4\pi^2[(u-P/2)^2 + (v-Q/2)^2] = -4 \pi^2 D^2(u,v)  $</li></ul></li><li>拉普拉斯图像<ul><li>$\nabla^2 f(x,y) = \Im^{-1} {H(u,v)F(u,v)}$</li><li>频率域滤波、傅里叶反变换</li><li>$F(u,v)$是原图像的DFT</li></ul></li><li>图像锐化<ul><li>$g(x,y) = f(x,y)+ c \nabla^2 f(x,y)$</li><li>$f(x,y)$和$\nabla^2 f(x,y)$ 不在一个数量级！</li><li>$c=-1$</li><li>$f(x,y)$ 归一化到$[0,1]$, 再计算DFT</li><li>$\nabla^2 f(x,y)$ 归一化到$[-1,1]$ </li></ul></li></ul><h2 id="Ch10-图像复原"><a href="#Ch10-图像复原" class="headerlink" title="Ch10. 图像复原"></a>Ch10. 图像复原</h2><p>提纲</p><ul><li>图像退化/复原建模</li><li>噪声模型</li><li>仅有噪声的图像复原<ul><li>均值、统计排序、自适应滤波器</li></ul></li><li>频域滤波消除周期噪声<ul><li>带阻、带通、陷波、最佳陷波</li></ul></li><li>估计退化函数</li><li>逆滤波</li></ul><p>引言：</p><ul><li>图像复原<ul><li>以预先制定的目标改善图像，客观</li><li>对模糊图像去模糊</li><li>利用退化现象的先验知识来恢复图像</li><li>建模退化过程 -&gt; 利用逆过程复原图像</li></ul></li><li>图像增强<ul><li>由人的主观感受来评判，主观</li><li>对比度拉伸、增强</li></ul></li></ul><p>图像退化/复原建模</p><ul><li>输入$f(x,y)$</li><li>退化函数$H$</li><li>加性噪声$\eta (x,y)$</li><li>复原滤波器</li><li>输出$\hat{f}(x,y)$</li><li>目标： $f(x,y) \approx \hat{f}(x,y)$ </li></ul><ul><li>$H$为线性，位置不变<ul><li>$g(x,y) = h(x,y) \star f(x,y) + \eta(x,y)$</li><li>$h(x,y)$是退化函数的空间表示</li></ul></li><li>频率域表示<ul><li>$G(u,v) = H(u,v)F(u,v) + N(u,v)$ </li></ul></li></ul><p>噪声</p><ul><li>当$H=I$时<ul><li>$G(u,v) = F(u,v) +N(u,v)$</li></ul></li><li>噪声来源<ul><li>图像获取：环境条件、传感器质量</li><li>图像传输：无线信号被干扰</li></ul></li><li>刻画噪声<ul><li>空间域和频率域特点<ul><li>白噪声：傅里叶变换后为常数</li></ul></li><li>噪声是否和图像有关</li></ul></li><li>噪声的空间表示<ul><li>概率密度函数(PDF)</li></ul></li></ul><p>噪声类型</p><ul><li>高斯噪声<ul><li>电路噪声，传感器噪声</li></ul></li><li>瑞利噪声<ul><li>范围成像</li></ul></li><li>爱尔兰(伽马)噪声<ul><li>激光成像</li></ul></li><li>指数噪声<ul><li>激光成像</li></ul></li><li>均匀噪声<ul><li>仿真生成随机数</li></ul></li><li>脉冲(椒盐)噪声<ul><li>快速过渡</li></ul></li></ul><h3 id="仅有噪声的图像复原"><a href="#仅有噪声的图像复原" class="headerlink" title="仅有噪声的图像复原"></a>仅有噪声的图像复原</h3><ul><li>仅有噪声的图像退化<ul><li>空间域： $g(x,y)=f(x,y) + \eta(x,y)$</li><li>频率域：$G(u,v) = F(u,v) + N(u,v)$</li></ul></li><li>周期噪声<ul><li>从$G(u,v)$ 估计$N(u,v)$, 直接减去噪声</li></ul></li><li>一般加性噪声<ul><li>空间滤波</li></ul></li></ul><h3 id="统计排序滤波器-1"><a href="#统计排序滤波器-1" class="headerlink" title="统计排序滤波器"></a>统计排序滤波器</h3><ul><li>非线性滤波器<ul><li>对滤波器覆盖的像素排序</li><li>用排序决定的值替代中心像素</li></ul></li><li>中值滤波器<ul><li>$\hat{f} (x,y) = median {g(s,t)}, (s,t)\in S_{xy} $</li><li>$(x,y)$ 处的像素值也参与计算</li><li>良好的去噪能力，并且模糊少</li><li>尤其适用于单极或双极的脉冲信号</li></ul></li><li>最大值滤波器<ul><li>寻找图像中的亮点</li><li>降低胡椒噪声</li></ul></li><li>最小值滤波器<ul><li>寻找图像中的暗点</li><li>降低盐粒噪声</li></ul></li><li>中点滤波器<ul><li>最大值和最小值的中点</li><li>结合了统计排序和求平均</li><li>适用于随机噪声<ul><li>高斯噪声、均匀噪声</li></ul></li></ul></li><li>$\alpha$截断的均值滤波<ul><li>去掉$S_{xy}$中灰度最低的$d/2$个像素</li><li>去掉$S_{xy}$中灰度最高的$d/2$个像素<ul><li>$\hat{f} (x,y) =\frac{1}{mn-d} \sum\limits<em>{(s,t) \in S</em>{x,y} } g_r(s,t)$ </li></ul></li><li>适用于存在多种噪声的情况<ul><li>高斯噪声、椒盐噪声混合</li></ul></li><li>$d=0$, 算数均值滤波器</li><li>$d=mn-1$, 中值滤波器</li></ul></li></ul><h2 id="Ch11-彩色图像处理-I"><a href="#Ch11-彩色图像处理-I" class="headerlink" title="Ch11. 彩色图像处理(I)"></a>Ch11. 彩色图像处理(I)</h2><ul><li><p>全彩色：用全彩色传感器获取的真实彩色</p></li><li><p>伪彩色：为特定灰度或灰度范围赋予颜色</p></li><li><p>无色光</p><ul><li>灰度级：表示强度的数值</li></ul></li><li>彩色光<ul><li>约为400-700纳米电磁波</li><li>辐射：能量(瓦特)</li><li>光强：感知的能量(流明)</li><li>亮度：主观描绘</li></ul></li></ul><ul><li>主颜色<ul><li>红色、绿色、蓝色</li></ul></li><li>次生色(secondary colors)<ul><li>主颜色叠加</li></ul></li><li>颜料的主颜色<ul><li>吸收光的主颜色</li></ul></li></ul><p>区分颜色：</p><ol><li>亮度：主观描绘，类似于无色光的强度</li><li>色调：主波长，也就是感知到的颜色</li><li>饱和度：<ul><li>反应白光的比例，白光越多越不饱和</li><li>红色+白色=粉红色、紫色+白色=淡紫色</li></ul></li></ol><ul><li>色度：色调、饱和度</li></ul><h3 id="伪彩色图像处理"><a href="#伪彩色图像处理" class="headerlink" title="伪彩色图像处理"></a>伪彩色图像处理</h3><p>按照特定规则对灰度值赋颜色</p><p>便于可视化和理解灰度事件</p><h4 id="灰度分层"><a href="#灰度分层" class="headerlink" title="灰度分层"></a>灰度分层</h4><p>根据截面分配两种颜色</p><p>也可以截取k个面，分成$k+1$个颜色。</p><p>也可以对每个RGB做一次灰度变换。</p><h3 id="RGB彩色模型"><a href="#RGB彩色模型" class="headerlink" title="RGB彩色模型"></a>RGB彩色模型</h3><ul><li>面向彩色显示器</li><li>笛卡尔坐标系<ul><li>红绿蓝在三个角</li><li>黑色在原点</li><li>白色在最远的角</li><li>中间虚线是灰色</li><li>正则化<ul><li>属于$[0,1]$</li></ul></li></ul></li><li>3幅分量图像<ul><li>每种主颜色对应一幅图像</li><li>叠加在一起合成一幅彩色图像</li></ul></li><li>像素深度(pixel depth)<ul><li>表示每个像素的比特数</li></ul></li><li>全彩色图像<ul><li>24比特的RGB图像</li><li>颜色数目$2^{24} = 16777216$</li></ul></li><li>高端显卡或显示器<ul><li>支持24比特的RGB图像</li></ul></li><li>低端设备<ul><li>通常只能显示256种彩色</li><li>更多的颜色有时没有意义</li></ul></li><li>稳定RGB色(safe RGB colors)<ul><li>真实展现、与硬件无关</li><li>互联网:稳定Web色</li><li>通常包括216颜色</li><li>每个RGB只有六种取值: $6^3 =216$</li></ul></li></ul><h3 id="CMY颜色模型"><a href="#CMY颜色模型" class="headerlink" title="CMY颜色模型"></a>CMY颜色模型</h3><ul><li>青色(C)、洋红(M)、黄色(Y)<ul><li>彩色打印机</li></ul></li><li>转换公式<ul><li>[C M Y] = [1 1 1] - [R G B]</li></ul></li><li>CMYK颜色模型<ul><li>CMY的混合产生的黑色不纯</li><li>添加了黑色(K)</li></ul></li></ul><h3 id="HSI颜色模型"><a href="#HSI颜色模型" class="headerlink" title="HSI颜色模型"></a>HSI颜色模型</h3><ul><li>RGB/CMY颜色模型不够直观<ul><li>人不会直接用这些数字来描述颜色</li></ul></li><li>色调(hue)<ul><li>主波长，也就是感知到的颜色</li></ul></li><li>饱和度(saturation)<ul><li>反应白光的比例，白光越多越不饱和</li></ul></li><li>亮度(brightness)<ul><li>主观描绘，类似于无色光的强度(intensity)</li></ul></li><li>HSI模型将亮度和颜色相关的信息解耦合<ul><li>颜色相关的信息:色调、饱和度</li><li>对人而言更直观</li></ul></li><li>强度(intensity)<ul><li>平行面与强度轴的交点</li></ul></li><li>饱和度(saturation)<ul><li>与强度轴的距离相反</li><li>强度轴上的饱和度为0</li></ul></li></ul><h2 id="Ch13-图像分割"><a href="#Ch13-图像分割" class="headerlink" title="Ch13. 图像分割"></a>Ch13. 图像分割</h2><p>引言：</p><ul><li>图像分割：<ul><li>把图像细分为构成它的区域或物体</li><li>分割的粒度取决于应用问题</li></ul></li><li>分割是图像处理最困难问题之一<ul><li>分割的精度决定了处理任务的成败</li></ul></li><li>分割的基本原理<ul><li>灰度的不连续性：根据灰度的突变分割</li><li>灰度的相似性：区域内的图像很相似</li></ul></li></ul><p>基础知识：</p><ul><li>R表示图像所占的区域</li><li>图像分割将R分割成$n$个区域$R_1,…,R_n$<ol><li>$\cup_{i=1}^n R_i = R$</li><li>$R_i$是一个连通集合，$i=1,…,n$</li><li>$R_i \cap R_j = \emptyset, \forall i \not= j$</li><li>$Q(R_i) = True, i=1,…,n$</li><li>对于任意的相邻区域$R_i$和$R_j$, $Q(R_i \cup R_j) = False$</li></ol></li><li>$Q(\cdot)$ 表示某个用于划分区域的函数</li></ul><p>基本概念：</p><ul><li>边缘<ul><li>边缘像素：灰度发生剧烈变化</li><li>边缘是连通的边缘像素集合</li></ul></li><li>线<ul><li>一种特殊的边缘</li><li>两侧的灰度值都很大或都很小</li></ul></li><li>点<ul><li>长宽只有一个像素的线</li></ul></li></ul><p>背景知识：</p><ul><li>1阶或2阶导数可以检测灰度突变</li><li>1阶导数的性质<ul><li>在恒定灰度区域为零</li><li>在突变(斜坡、台阶)的起点非零</li><li>沿着斜坡非零</li><li>$\frac{\partial f}{\partial x} = f’(x) = f(x+1)-f(x)$</li></ul></li><li>2阶导数的性质<ul><li>在恒定灰度区域为零</li><li>在突变(斜坡、台阶)的起点和终点非零</li><li>沿着恒定斜率斜坡为零</li><li>$\frac{\partial^2 f}{\partial x^2} = \frac{\partial f’(x)}{\partial x} = f’(x+1) - f’(x) = f(x+2)-2f(x+1)+f(x)$</li><li>我们一般写成：$\frac{\partial^2 f}{\partial x^2} = f(x+1)+f(x-1)-2f(x)$ </li></ul></li></ul><p>一般结论：</p><ul><li>一阶导数通常产生较粗的边缘</li><li>二阶导数对细节有较强的响应<ul><li>细线、孤立点、噪声</li></ul></li><li>二阶导数在斜坡和台阶产生双边缘响应</li><li>二阶导数的符号变换有指示意义<ul><li>灰度从亮到暗</li><li>灰度从暗到亮</li></ul></li></ul><h3 id="孤立点的检测"><a href="#孤立点的检测" class="headerlink" title="孤立点的检测"></a>孤立点的检测</h3><ul><li>利用二阶导数检测孤立点<ul><li>响应更强</li></ul></li><li>拉普拉斯算子<ul><li>$\nabla^2 f(x,y) = \frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2} = f(x+1,y) + f(x-1,y) + f(x,y+1) + f(x,y-1)-4f(x,y)$  </li></ul></li><li>检测方法<ul><li>根据响应幅度是否大于某阈值$T$</li><li>$g(x,y) = \begin{cases} 1 &amp; \text{if} |R(x,y)| \ge T\ 0 &amp; \text{otherwise} \end{cases}$ </li><li>其中$R = \sum\limits_{k=1}^9 w_k z_k$ </li></ul></li></ul><h3 id="线检测"><a href="#线检测" class="headerlink" title="线检测"></a>线检测</h3><ul><li>利用二阶导数检测线<ul><li>响应更强、更细的线</li><li>需要留意双线效应</li></ul></li><li>拉普拉斯算子</li><li>可以只保留正数</li></ul><h3 id="边缘模型"><a href="#边缘模型" class="headerlink" title="边缘模型"></a>边缘模型</h3><ul><li>台阶边缘(Step Edge)<ul><li>1个像素距离上发生灰度级的理想过渡</li><li>经常出现在计算机生成的图像中</li></ul></li><li>斜坡边缘(Ramp Edge)<ul><li>实际边缘通常是模糊(聚焦机制)、有噪声(电子器件)</li><li>斜率与模糊程度成反比</li><li>一阶导数的大小用来检测其像素处是否存在边缘</li><li>二阶导数的符号用来确定一个边缘像素位于亮或暗区域</li></ul></li><li>屋顶边缘(Roof Edge)<ul><li>表示穿过区域的线</li><li>出现在数字化的线条图、卫星图像中的道路</li></ul></li><li>三种边缘通常同时出现<ul><li>陡峭的斜坡通常被认为是台阶</li></ul></li></ul><p>存在噪声的边缘：</p><ol><li>视觉上噪声并不明显</li><li>噪声对导数影响很大</li><li>二阶导数无法辨认</li><li>存在噪声时，图像平滑很必要</li></ol><p>边缘检测的三个基本步骤</p><ol><li>为降噪对图像进行平滑处理<ul><li>导数对噪声敏感</li></ul></li><li>边缘点的检测<ul><li>抽取所有的潜在边缘点</li></ul></li><li>边缘定位<ul><li>选出真正的边缘点</li></ul></li></ol><h3 id="基本边缘检测"><a href="#基本边缘检测" class="headerlink" title="基本边缘检测"></a>基本边缘检测</h3><p>图像的梯度及其性质：</p><ul><li>梯度：最大变化率的方向<ul><li>线性算子 $\nabla f \equiv grad(f) \equiv [g_x, g_y]^T = [\frac{\partial f}{\partial x} , \frac{\partial f}{\partial y}]^T $ </li></ul></li><li>大小<ul><li>非线性： $M(x,y) = mag(\nabla f) = \sqrt{g_x^2 + g_y^2}$ </li><li>近似计算： $M(x,y) \approx |g_x| + |g_y|$ </li></ul></li><li>方向<ul><li>$\alpha(x,y) = tan^{-1} [\frac{g_y}{g_x}]$</li></ul></li><li>边缘的方向和梯度正交</li></ul><p>梯度算子：</p><ul><li>罗伯特交叉梯度算子<ul><li>$g_x = \frac{\partial f}{\partial x} = (z_9 -z_5)$</li><li>$g_y = \frac{\partial f}{\partial y} = (z_8 -z_6)$</li><li>非中心化</li><li>考虑对角方向</li></ul></li><li>普鲁伊特(Prewitt)算子<ul><li>$g_x = (z_7 + z_8 +z_9) - (z_1 +z_2 + z_3)$</li><li>$g_y = (z_3 + z_6 + z_9) - (z_1 + z_4 + z_7)$ </li><li>关于中心点对称</li></ul></li><li>Sobel算子<ul><li>$g_x = (z_7 + 2z_8 +z_9) - (z_1 +2z_2 + z_3)$</li><li>$g_y = (z_3 + 2z_6 + z_9) - (z_1 + 2z_4 + z_7)$</li><li>关于中心点对称</li></ul></li></ul><h3 id="高级边缘检测"><a href="#高级边缘检测" class="headerlink" title="高级边缘检测"></a>高级边缘检测</h3><ul><li>基本边缘检测<ul><li>没有考虑边缘的性质</li><li>没有考虑噪声模型</li></ul></li><li>Marr-Hildreth边缘检测器</li><li>坎尼(Canny)边缘检测器</li></ul><h4 id="Marr-Hildreth边缘检测器"><a href="#Marr-Hildreth边缘检测器" class="headerlink" title="Marr-Hildreth边缘检测器"></a>Marr-Hildreth边缘检测器</h4><ol><li>灰度变化和图像尺度有关<ul><li>需要用不同尺寸的算子</li></ul></li><li>灰度变化会影响导数<ul><li>一阶导数出现波峰或波谷</li><li>二阶导数出现零交叉</li></ul></li><li>理想的检测器具有如下功能<ol><li>能够近似1阶或2阶导数</li><li>能够被调整以在不同尺寸上起作用<ul><li>大的算子检测模糊边缘、小的算子检测细节</li></ul></li></ol></li></ol><p>滤波器$\nabla^2 G$</p><ul><li>$\nabla^2$是拉普拉斯算子<ul><li>$\nabla^2 = \frac{\partial^2}{\partial x^2} + \frac{\partial^2}{\partial y^2}$</li><li>$G$是二维高斯函数<ul><li>$G(x,y) = e^{- \frac{x^2+y^2}{2 \sigma^2}}$</li><li>其中$\sigma$是标准差</li></ul></li><li>满足上页两个条件的最佳算子</li><li>高斯的拉普拉斯(LoG)</li></ul></li></ul><p>优势</p><ol><li>高斯部分会模糊图像<ul><li>可以去掉尺寸小于$\sigma$ 的细节，比如噪声</li></ul></li><li>二阶导数<ul><li>各向同性，对任何方向的变化有相同的响应</li><li>符合人的视觉系统</li></ul></li></ol><p>步骤：</p><ol><li>用$n \times n$ 的高斯低通滤波器平滑图像<ul><li>$n$是大于等于$6 \sigma$的最小奇数</li></ul></li><li>计算上述图像的拉普拉斯</li><li>寻找上述结果的零交叉<ol><li>检查某像素两个相对 邻域像素的符号(上下、左右、两对角)</li><li>符号相反，并且差异大于某阈值</li></ol></li></ol><p>产生闭环 “意大利空心粉”效应， 通过阈值化可以缓解</p><h4 id="坎尼-Canny-边缘检测器"><a href="#坎尼-Canny-边缘检测器" class="headerlink" title="坎尼(Canny)边缘检测器"></a>坎尼(Canny)边缘检测器</h4><ol><li>低错误率<ul><li>所有边缘都被找到，并且没有伪响应</li></ul></li><li>边缘点应被很好地定位<ul><li>已定位的边缘必须尽可能接近真实边缘</li></ul></li><li>单一的边缘点响应<ul><li>对每个真实边缘点，检测器仅返回一个点</li></ul></li></ol><ul><li>数学分析<ul><li>考虑加性高斯白噪声污染的1维台阶边缘</li><li>高斯一阶导数是近似最优的检测器</li></ul></li><li>拓展到二维情况<ul><li>挑战：边缘可能是任意方向</li><li>使用二维高斯函数</li><li>基于梯度寻找边缘的方向</li></ul></li></ul><p>步骤:</p><ol><li>高斯函数平滑输入图像</li><li>计算图像的梯度</li><li>非最大抑制<ul><li>目的:把梯度生成的粗边缘变细</li><li>指定梯度(边缘法线)的多个离散方向<ul><li>4种边缘：水平、垂直、+$45^{\circ}$, $-45^{\circ}$ </li></ul></li><li>根据梯度(边缘法线)的方向确定边缘的方向</li><li>考虑$(x,y)$为中心的$3 \times 3$区域</li><li>考虑四个方向</li><li>确定和梯度$\alpha(x,y)$最接近的方向$d_k$ </li><li>如果$M(x,y)$的值比$(x,y)$在$d_k$方向的任一邻居数值小，对其抑制<ul><li>$g_N(x,y) = 0$</li></ul></li><li>否则，保留：<ul><li>$g_N(x,y) = M(x,y)$ </li></ul></li></ul></li><li>滞后阈值<ul><li>目的：减少伪边缘点</li><li>两个阈值：低阈值$T_L$、 高阈值$T_H$ </li><li>两个阈值的比值为: $2:1$或$3:1$</li><li>利用$T_H$阈值化<ul><li>强边缘点： $g_{NH} (x,y) = g_N(x,y) \ge T_H$</li></ul></li><li>利用$T_L$阈值化<ul><li>$g_{NL}(x,y) = g_N(x,y) \ge T_L$</li><li>$g<em>{NL}$包含$g</em>{NH}$的所有非零元素</li><li>去掉$g<em>{NL}$ 中和$g</em>{NH}$重复的点<ul><li>$g<em>{NL}(x,y) = g</em>{NL}(x,y) - g_{NH}(x,y)$</li><li>弱边缘点</li></ul></li></ul></li></ul></li><li>连通性分析<ol><li>遍历$g_{NH}$中的每一个点$p$<ul><li>保留$g_{NL}$中和$p$ 连通(例如8连通)</li></ul></li><li>去掉$g_{NL}$剩余的点</li><li>合并$g<em>{NH}$ 和 $g</em>{NL}$ </li></ol></li></ol><h2 id="Ch14-图像分割"><a href="#Ch14-图像分割" class="headerlink" title="Ch14. 图像分割"></a>Ch14. 图像分割</h2><p>背景：</p><ul><li>边缘检测的结果不完美<ul><li>噪声</li><li>不均匀照明导致的边缘间断</li><li>虚假的灰度值不连续</li></ul></li><li>边缘连接<ul><li>将边缘像素组合成有意义的边缘或区域边界<ol><li>局部处理</li><li>区域处理</li><li>全局处理(使用霍夫变换)</li></ol></li></ul></li></ul><h3 id="局部处理"><a href="#局部处理" class="headerlink" title="局部处理"></a>局部处理</h3><ol><li><p>分析每个点$(x,y)$邻域内像素的特点</p></li><li><p>将依据某准则相似的点连接起来</p><ol><li>基于梯度大小判断相似： $|M(s,t) - M(x,y)| \le E$</li><li>基于梯度方向判断相似：$|\alpha(s,t) - \alpha(x,y)| \le A$ </li></ol><ul><li>如果大小和方向都相似，则连接$(s,t)$和$(x,y)$ </li></ul></li></ol><p>简化算法(计算简单)</p><ol><li>计算输入图像$f(x,y)$的梯度大小和方向<ul><li>梯度大小$M(x,y)$, 梯度方向$\alpha(x,y)$</li></ul></li><li>依据下式产生二值图像<ul><li>$g(x,y) = 1$ if $M(x,y) &gt; T_M$ AND $\alpha(x,y) = A \pm T_A $</li><li>$T_M$为阈值、$A$为特定角度、$T_A$为允许的带宽</li></ul></li><li>逐行扫描，填充长度不超过$K$的空隙</li><li>以角度$\theta$ 旋转$g(x,y)$,重复第3步，再反旋转</li></ol><h3 id="区域处理"><a href="#区域处理" class="headerlink" title="区域处理"></a>区域处理</h3><ul><li>前提<ul><li>感兴趣区域的位置已知</li></ul></li><li>目标<ul><li>基于区域连接像素，近似区域的边界</li></ul></li><li>方法<ul><li>函数近似<ul><li>为已知点拟合一条2维曲线</li></ul></li><li>多边形近似<ul><li>实现容易、捕捉基本形状特征、表示简单</li></ul></li></ul></li></ul><p>算法设计：</p><ul><li>前提<ul><li>两个起始点</li><li>所有的点必须排序<ul><li>顺时针、逆时针</li></ul></li></ul></li><li>判断曲线类型<ul><li>边界线段(开放曲线)<ul><li>存在两个间距较大的连续点(可作为起始点)</li></ul></li><li>边界(闭合曲线)<ul><li>连续点之间的距离比较均匀<ul><li>两端的点为起始点</li></ul></li></ul></li></ul></li></ul><p>区域处理算法：</p><ol><li>令$P$ 是一个已排序、不重复的二值图像中的序列。指定两个起始点$A$和$B$。它们是多边形的两个起始顶点。</li><li>指定一个阈值$T$,以及两个空堆栈”开”(OPEN)和”闭”(CLOSED)。</li><li>如果$P$中的点对应于一条闭合曲线，则把$B$放到”开”和”闭”中，并把$A$放到”开”中。 如果对应于一条开放曲线，则把$A$放到”开”中，而把$B$放到”闭”。</li><li>计算从”闭”中最后一个顶点到”开”中最后一个顶点的线的参数。</li><li>寻找属于序列$P$、且在步骤4中直线的两个顶点之间的点；计算这些点与直线的距离，选择具有最大距离$D<em>{max}$的点$V</em>{max}$。</li><li>如果$D<em>{max} &gt; T$, 则把$V</em>{max}$作为一个新顶点放在”开”堆栈的末尾。转到步骤4.</li><li>否则，从”开”中移除最后一个顶点，并把它作为”闭”的最后一个顶点插入。</li><li>如果”开”非空，转到步骤4</li><li>否则，退出。”闭”中的顶点就是拟合$P$中的点的多边形的顶点。</li></ol><h3 id="全局处理"><a href="#全局处理" class="headerlink" title="全局处理"></a>全局处理</h3><ul><li>考虑没有边缘先验知识的情况</li><li>利用全局性质判断是否为边缘像素<ol><li>指定感兴趣的几何形状</li><li>判断像素集合是否满足该形状</li></ol></li><li>问题:给定$n$个点，寻找共线的像素<ol><li>考虑所有可能的直线$n(n-1)/2$</li><li>寻找靠近每一条直线的像素集合<ul><li>复杂度$n^2 (n-1)/2$ </li></ul></li></ol></li></ul><h4 id="霍夫变换"><a href="#霍夫变换" class="headerlink" title="霍夫变换"></a>霍夫变换</h4><ul><li>xy-平面<ul><li>直线方程：$y_i = ax_i +b$</li></ul></li><li>ab-平面<ul><li>参数方程：$b=-ax_i + y_i$</li><li>每个点对应一条直线</li></ul></li></ul><p>但这样导致$ab$平面无限延伸，我们换一种表示方式</p><ul><li>xy-平面<ul><li>法线方程：$x \cos \theta + y \cos \theta = \rho$</li></ul></li><li>$\rho \theta-$平面<ul><li>参数方程：$\rho = x \cos \theta + y \sin \theta$ </li><li>每个点对应一条正弦曲线</li></ul></li></ul><p>如何计算交点(近似计算)：</p><ul><li>划分累加单元<ul><li>$-90^{\circ} \le \theta \le 90^{\circ}$</li><li>$-D \le \rho \le D$<ul><li>$D$是对角长度</li></ul></li></ul></li><li>统计每个单元内曲线的数目<ul><li>$(i,j)$位置单元内曲线数目记为$A(i,j)$</li><li>$(i,j)$位置单元对应的参数$(\rho_i, \theta_j)$</li><li>计算$\rho=x \cos \theta_j + y \sin \theta_j$, 并离散化</li></ul></li></ul><p>将霍夫变换用于边缘连接(可以扩展到直线以外的曲线)</p><ol><li>生成二值的边缘图像<ul><li>可采用之前介绍的任意算法</li></ul></li><li>划分$\rho \theta - $平面的累积单元<ul><li>粒度决定了精度、计算量</li></ul></li><li>统计每个累加单元的曲线数量<ul><li>寻找数值高的单元</li></ul></li><li>检验数值高累加单元对应的像素<ul><li>将距离小于某阈值的像素连接起来</li></ul></li></ol><h2 id="Ch15-图像压缩"><a href="#Ch15-图像压缩" class="headerlink" title="Ch15. 图像压缩"></a>Ch15. 图像压缩</h2><ul><li>$b$和$b’$为两种不同表示方式的比特数</li><li>用$b$比特表示的相对数据冗余： $R = 1 - \frac{1}{C}$, $C = \frac{b}{b’}$</li><li>压缩比, $C=10$ 意味着有$90\%$ 的冗余</li></ul><p>2维灰度矩阵包含三种冗余</p><ul><li>编码冗余<ul><li>编码:表示信息的符号系统 (字母、比特)</li><li>码字:符号序列</li><li>灰度图像的8位编码往往是冗余的</li></ul></li><li>空间和时间冗余<ul><li>图像中紧邻点是空间相关的</li><li>视频中连续帧是时间相关的</li></ul></li><li>不相关的信息<ul><li>被视觉系统忽略的信息</li><li>与图像用途无关的信息</li></ul></li></ul><p>霍夫曼编码</p><ul><li>单独对信源符号编码<ul><li>霍夫曼编码是最短的编码</li><li>对于固定的$n$ ,该编码是最优的</li></ul></li></ul><ol><li>简化信源<ul><li>对符号的概率进行排序，合并低概率符号</li><li>重复该过程，直到剩余两个符号</li></ul></li><li>对简化后的信息源编码<ul><li>从最小信源开始，返回到原信源</li><li>为每一个分支分配符号</li></ul></li></ol><h2 id="Ch16-形态学处理"><a href="#Ch16-形态学处理" class="headerlink" title="Ch16. 形态学处理"></a>Ch16. 形态学处理</h2><h3 id="腐蚀"><a href="#腐蚀" class="headerlink" title="腐蚀"></a>腐蚀</h3><ul><li>集合$B$对集合$A$的腐蚀(erosion)<ul><li>$A \ominus B  = {z| (B)_z \subseteq A  }$</li><li>$(B)_z$表示把集合$B$平移到坐标$z$</li><li>通常假设集合$B$为j结构元</li><li>$(B)_z$意味着把$B$的原点平移到$z$</li></ul></li><li>等价定义<ul><li>$A \ominus B = { z| (B)_z \cap A^c = \emptyset }$</li><li>$A^c$表示集合$A$的补集</li></ul></li><li>腐蚀，可以被理解为形态学滤波</li></ul><h3 id="膨胀"><a href="#膨胀" class="headerlink" title="膨胀"></a>膨胀</h3><ul><li>集合$B$对集合$A$的膨胀(dilation)<ul><li>$A \oplus B = { z | (\hat{B})_z \cap A \not= \emptyset}$</li><li>$\hat{B}$表示集合$B$的反射</li><li>$(\hat{B})_z$ 表示把集合$\hat{B}$平移到坐标$z$</li><li>通常假设集合$B$为结构元</li></ul></li><li>等价定义<ul><li>$A \oplus B = \bigcup\limits_{b \in B} (A)_b$  </li></ul></li></ul><h3 id="对偶性"><a href="#对偶性" class="headerlink" title="对偶性"></a>对偶性</h3><ul><li>公式<ul><li>$(A \ominus B)^c = A^c \oplus \hat{B}$ </li><li>$(A \oplus B)^c = A^c \ominus \hat{B}$ </li></ul></li><li>证明<ul><li>$(A\ominus B)^c  = {z | (B)_z \subseteq A }^c = {z | (B)_z \cap A^c \not= \emptyset }^c = {z | (B)_z \cap A^c \not= \emptyset } = A^c \oplus \hat{B} $ </li></ul></li></ul><h3 id="开操作和闭操作"><a href="#开操作和闭操作" class="headerlink" title="开操作和闭操作"></a>开操作和闭操作</h3><p>$A \circ B = \bigcup { (B)_z | (B)_z \subseteq A }$ </p><p>$A \cdot B = {z | (B)_z \cap A  \not= \emptyset}$</p><h2 id="Ch17-目标识别"><a href="#Ch17-目标识别" class="headerlink" title="Ch17. 目标识别"></a>Ch17. 目标识别</h2><p>提纲</p><ul><li>引言</li><li>模式和模式类</li><li>基于决策论方法的识别<ul><li>匹配<ul><li>最小距离分类器</li><li>基于相关的匹配</li></ul></li><li>最佳统计分类器</li><li>神经网络<ul><li>针对两类的感知机</li><li>多层前馈神经网络</li></ul></li></ul></li></ul><p>决策论方法</p><ul><li>决策论方法(decision-theoretic methods)<ul><li>$x=(x_1,x_2,…,x_n)^T$表示$n$维的模式向量</li><li>存在$W$个模式类$w_1, w_2,…,w_W$</li><li>构造决策函数$d_1(\cdot), d_2(\cdot),…,d_W(\cdot)$</li><li>如果$ x \in w_i$, 那么 $d_i(x) &gt; d_j(x)$,  $j=1,2,…,W; j \not= i$</li></ul></li><li>$w_i$和$w_j$之间的决策边界<ul><li>$d_i(x) = d_j (x) \Leftrightarrow  d_i(x) - d_j(x)=0$</li><li>$d_{ij}(x) = d_i(x) - d_j(x) =0$</li><li>$d_{ij}(x)&gt;0$ 则属于$w_i$; 反之，属于$w_j$    </li></ul></li></ul><h3 id="最小距离分类器"><a href="#最小距离分类器" class="headerlink" title="最小距离分类器"></a>最小距离分类器</h3><ol><li>把原型定义为每个类的平均向量<ul><li>$m_j = \frac{1}{N<em>j} \sum\limits</em>{x_j \in w_j} x_j $, $j=1,…,W$</li><li>$N_j$ 是类别$w_j$包含的模式数量</li></ul></li><li>利用欧式距离判断远近 <ul><li>$D_j(x) = ||x-m_j || $, $j=1,…,W$</li><li>$||a|| = (a^T a)^{1/2}$</li><li>如果$D_i(x)$是最短距离，那么$x \in w_i$ </li><li>等价计算方式</li><li>$d_j(x) = x^T m_j - \frac{1}{2} m_j^T m_j$  $j=1,2,…,W$</li><li>如果$d_i(x)$是最大值，那么$x \in w_i$ </li></ul></li></ol><ul><li><p>$w_i$ 和$w_j$之间的决策边界</p><ul><li>$d_{ij} = d_i(x) - d_j(x) = x^T(m_i-m_j) - \frac{1}{2} (m_i-m_j)^T (m_i+m_j) =0$</li><li>连接$m_i$ 和 $m_j$线段的垂直平分线(bisector)</li><li>$n=2$, 对应于直线</li><li>$n=3$, 对应于平面</li><li>$n&gt;3$, 对应于超平面 </li></ul></li><li><p>最小距离分类器的适用场景</p><ul><li>最小距离分类器的适用场景</li><li>类内之间的分散程度小</li></ul></li><li>实际应用中<ul><li>未必满足上述条件</li></ul></li><li>解决方案<ul><li>对数据进行预处理<ul><li>特征选择、特征抽取</li></ul></li><li>控制数据的产生过程</li></ul></li></ul><h3 id="最佳统计分类器"><a href="#最佳统计分类器" class="headerlink" title="最佳统计分类器"></a>最佳统计分类器</h3><p>基础知识</p><ul><li>把属于$w_i$的模式预测为属于$w_j$<ul><li>遭受损失$L_{ij}$</li></ul></li><li>模式$x$属于类别$w_i$的概率记为$p(w_i|x)$</li><li>预测模式$x \in w_j$的平均损失<ul><li>条件平均风险： $r<em>j(x) = \sum\limits</em>{k=1}^W L_{kj} p(w_k | x)$</li><li>贝叶斯公式<ul><li>$r<em>j(x) = \frac{1}{p(x)} \sum\limits</em>{k=1}^W L_{kj} p(x|w_k) P(w_k) $</li><li>$p(x|w_k)$表示类别的概率密度</li></ul></li><li>去掉与类别无关的$1/p(x)$<ul><li>$r<em>j(x) = \sum\limits</em>{k=1}^W L_{kj} p(x|w_k) P(w_k)$</li></ul></li></ul></li><li>贝叶斯分类器<ul><li>最小化平均损失</li><li>预测$x \in w_i$ 如果 $r_i(x) &lt; r_j(x)$,  $\forall j \not=i$ </li><li>0-1损失函数： $L<em>{ij} = 1 - \delta</em>{ij}$<ul><li>预测正确无损失，预测错误损失为1</li><li>$r_j(x) = p(x) - p(x|w_j) P(w_j)$ </li></ul></li></ul></li><li>前提条件<ul><li>每个类$w_j$出现的概率$P(w_j)$已知<ul><li>从数据中估计，或者直接令$P(w_j) = 1/W$</li></ul></li><li>每个类$w_j$的概率密度$p(x|w_j)$已知<ul><li>从数据中估计高维密度$p(x|w_j)$已知</li><li>从数据中估计高位密度函数非常困难</li><li>通常假设密度函数为某种解析形式，然后从数据中估计函数参数</li></ul></li></ul></li></ul><h3 id="针对高斯模式类的贝叶斯分类器"><a href="#针对高斯模式类的贝叶斯分类器" class="headerlink" title="针对高斯模式类的贝叶斯分类器"></a>针对高斯模式类的贝叶斯分类器</h3><ul><li>假设概率密度$p(x|w_j)$为高斯函数</li><li>考虑1维空间内的2分类问题<ul><li>$n=1$, $W=2$</li><li>决策函数<ul><li>$d_j(x) = p(x|w_j) P(w_j) = \frac{1}{\sqrt{2 \pi} \sigma_j} e^{-\frac{(x-m_j)^2}{2 \sigma_j^2}} P(w_j) , j=1,2$ </li><li>参数为均值$m_1,m_2$, 标准差$\sigma_1, \sigma_2$ </li></ul></li></ul></li><li>考虑$n$ 维空间内的$W$分类问题</li></ul><p>Ch04</p><p>空间相关与卷积 区别 联系  例子</p><p>滤波器特点</p><p>近邻含义 </p><p>不用背傅里叶公式 只会被离散版本</p><p>选择题</p><p>判断题</p><p>简答题</p><p>计算题</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;数字图像处理&quot;&gt;&lt;a href=&quot;#数字图像处理&quot; class=&quot;headerlink&quot; title=&quot;数字图像处理&quot;&gt;&lt;/a&gt;数字图像处理&lt;/h1&gt;&lt;h2 id=&quot;课程概述&quot;&gt;&lt;a href=&quot;#课程概述&quot; class=&quot;headerlink&quot; title=&quot;课
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Computer Network Review</title>
    <link href="https://ricky-ting.github.io/2020/01/02/Computer-Network-Review/"/>
    <id>https://ricky-ting.github.io/2020/01/02/Computer-Network-Review/</id>
    <published>2020-01-02T02:03:14.000Z</published>
    <updated>2020-01-02T02:04:19.152Z</updated>
    
    <content type="html"><![CDATA[<h1 id="计算机网络"><a href="#计算机网络" class="headerlink" title="计算机网络"></a>计算机网络</h1><h2 id="课程概述"><a href="#课程概述" class="headerlink" title="课程概述"></a>课程概述</h2><h3 id="参考教材"><a href="#参考教材" class="headerlink" title="参考教材"></a>参考教材</h3><ul><li><p>James F. Kurose, Keith W. Ross. 计算机网络-自顶向下方法(7th)</p></li><li><p>William Stallings. 数据与计算机通信(10th)</p></li></ul><h3 id="课程考核"><a href="#课程考核" class="headerlink" title="课程考核"></a>课程考核</h3><ul><li><p>分组实践，课程报告 (30%)</p></li><li><p>课后作业(30%)</p></li><li><p>期末考试(40%)</p></li></ul><p>nju2019autumn@163.com</p><h3 id="课程内容"><a href="#课程内容" class="headerlink" title="课程内容"></a>课程内容</h3><ul><li><p>端网络</p><ul><li><p>前端网络：客户端</p></li><li><p>后端网络：服务端</p></li></ul></li><li><p>骨干网</p></li></ul><a id="more"></a><h2 id="第一章"><a href="#第一章" class="headerlink" title="第一章"></a>第一章</h2><p>服务质量：</p><ul><li><p>“best effort”(unreliable) data delivery  –IP</p></li><li><p>Reliable data delivery from source to destination –TCP</p></li><li><p>Guaranteed delay and throughout  – QoS</p></li></ul><p>Network Protocols</p><ul><li>HTTP, TCP, IP, PPP, Ethernet</li></ul><p>Internet standards</p><ul><li><p>IETF: Internet Engineering Task Force</p></li><li><p>RFC: Request for comments</p></li><li><p>Client/server model</p><ul><li><p>Client host requests, receives service from always-on server</p></li><li><p>e.g. Web browser/server; Email client/server</p></li></ul></li><li><p>Peer-to-peer model</p><ul><li><p>Minimal(or no) use of dedicated servers</p></li><li><p>eg. Skype, Bit Torrent</p></li></ul></li></ul><p>Magnitude of Different Delay：</p><ul><li><p>Transmission delay</p><ul><li>Significant for low-speed links, now typically a few microseconds or less</li></ul></li><li><p>Propagation delay</p><ul><li>A few micro-seconds to hundreds of milliseconds</li></ul></li><li><p>Nodal processing delay</p><ul><li>Nodal processing delay</li></ul></li><li><p>Queuing delay</p><ul><li>Depends on congestion, maybe seconds</li></ul></li></ul><p>Queuing Delay：</p><ul><li><p>R=link bandwidth (bps)</p></li><li><p>L=packet length (bits)</p></li><li><p>$\alpha$=average packet arrival rate</p></li><li><p>Traffic intensity $\rho = L \times \alpha / R$ </p></li><li><p>Intensity $\rho$ ~ 0 : average queuing delay small</p></li><li><p>Intensity $\rho \rightarrow$1 : delays become large, and huge</p></li><li><p>Intensity $\rho \ge $1 : average delay infinite</p></li></ul><p>Different Types of Malware</p><ul><li><p>Virus</p><ul><li><p>Infection by receiving and running (unwarily) executables</p></li><li><p>Self-replicating: propagate itself to other executables</p></li></ul></li><li><p>Worm</p><ul><li>Actively transmitting itself over a network to infect other hosts</li></ul></li><li><p>Trojan horses</p><ul><li>Disguised as something innocuous or desirable, tempting the user to run it</li></ul></li><li><p>Backdoor </p><ul><li>Providing a method of bypassing normal authentication procedures</li></ul></li><li><p>Adware</p><ul><li>Playing, displaying, or downloading advertisements to the user host</li></ul></li><li><p>Spyware</p><ul><li>Recording keystrokes, web sites visited, uploading info to collection site</li></ul></li></ul><p>Denial of Service (DOS)</p><ul><li><p>Attackers make resources (server, bandwidth) unavailable by overwhelming resource with bogus traffic</p></li><li><p>e.g. multiple coordinated sources swamp server with TCP SYN message</p></li></ul><p>How to handle Masquerade</p><ul><li>Encryption: the message cannot be understood</li><li>MAC: the message cannot be altered</li><li>Sign: the source cannot be forged</li></ul><p>交换机通常位于接入网中，而路由器通常用于网络核心中。</p><p>一个分组所经历的一系列通信链路和分组交换机称为通过该网络的路径(route或path).</p><p>因特网工程任务组(Internet Engineering Task Force, IETF)</p><p>请求评论(Request For Comment, RFC) </p><p>接入网：是指将端系统物理连接到其边缘路由器(edge router)的网络。边缘路由器是端系统到任何其他远程端系统的路径上的第一台路由器。</p><p>存储转发传输(store-and-forward transmission):是指在交换机能够开始向输出链路传输该分组的第一个比特之前，必须接收到整个分组。</p><p>接入ISP-区域ISP(regional ISP)- 第一层ISP(tier-1 ISP)</p><h2 id="第二章：应用层"><a href="#第二章：应用层" class="headerlink" title="第二章：应用层"></a>第二章：应用层</h2><p>两种主流体系结构：</p><ul><li>客户-服务器体系架构</li><li>对等(P2P)体系结构</li></ul><h3 id="Web和HTTP"><a href="#Web和HTTP" class="headerlink" title="Web和HTTP"></a>Web和HTTP</h3><p>HTTP是一个无状态协议(stateless protocol)</p><p>非持续连接(non-persistent connection): 每个请求/响应是经一个单独的TCP连接发送</p><p>持续连接(persistent connection): 所有的请求及其响应经相同的TCP连接发送</p><h4 id="HTTP报文格式"><a href="#HTTP报文格式" class="headerlink" title="HTTP报文格式"></a>HTTP报文格式</h4><p>HTTP请求报文的第一行叫做请求行(request line), 其后继的行叫做首部行(header line)，后面还可能有实体体(entity body).</p><p>请求行有三个字段：方法字段、URL字段和HTTP版本字段</p><p>HTTP响应报文包括三个部分：状态行、首部行、实体体</p><h2 id="第三章：运输层"><a href="#第三章：运输层" class="headerlink" title="第三章：运输层"></a>第三章：运输层</h2><h3 id="3-1-概述和运输层服务"><a href="#3-1-概述和运输层服务" class="headerlink" title="3.1 概述和运输层服务"></a>3.1 概述和运输层服务</h3><p>运输层协议只工作在端系统</p><p>运输层协议能够提供的服务常常受制于底层网络层协议的服务模型。然而，即使底层网络协议不能在网络层提供相应的服务，运输层协议也能提供某些服务。</p><ul><li>UDP(用户数据报协议):不可靠、无连接的服务。</li><li>TCP(传输控制协议):可靠的、面向连接的服务。</li></ul><p>端口号是一个16比特的数，其大小在0~65535之间。0~1023范围的端口号称为周知端口号(well-known port).</p><ul><li>如果两个UDP报文段有不同的源IP地址和/或源端口号，但具有相同的目的IP地址和目的端口号，那么这两个报文段将通过相同的目的套接字被定向到相同的目的进程。</li><li>但TCP与UDP不同：两个具有不同源IP地址或源端口号的到达TCP报文段被定向到两个不同的套接字，除非TCP报文段携带了初始创建连接的请求。当一个TCP报文段到达主机时，所有4个字段被用来将报文段定向(分解)到相应的套接字。</li></ul><p>端口扫描：可以用nmap</p><ul><li>对于TCP，nmap顺序地扫描端口，寻找能够接受TCP连接的端口</li><li>对于UDP，nmap也是顺序地扫描端口，寻找对传输的UDP报文段进行响应的UDP端口。</li></ul><h3 id="3-3-无连接运输：UDP"><a href="#3-3-无连接运输：UDP" class="headerlink" title="3.3 无连接运输：UDP"></a>3.3 无连接运输：UDP</h3><p>UDP特点：</p><ul><li>关于发送什么数据以及何时发送的应用层控制更为精细</li><li>无须连接建立, goole(QUIC)</li><li>无连接状态</li><li>分组首部开销小。每个TCP报文段都有20字节的首部开销，而UDP仅有8字节开销。</li><li>NAT穿透可以用UDP，UDP打洞</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">|源端口号(2byte)|目的端口号(2byte)|</span><br><span class="line">| 长度(2byte)   |检验和(2byte)  |</span><br><span class="line">| 应用数据(报文) |</span><br></pre></td></tr></table></figure><p>UDP校验和：即因特网校验和。2字节相加，溢出回卷，最后取反码。</p><p>端到端原则(end-end principle),该原则表述为因为某种功能必须基于端到端实现：”与在较高级别提供这些功能(比如这里的差错检测)的代价相比，在较低级别上设置的功能可能是冗余的或几乎没有价值的。”</p><p>虽然UDP提供差错检测，但它对差错恢复无能无力。UDP的某种实现只是丢弃受损的报文段，其他实现是将受损的报文段交给应用程序并给出警告。</p><h3 id="3-4-可靠数据传输原理"><a href="#3-4-可靠数据传输原理" class="headerlink" title="3.4 可靠数据传输原理"></a>3.4 可靠数据传输原理</h3><p>可靠数据传输为上层实体提供的服务抽象是：数据可以通过一条可靠的信道进行传输。借助于可靠信道，传输数据比特就不会受到损坏或丢弃，而且所有数据都是按照其发送顺序进行交付。</p><p>GoBackN协议：</p><p>SR协议：</p><ul><li>窗口长度必须小于或等于序号空间大小的一半。</li></ul><h3 id="3-5-面向连接的运输：TCP"><a href="#3-5-面向连接的运输：TCP" class="headerlink" title="3.5 面向连接的运输：TCP"></a>3.5 面向连接的运输：TCP</h3><p>最大报文段长度(Maximum Segement Size,MSS): MSS通常根据最初确定的由本地发送主机发送的最大链路层帧长度(即所谓的最大传输单元(Maximum Transimission Unit, MTU))来设置。如以太网和PPP链路层协议都具有1500字节的MTU，因此MSS的典型值为1460字节。MSS不包括首部。</p><p>TCP协议没有规定收到失序的报文段应该怎么办，这一问题可以给实现TCP的编程人员去处理。他们可以丢弃或者缓存，现实中通常采用缓存。</p><p>TCP的首部：</p><ul><li>源端口号(16比特)</li><li>目的端口号(16比特)</li><li>序号(32比特)</li><li>确认号(32比特)</li><li>首部长度(4比特)</li><li>一些标志位</li><li>接收窗口(16比特)</li><li>因特网校验和(16比特)</li><li>紧急数据指针(16比特)</li></ul><p>TCP提供累积确认(cumulative acknowledgment)</p><h4 id="3-5-3-往返时间的估计与超时"><a href="#3-5-3-往返时间的估计与超时" class="headerlink" title="3.5.3 往返时间的估计与超时"></a>3.5.3 往返时间的估计与超时</h4><ol><li>估计往返时间<ul><li>做SampleRTT的测量：在任意时刻，仅为一个已发送的但目前尚未被确认的报文段测量一个SampleRTT。TCP绝不为已被重传的报文段计算SampleRTT。</li><li>更新公式：EstimatedRTT = $(1-\alpha)$ EstimatedRTT + $\alpha$ SampleRTT</li><li>$\alpha$的推荐值是$\alpha=0.125$ </li><li>指数加权移动平均(Exponential Weighted Moving Average, EWMA)</li><li>RTT偏差DevRTT,用于估算SampleRTT一般会偏离EstimatedRTT的程度：<ul><li>DevRTT = $(1- \beta)$ DevRTT + $\beta$ |SampleRTT - EstimatedRTT|</li><li>$\beta$的推荐值为0.25</li></ul></li></ul></li><li>设置和管理重传超时间隔<ul><li>TimeoutInterval=EstimatedRTT+4DevRTT</li><li>推荐初始TimeoutInterval值为1秒。出现超时后，TimeoutInterval值将加倍。然而，只要收到报文段并更新EstimatedRTT，就使用上述公式再次计算TimeoutInterval.</li></ul></li></ol><h4 id="3-5-4-可靠数据传输"><a href="#3-5-4-可靠数据传输" class="headerlink" title="3.5.4 可靠数据传输"></a>3.5.4 可靠数据传输</h4><p>定时器太多会带了很多开销，所以使用单一定时器</p><ol><li>一些有趣的情况：关于超时和重传</li><li>超时间隔加倍</li><li>快速重传：一旦收到3个冗余ACK，TCP就执行快速重传(fast retransmit)</li><li>是回退N步还是选择重传：<ul><li>TCP只会重传一个分组</li><li>TCP的差错恢复机制更像是GBN协议和SR协议的混合体。</li></ul></li></ol><h4 id="3-5-5-流量控制-flow-control"><a href="#3-5-5-流量控制-flow-control" class="headerlink" title="3.5.5 流量控制(flow control)"></a>3.5.5 流量控制(flow control)</h4><ul><li>不同于拥塞控制</li><li>缓存不溢出，需要：LastByteRcvd - LastByteRead $\le$ RcvBuffer</li><li>所以接收窗口: rwnd=RcvBuffer-[LastByteRcvd-LastByteRead]</li><li>所以A要保持： LastByteSent - LastByteAcked $\le$ rwnd</li><li>即使B的缓存满了，$A$也会继续发送只有一个字节数据的报文段</li></ul><h4 id="3-5-6-TCP连接管理"><a href="#3-5-6-TCP连接管理" class="headerlink" title="3.5.6 TCP连接管理"></a>3.5.6 TCP连接管理</h4><p>建立连接(三次握手，three-way handshake)：</p><ol><li>客户端-&gt; [SYN=1,seq=client_isn] -&gt; 服务器端</li><li>客户端 &lt;- [SYN=1, seq=server_isn, ack=client_isn+1] &lt;- 服务器端</li><li>客户端-&gt; [SYN=0,seq=client_isn+1,ack=server_isn+1] -&gt;服务器端</li></ol><ul><li>第二步中的允许连接的报文段被称为SYNACK报文段(SYNACK segment). 第二步中通常服务器会分配变量和缓存，但为了应对洪泛攻击，服务器也可以不这么做。</li><li>第三步中可携带数据</li><li>P168 状态图</li></ul><p>关闭连接：</p><ol><li>客户端 -&gt;[FIN]-&gt;服务器端</li><li>客户端 &lt;- [ACK] &lt;- 服务器端</li><li>客户端 &lt;- [FIN] &lt;- 服务器端</li><li>客户端 -&gt; [ACK] -&gt;服务器端</li></ol><p>P169 状态图</p><p>SYN洪泛攻击</p><ul><li>攻击者发送大量的TCP SYN报文段，而不完成第三次握手，导致服务器的连接资源被消耗殆尽</li><li>解决方法：服务器返回的seq是源和目的IP地址与端口号的hash值，这样就不需要记住任何关于该TCP连接的信息，当客户端发送第三步的时候，服务器可以将ack-1然后判断该连接是否合法，如果合法就分配相应的资源。</li></ul><p>当服务器端不在某端口接收TCP连接，会发送RST。</p><p>当服务器端不在某端口接收UDP连接，会发送一个特殊的ICMP的数据报。</p><p>nmap工作原理：向目标主机的特定TCP端口发送一个特殊的TCP SYN报文段：</p><ol><li>源主机收到一个TCP SYNACK报文段：意味着目标主机上一个程序该端口接收TCP连接，所以结果是“打开”。</li><li>源主机收到一个TCP RST报文段：该端口没有运行接收TCP连接的程序，但至少没有被防火墙阻拦。 </li><li>什么也收不到：被防火墙阻拦。</li></ol><h3 id="3-6-拥塞控制原理"><a href="#3-6-拥塞控制原理" class="headerlink" title="3.6 拥塞控制原理"></a>3.6 拥塞控制原理</h3><p>我们可以根据网络层是否为运输层拥塞控制提供了显式帮助，来区分拥塞控制方法。</p><ul><li>端到端拥塞控制</li><li>网络辅助的拥塞控制</li></ul><h3 id="TCP拥塞控制"><a href="#TCP拥塞控制" class="headerlink" title="TCP拥塞控制"></a>TCP拥塞控制</h3><p>TCP使用端到端拥塞控制</p><p>TCP采用的方法是让每一个发送方根据所感知到的网络拥塞程度来限制其能向连接发送流量的速率。</p><p>三个问题：</p><ol><li>一个TCP发送方如何限制它向连接发送流量的速率<ul><li>发送方跟踪一个额外的变量：拥塞窗口(congestion window),表示为cwnd</li><li>我们维护：LastByteSent - LastByteAcked $\le $ min{cwnd, rwnd}</li></ul></li><li>一个TCP发送方如何感知从它到目的地之间的路径上存在拥塞呢？<ul><li>超时或收到三个冗余的ACK。</li></ul></li><li>当发送方感知到端到端的拥塞时，采用何种算法来改变其发送速率呢？<ul><li>基本原则：<ul><li>一个丢失的报文段意味着拥塞，因此当丢失报文段时应当降低TCP发送方的速率。</li><li>一个确认报文段指示该网络正在向接收方交付发送方的报文段，因此，当对先前未确认报文段的确认到达时，能够增加发送方的速率。</li><li>带宽探测。</li></ul></li></ul></li></ol><h4 id="TCP拥塞控制算法"><a href="#TCP拥塞控制算法" class="headerlink" title="TCP拥塞控制算法"></a>TCP拥塞控制算法</h4><p>主要包括三个部分：慢启动、拥塞避免、快速恢复</p><ol><li>慢启动<ul><li>cwnd初始值较小，但每个RTT时刻翻倍直到下列三种情况<ul><li>存在一个由超时指示的丢包事件<ul><li>把cwnd设置为1并重新开始慢启动过程。并且将ssthresh(慢启动阈值)设置为cwnd/2</li></ul></li><li>达到或超过ssthresh的值，结束慢启动并且TCP转移到拥塞避免模式</li><li>检测到3个冗余ACK，TCP执行一种快速重传并进入快速恢复状态</li></ul></li></ul></li><li>拥塞避免<ul><li>线性增长：每RTT 1MSS</li><li>当拥塞时，ssthresh设置为cwnd的一半。<ul><li>如果是超时， cwnd设置为1</li><li>如果是3个冗余ACK，cwnd减半</li></ul></li></ul></li><li>快速恢复</li></ol><p>详细待了解！！！</p><p>TCP拥塞控制常常被称为加性增、乘性减(Additive-Increase, Multiplicative-Decrease, AIMD)拥塞控制方式。</p><h2 id="第四章：网络层-数据平面"><a href="#第四章：网络层-数据平面" class="headerlink" title="第四章：网络层(数据平面)"></a>第四章：网络层(数据平面)</h2><ul><li>数据平面<ul><li>转发：将一个分组从一个输入链路接口转移到适当的输出链路接口的路由器本地动作。</li></ul></li><li>控制平面<ul><li>路由选择：确定分组从源到目的地所采取的端到端路径的网络范围处理过程。</li></ul></li></ul><p>因特网的网络层提供了单一的服务，称为尽力而为服务(best-effort service).</p><h3 id="4-2-路由器工作原理"><a href="#4-2-路由器工作原理" class="headerlink" title="4.2 路由器工作原理"></a>4.2 路由器工作原理</h3><p>路由器的结构：</p><ul><li>输入端口</li><li>交换结构</li><li>输出端口</li><li>路由选择处理器: 执行控制平面的功能。在传统的路由器中，它执行路由选择协议，维护路由选择表与关联链路状态信息，并为该路由器计算转发表。在SDN路由器中，路由器选择处理器负责与远程控制器通信，目的是接收由远程控制器计算的转发表项，并在该路由器的输入端口安装这些表项。路由选择处理器还执行网络管理功能。</li></ul><p>输入端口、输出端口和交换结构几乎总是用硬件实现的。控制平面的功能通常用软件实现并在路由选择处理器上执行。</p><ul><li>基于目的地的转发</li><li>通用转发</li></ul><h4 id="4-2-1-输入端口处理和基于目的地转发"><a href="#4-2-1-输入端口处理和基于目的地转发" class="headerlink" title="4.2.1 输入端口处理和基于目的地转发"></a>4.2.1 输入端口处理和基于目的地转发</h4><p>结构：$\rightarrow$ 线路端接 $\rightarrow$  数据链路处理(协议，拆封) $\rightarrow$ 查找、转发、排队 $\rightarrow$ 交换结构</p><p>使用在每个输入端口的影子副本，转发决策能在每个输入端口本地做出，无须基于每个分组调用集中式路由选择处理器，因此避免了集中式处理的瓶颈。</p><p>转发表保存前缀，进行匹配，最长前缀匹配规则。</p><p>输入端口除了做查找，还要进行下列：</p><ol><li>必须出现物理层和链路层处理</li><li>必须检查分组的版本号、校验和以及寿命字段，并且重写后两个字段</li><li>必须更新用于网络管理的计数器。</li></ol><h4 id="4-2-2-交换"><a href="#4-2-2-交换" class="headerlink" title="4.2.2 交换"></a>4.2.2 交换</h4><ul><li>经内存交换：许多现代路由器通过内存进行交换。但他们看起来更像共享内存的多处理器。</li><li>经总线交换：输入端口经一根共享总线将分组直接传送到输出端口，不需要路由选择处理器的干预</li><li>经互联网络交换</li></ul><h4 id="4-2-3-输出端口处理"><a href="#4-2-3-输出端口处理" class="headerlink" title="4.2.3 输出端口处理"></a>4.2.3 输出端口处理</h4><p>结构：交换结构 $\rightarrow$ 排队(缓存管理) $\rightarrow$ 数据链路处理(协议，封装)  $\rightarrow$ 线路端接 $\rightarrow$ </p><h4 id="4-2-4-何处出现排队"><a href="#4-2-4-何处出现排队" class="headerlink" title="4.2.4 何处出现排队"></a>4.2.4 何处出现排队</h4><ol><li>输入排队<ul><li>线路前部(Head-Of-the-Line,HOL)阻塞</li></ul></li><li>输出排队<ul><li>丢弃到达的分组:弃尾(drop)</li><li>在缓存填满之前便丢弃一个分组：主动队列管理(Active Queue Management, AQM)算法。</li></ul></li></ol><p>用于缓存长度的经验方法：缓存数量($B$)应当等于平均往返时延(RTT)乘以链路的容量($C$) . 最近的研究： $B = RTT * C / \sqrt{N}$. $N$为TCP流的条数。</p><h4 id="4-2-5-分组调度"><a href="#4-2-5-分组调度" class="headerlink" title="4.2.5 分组调度"></a>4.2.5 分组调度</h4><ol><li>先进先出(FIFO)</li><li>优先权排队(priority queuing)<ul><li>有非抢占式优先权排队(non-preemptive priority queuing)</li></ul></li><li>循环和加权公平排队<ul><li>循环排队规则(round robin queuing discipline)</li><li>加权公平排队(Weighted Fair Queuing, WFQ)规则</li></ul></li></ol><h3 id="4-3-网际协议：IPv4、寻址、IPv6及其他"><a href="#4-3-网际协议：IPv4、寻址、IPv6及其他" class="headerlink" title="4.3 网际协议：IPv4、寻址、IPv6及其他"></a>4.3 网际协议：IPv4、寻址、IPv6及其他</h3><h4 id="4-3-1-IPv4数据报格式"><a href="#4-3-1-IPv4数据报格式" class="headerlink" title="4.3.1 IPv4数据报格式"></a>4.3.1 IPv4数据报格式</h4><ul><li>版本(号)：4比特，一般为0100, 即4</li><li>首部长度：4比特，一般为0101，即5， 5*4byte=20bytes</li><li>服务类型(TOS)：8比特，</li><li>数据报长度：16比特，以字节记</li><li>标识、标志、片偏移 (32比特)：这三个字段与所谓IP分片有关。新版本的IP(即IPv6)不允许在路由器上对分组分片</li><li>寿命(Time-To-Live, TTL) (8比特): 用来保证数据报不会永远在网络中循环。若TTL减为0，则该数据报必须丢弃。</li><li>协议(8比特)：该字段值指示了IP数据报的数据部分应交给哪个特定的运输层协议。值为6表示是TCP，值为17表示UDP</li><li>首部检验和(16比特)：IP层只对IP首部计算校验和，而TCP/UDP检验和是对整个TCP/UDP报文段进行的。</li><li>源和目的IP地址</li><li>选项字段：允许IP首部被扩展。 在IPv6首部中已去掉了IP选项。</li><li>数据(有效载荷)。</li></ul><h4 id="4-3-2-IPv4数据报分片"><a href="#4-3-2-IPv4数据报分片" class="headerlink" title="4.3.2 IPv4数据报分片"></a>4.3.2 IPv4数据报分片</h4><p>一个链路层帧能承载的最大数据量叫做最大传送单元(Maximum Transimission Unit, MTU). 对IP数据报长度具有严格限制并不是主要问题。问题在于在发送方与目的地路径上的每段链路可能使用不同的链路层协议，且每种协议可能具有不同的MTU。</p><p>IPv4的设计者感到在路由器中重新组装数据报会给协议带来相当大的复杂性并且影响路由器的性能。为坚持网络内核保持简单的原则，IPv4的设计者决定将数据报的重新组装工作放到端系统中，而不是放到网络路由器中。</p><p>所以分片可以发生在端系统和路由器上。重组只会发生在端系统上。</p><p>16比特标识唯一标识了一个数据报(发送主机通常将它发送的每个数据报的标识号加1)。13比特片偏移记录了该分片在原数据报中的偏移(以8字节为单位，所以13对应16)。最后一个片的标志比特被设为0，而所有其他片的标志比特被设为1.</p><h4 id="4-3-3-IPv4编址"><a href="#4-3-3-IPv4编址" class="headerlink" title="4.3.3 IPv4编址"></a>4.3.3 IPv4编址</h4><p>子网(subbet), 子网掩码(network mask) </p><p>因特网的地址分配策略被称为无类别域间路由选择(Classless Interdomain Routing, CIDR).</p><p>使用单个网络前缀通告多个网络的能力通常被称为地址聚合(address aggregation), 也称为路由聚合(route aggregation) 或路由摘要(route summarization) </p><p>a.b.c.d/x</p><p>一个地址的剩余32-x比特可认为是用于区分该组织内部设备的，其中的所有设备具有相同的网络前缀。</p><p>具有8、16和24比特子网地址的子网分别被称为A、B和C类网络。</p><p>255.255.255.255 广播地址</p><p>组织内的地址：动态主机配置协议(Dynamic Host Configuration, DHCP).DHCP除了分配IP地址，还会告诉主机它的子网掩码，它的第一跳路由器地址(常被称为默认网关)与它的本地DNS服务器的地址。 DHCP又常被称为即插即用协议(plug-and-play protocol) 或零配置(zeroconf)协议。</p><p>通常情况下，每个子网需要一个DHCP服务器，但也可以用一个DHCP中继代理(通常是一台路由器)，这个代理知道用于该网络的DHCP服务器的地址。</p><p>DHCP协议是一个4个步骤的过程：</p><ol><li>DHCP服务器发现<ul><li>发送DHCP发现报文(DHCP discover message), 使用UDP， 端口67。使用广播地址为目的IP，使用0.0.0.0为本机IP</li></ul></li><li>DHCP服务器提供<ul><li>DHCP服务器收到一个DHCP发现报文时，用DHCP提供报文(DHCP offer message)向客户做出响应，使用广播地址为目的IP，使用本机IP为源IP。 这个报文里包含有收到的发现报文的事物ID、向客户推荐的IP地址。网络掩码以及IP地址租用期(address lease time). 服务器租用期通常设置为几小时或几天。</li></ul></li><li>DHCP请求<ul><li>从一个或多个服务器提供中选择一个，并向选中的服务器提供用DHCP请求报文(DHCP request message)进行响应，回显配置的参数。这一步中仍用广播地址为目的IP，使用0.0.0.0位源IP</li></ul></li><li>DHCP ACK<ul><li>服务器用DHCP ACK报文(DHCP ACK message) 对DHCP请求报文进行响应。 仍然是广播消息。</li></ul></li></ol><p>DHCP协议的所有消息都是广播消息。</p><p>从移动性角度看，DHCP确实有非常严重的缺陷。因为每到一个新的子网，就会获取一个新的IP地址。</p><h4 id="4-3-4-网络地址转换-Network-Address-Translation-NAT"><a href="#4-3-4-网络地址转换-Network-Address-Translation-NAT" class="headerlink" title="4.3.4 网络地址转换(Network Address Translation, NAT)"></a>4.3.4 网络地址转换(Network Address Translation, NAT)</h4><p>NAT转换表(NAT translation table)</p><h4 id="4-3-5-IPv6"><a href="#4-3-5-IPv6" class="headerlink" title="4.3.5 IPv6"></a>4.3.5 IPv6</h4><p>IPv6有已下特性</p><ul><li>IPv6将IP地址长度从32比特增加到128比特。还引入了任播地址(anycast address)的新型地址，这种地址可以使数据报交付给一组主机中的任意一个。(例如，这种特性可用于向一组包含特定文档的镜像站点中的最近一个发送HTTP GET报文)。</li><li>简化高效的40字节首部</li><li>流标签</li></ul><p>IPv6的一些字段：</p><ul><li>版本(4比特)：设置为6</li><li>流量类型(8比特)：与我们在iPv4中看到的TOS字段的含义类似</li><li>流标签(20比特)：标识一条数据报的流，能够对一条流中的某些数据报给出优先权</li><li>有效载荷长度(16比特)</li><li>下一个首部(8比特)：标识数据报中的内容需要交付给哪个协议，跟IPv4首部字段中协议字段的值一样</li><li>跳限制(8比特)：类似于TTL</li><li>源地址和目标地址(各128比特)</li><li>数据</li></ul><p>在IPv4数据报中没有的部分：</p><ul><li>分片/重新组装</li><li>首部检验和</li><li>选项</li></ul><p>在实践中已经得到广泛采用的IPv4到IPv6迁移的方法包括建隧道(tunneling)</p><h3 id="4-4-通用转发和SDN"><a href="#4-4-通用转发和SDN" class="headerlink" title="4.4 通用转发和SDN"></a>4.4 通用转发和SDN</h3><p>通用转发：每台分组交换机包含一张匹配加动作表，该表示由远程控制器计算和分发的</p><h2 id="第五章：网络层：控制平面"><a href="#第五章：网络层：控制平面" class="headerlink" title="第五章：网络层：控制平面"></a>第五章：网络层：控制平面</h2><h3 id="5-1-概述"><a href="#5-1-概述" class="headerlink" title="5.1 概述"></a>5.1 概述</h3><p>完成转发表和流表的计算和维护有两种方法：</p><ol><li>每路由器控制：每台路由器内运行这一种路由选择算法</li><li>逻辑集中式控制：由逻辑集中式路由选择控制器计算并分发转发表给每台路由器。路由器主要负责和其通信即可，获取转发表。</li></ol><h3 id="5-2-路由选择算法"><a href="#5-2-路由选择算法" class="headerlink" title="5.2 路由选择算法"></a>5.2 路由选择算法</h3><p>其目的是从发送方到接收方的过程中确定一条通过路由器网络好的路径。这里的好可能是具有最低开销的，也有策略上的考量(比如某ISP不转发另一ISP的流量)</p><p>我们对路由选择算法有三种分类方式：</p><ol><li>根据该算法是集中式还是分散式：<ul><li>集中式路由选择算法(centralized routing algorithm): 指需要关于网络的完整的、全局性的知识。具有全局状态信息的算法常被称作链路状态(Link State, LS)算法。</li><li>分散式路由选择算法(decentralized routing algorithm): 没有节点拥有关于所有网络链路开销的完整信息。</li></ul></li><li>根据算法是静态的还是动态的：<ul><li>静态路由选择算法(static route algorithm): 路由随时间变化缓慢，通常可以人工进行调整。</li><li>动态路由选择算法(dynamic routing algorithm): 可周期性地运行或直接响应拓扑或链路开销的变化而运行。但也容易受路由选择循环、路由震荡之类问题的影响。</li></ul></li><li>根据它是负载敏感的还是负载迟钝的：<ul><li>负载敏感算法(load-sensitive algorithm): 链路开销会动态地变化以反映出底层链路的当前拥塞水平。</li><li>负载迟钝的(load-insensitive): 当今的因特网路由选择算法都是负载迟钝的。</li></ul></li></ol><h4 id="5-2-1-链路状态路由选择算法"><a href="#5-2-1-链路状态路由选择算法" class="headerlink" title="5.2.1 链路状态路由选择算法"></a>5.2.1 链路状态路由选择算法</h4><p>可以用Dijkstra算法。</p><h4 id="5-2-2-距离向量路由算法"><a href="#5-2-2-距离向量路由算法" class="headerlink" title="5.2.2 距离向量路由算法"></a>5.2.2 距离向量路由算法</h4><p>距离向量(Distance-Vector, DV)算法是一种迭代的、异步的和分布式的算法。</p><p>一旦更新，向邻居发送更新后的。</p><p>毒性逆转(poisoned reverse)：如果$z$通过$y$路由选择到目的地$x$，则$z$将通告$y$,它$z$到$x$的距离是无穷大。涉及3个或更多节点(而不只是两个直接相连的邻居节点)的环路将无法用毒性逆转技术检测到。</p><p>LS和DV路由选择算法的比较：</p><ul><li>报文复杂性：LS算法需要发送$O(|N||E|)$个报文。 DV则在每次迭代时，在两个直接相连邻居之间交换报文。</li><li>收敛速度：LS是一个$O(|N|^2)$的算法。DV算法收敛较慢，且在收敛时遇到路由选择环路，DV算法还会遭遇无穷计数问题。</li><li>健壮性：LS算法有一定程度的健壮性。DV算法中一个不正确的节点计算值会扩展到整个网络。</li></ul><h3 id="5-3-因特网中自治系统内部的路由选择：OSPF"><a href="#5-3-因特网中自治系统内部的路由选择：OSPF" class="headerlink" title="5.3 因特网中自治系统内部的路由选择：OSPF"></a>5.3 因特网中自治系统内部的路由选择：OSPF</h3><p>自治的原因：规模和管理自治</p><p>一个自治系统由其全局唯一的AS号(ASN)所标识，就像IP地址那样，AS号由ICANN区域注册机构所分配。</p><p>在相同AS中的路由器都运行着相同的路由选择算法并且有彼此的信息。在一个自治系统内运行的路由选择算法叫做自治系统内部路由选择协议(intra-autonomous system routing protocol).</p><p>开放最短路优先(OSPF): OSPF路由选择及其关系密切的协议IS-IS都被广泛用于因特网的AS内部路由选择。</p><p>OSPF是一种链路状态协议，它是用洪泛链路状态信息和Dijkstra最低开销路径算法。</p><p>使用OSPF，一台路由器构建了一幅关于整个自治系统的完整拓扑图。于是，每台路由器在本地运行Dijkstra的最短路径算法，以确定一个以自身为根节点到所有子网的最短路径树。</p><p>当链路状态发生变化时，路由器就会广播链路状态信息，即使为发生变换，也会周期性地广播链路状态。链路状态通告的这种周期性更新增加了链路状态算法的健壮性。</p><p>OSPF的通告包含在OSPF报文中，由IP承载，对OSPF其上层协议的值是89。</p><p>OSPF的优点：</p><ul><li>安全</li><li>多条相同开销的路径：当到达某目的地的多条路径具有相同的开销时，OSPF允许使用多条路径。</li><li>对单播与多播路由选择的综合支持</li><li>支持在单个AS中的层次结构：一个OSPF自治系统能够层次化地配置多个区域。每个区域都运行自己的OSPF链路状态路由选择算法。</li></ul><h3 id="5-4-ISP之间的路由选择：BGP"><a href="#5-4-ISP之间的路由选择：BGP" class="headerlink" title="5.4 ISP之间的路由选择：BGP"></a>5.4 ISP之间的路由选择：BGP</h3><p>自治系统间路由选择协议(inter-autonomous system routing protocol). 边界网关协议(Broder Gateway Protocol, BGP)</p><p>正是这个协议将因特网中数以千计的ISP黏合起来。</p><p>BGP是一种分布式和异步的协议</p><h4 id="5-4-1-BGP的作用"><a href="#5-4-1-BGP的作用" class="headerlink" title="5.4.1 BGP的作用"></a>5.4.1 BGP的作用</h4><ol><li>从邻居AS获得前缀的可达性信息。BGP允许每个子网向因特网的其余部分通告它的存在。BGP确保在因特网中的所有AS知道该子网。</li><li>确定到该前缀的”最好的”路由</li></ol><h4 id="5-4-2-通告BGP路由信息"><a href="#5-4-2-通告BGP路由信息" class="headerlink" title="5.4.2 通告BGP路由信息"></a>5.4.2 通告BGP路由信息</h4><p>对于每个AS，每台路由器要么是一台网关路由器(gateway router), 要么是一台内部路由器(internal router). </p><p>在BGP中，每对路由器通过使用179端口的半永久TCP连接交换路由选择信息。每条直连连接以及所有通过该连接发送的BGP报文，称为BGP连接(BGP connection). 跨越两个AS的BGP连接称为外部BGP(eBGP)连接，而在相同AS中的两台路由器之间的BGP会话称为内部BGP(iBGP)连接。</p><h4 id="5-4-3-确定最好的路由"><a href="#5-4-3-确定最好的路由" class="headerlink" title="5.4.3 确定最好的路由"></a>5.4.3 确定最好的路由</h4><p>一些术语：当路由器通过BGP连接通告前缀时，它在前缀中包括一些BGP属性(BGP attribute). 用BGP路由来说，前缀及其属性称为路由(route).  两个较为重要的属性是AS-PATH和NEXT-HOP。 AS-PATH属性包含了通告已经通过的AS列表。如果一台路由器在路径列表中看到包含了它自己的AS，它将拒绝该通告。NEXT-HOP是AS-PATH起始的路由器接口的IP地址</p><p>热土豆路由选择</p><p>在路由器转发表中增加AS外部目的地的步骤：</p><ol><li>从AS间协议学到经多个网关可达子网x</li><li>使用来自AS内部协议的路由选择信息，以决定到达每个网关的最低开销路径的开销</li><li>热土豆路由选择：选择具有最小最低开销的网关</li><li>从转发表确定通往最低开销网关的接口$I$。在转发表中加入表项$(x,I)$ </li></ol><p>热土豆路由选择依据的思想是：对于路由器1b，尽可能快地将分组送出其AS(更明确地说，用可能的最低开销)，而不担心其AS外部到目的地的余下部分的开销。</p><p>路由选择算法</p><p>在实践中，BGP使用了一种比热土豆路由选择更为复杂但却结合了其特点的算法。对于任何给定的目的地前缀，进入BGP的路由选择算法的输入是到某前缀的所有路由的集合，该前缀是已被路由器学习和接收的。如果仅有一条这样的路由，BGP显然选择该路由。如果到相同的前缀有两条或多条路由，则顺序地调用下列消除规则直到余下一条路由：</p><ol><li>路由被指派一个本地偏好值作为其属性之一(除了AS-PATH和NEXT-HOP以外)。一条路由的本地偏好可能由该路由器设置或可能由在相同AS中的另一台路由器学习到。本地偏好属性的值是一种策略决定，它完全取决于该AS的网络管理员。具有最高本地偏好值的路由将被选择。</li><li>从余下的路由中(所有具有相同的最高本地偏好值)，将选择具有最短AS-PATH的路由。如果该规则是路由选择的唯一规则，则BGP将使用距离向量算法决定路径，其中距离测度使用AS跳的跳数而不是路由器跳的跳数。</li><li>从余下的路由中(所有都具有相同的最高本地偏好值和相同的AS-PATH长度)，使用热土豆路由选择，即选择具有最靠近NEXT-HOP路由器的路由。</li><li>如果仍留下多条路由，该路由器使用BGP标识符来选择路由。</li></ol><h4 id="5-4-4-IP任播"><a href="#5-4-4-IP任播" class="headerlink" title="5.4.4 IP任播"></a>5.4.4 IP任播</h4><p>多台服务器使用相同的IP地址，由BGP路由来选择某一服务器。CDN一般不使用IP任播，而DNS一般使用IP任播。</p><h4 id="5-4-5-路由选择策略"><a href="#5-4-5-路由选择策略" class="headerlink" title="5.4.5 路由选择策略"></a>5.4.5 路由选择策略</h4><p>任何穿越某ISP主干网的流量必须是其源或目的位于该ISP的某个客户网络中。</p><h3 id="5-5-SDN控制平面"><a href="#5-5-SDN控制平面" class="headerlink" title="5.5 SDN控制平面"></a>5.5 SDN控制平面</h3><h3 id="5-6-ICMP-因特网控制报文协议"><a href="#5-6-ICMP-因特网控制报文协议" class="headerlink" title="5.6 ICMP:因特网控制报文协议"></a>5.6 ICMP:因特网控制报文协议</h3><p>ICMP最典型的用途是差错报告。</p><p>ping和traceroute就是用ICMP实现的</p><h3 id="5-7-网络管理和SNMP"><a href="#5-7-网络管理和SNMP" class="headerlink" title="5.7 网络管理和SNMP"></a>5.7 网络管理和SNMP</h3><h2 id="第六章：链路层和局域网"><a href="#第六章：链路层和局域网" class="headerlink" title="第六章：链路层和局域网"></a>第六章：链路层和局域网</h2><h3 id="6-1-链路层概述"><a href="#6-1-链路层概述" class="headerlink" title="6.1 链路层概述"></a>6.1 链路层概述</h3><h3 id="6-1-1-链路层提供的服务"><a href="#6-1-1-链路层提供的服务" class="headerlink" title="6.1.1 链路层提供的服务"></a>6.1.1 链路层提供的服务</h3><p>任一链路层的基本服务都是将数据报通过单一通信链路从一个节点移动到相邻节点。</p><p>链路层协议能够提供的可能服务包括：</p><ul><li>成帧(framing)</li><li>链路接入：媒体访问控制(Medium Access Control, MAC)协议规定了帧在链路上传输的规则</li><li>可靠交付：当链路层协议提供可靠交付服务时，它保证无差错地经链路层移动每个网络层数据报。链路层的可靠交付服务通常是通过确认和重传取得的。链路层可靠交付服务通常用于易于产生高差错率的链路，例如无线链路。许多有线的链路层协议不提供可靠交付服务。</li><li>差错检测和纠正：</li></ul><h4 id="6-1-2-链路层在何处实现"><a href="#6-1-2-链路层在何处实现" class="headerlink" title="6.1.2 链路层在何处实现"></a>6.1.2 链路层在何处实现</h4><p>链路层的主体部分是在网络适配器(network adapter)中实现。位于网络适配器核心的是链路层控制器。尽管大部分链路层是在硬件中实现的，但部分链路层是在运行于主机CPU上的软件中实现的。链路层的软件组件实现了高层链路层功能，如组装链路层寻址信息和激活控制器硬件。</p><h3 id="6-2-差错检测和纠正技术"><a href="#6-2-差错检测和纠正技术" class="headerlink" title="6.2 差错检测和纠正技术"></a>6.2 差错检测和纠正技术</h3><p>三种技术：奇偶校验、检验和方法 和 循环冗余检测。</p><h4 id="6-2-1-奇偶校验"><a href="#6-2-1-奇偶校验" class="headerlink" title="6.2.1 奇偶校验"></a>6.2.1 奇偶校验</h4><p>二维奇偶校验</p><p>接收方检测和纠正差错的能力被称为前向纠错。</p><h4 id="6-2-2-检验和方法"><a href="#6-2-2-检验和方法" class="headerlink" title="6.2.2 检验和方法"></a>6.2.2 检验和方法</h4><p>运输层使用检验和，链路层使用CRC。why?</p><p>因为运输层差错检测用软件实现，采用简单而快速如检验和这样的差错检测方案是重要的。在另一方面，链路层的差错检测在适配器中用专门的硬件实现，它能够快速执行更复杂的CRC操作。</p><h4 id="6-2-3-循环冗余检测"><a href="#6-2-3-循环冗余检测" class="headerlink" title="6.2.3 循环冗余检测"></a>6.2.3 循环冗余检测</h4><p>现今的计算机网络中广泛应用的差错检测技术基于循环冗余检测(Cyclic Redundancy Check, CRC)编码。CRC编码也称为多项式编码(polynomial code).</p><p>每个CRC标准都能检测小于$r+1$比特的突发差错。(这意味着所有连续的$r$比特或者更少的差错都可以检测到。)此外，在适当的假设下，长度大于$r+1$比特的突发差错以概率$1-0.5^r$被检测到。每个CRC标准也都能检测任何奇数个比特差错。</p><h3 id="6-3-多路访问链路和协议"><a href="#6-3-多路访问链路和协议" class="headerlink" title="6.3 多路访问链路和协议"></a>6.3 多路访问链路和协议</h3><p>有两种类型的网络链路：</p><ul><li>点对点链路：PPP,HDLC</li><li>广播链路：以太网、WiFi</li></ul><p>一个对链路层很重要的问题：如何协调多个发送和接收节点对一个共享广播信道的访问，这就是多路访问问题(multiple access problem).</p><p>多路访问协议(multiple access protocol).我们能够将任何多路访问协议分为3种类型之一：</p><ul><li>信道划分协议(channel partitioning protocol)<ul><li>FDM,TDM,CDMA</li></ul></li><li>随机接入协议(random access protocol)<ul><li>时隙ALOHA(以概率p重传)，需要在节点间对时隙同步</li><li>ALOHA，不需要时隙同步</li><li>载波侦听多路访问(CSMA)<ul><li>载波侦听(carrier sensing)</li><li>碰撞检测(collision detection): CSMA/CD</li><li>二进制指数后退(binary exponential backoff)算法</li><li>CSMA/CD效率:<ul><li>$\frac{1}{1+ 5 d<em>{prop}/d</em>{trans}}$</li><li>$d_{prop}$ 表示信号能量在任意两个适配器之间传播所需的最大时间</li><li>$d_{trans}$ 表示传输一个最大长度的以太网帧的时间</li></ul></li></ul></li></ul></li><li>轮流协议(taking-turns protocol)<ul><li>轮询协议(taking-turns protocol)</li><li>令牌传递协议(token-passing protocol)</li></ul></li></ul><p>我们希望多路访问协议应该具有下列所希望的特性：</p><ol><li>当仅有一个节点发送数据时，该节点具有$R$ bps的吞吐量</li><li>当有$M$个节点发送数据时，每个节点吞吐量为$R/M $ bps. 这不必要求$M$个节点中的每一个节点总是有$R/M$的瞬间速率，而是每个节点在一些适当定义的时间间隔内应该有$R/M$的平均传输速率。</li><li>协议是分散的；这就是说不会因某主节点故障而使整个系统崩溃</li><li>协议是简单的，使实现不昂贵</li></ol><h4 id="6-3-1-信道划分协议"><a href="#6-3-1-信道划分协议" class="headerlink" title="6.3.1 信道划分协议"></a>6.3.1 信道划分协议</h4><p>FDM,TDM,CDMA</p><h4 id="6-3-2-随机接入协议"><a href="#6-3-2-随机接入协议" class="headerlink" title="6.3.2 随机接入协议"></a>6.3.2 随机接入协议</h4><ol><li>时隙ALOHA<ul><li>同步的，有一系列的时隙，只在时隙开始时传送，且在某一时隙发生碰撞，在该时隙结束前能检测到</li><li>当一个节点有新的帧发送，它将在下一个时隙的开始进行传输</li><li>如果没有检测到碰撞，则成功</li><li>如果有碰撞，该节点以概率$p$在后续的每个时隙中重传它的帧，直到该帧被无碰撞地传输出去。</li><li>成功的概率： $Np(1-p)^{N-1}$, 最大效率为$\frac{1}{e}$, 即0.37 </li></ul></li><li>ALOHA<ul><li>不需要同步</li><li>成功的概率：$Np(1-p)^{2(N-1)}$, 最大效率为$\frac{1}{2e}$ </li></ul></li><li>载波侦听多路访问(CSMA)<ul><li>两个重要规则：<ul><li>说话之前先听： 载波侦听(carrier sensing)</li><li>如果与他人同时开始说话，停止说话：碰撞检测(collision detection)</li></ul></li><li>既然侦听了，又怎么会碰撞呢？：因为有广播信道端到端信道传播时延(channel propagation delay). 该传播时延越大，载波侦听节点不能侦听到网络中另一个节点已经开始传输的机会就越大。</li><li>CSMA不包含碰撞检测</li></ul></li><li>具有碰撞检测的载波侦听多路访问(CSMA/CD)<ul><li>协议步骤：<ol><li>适配器从网络层一条获得数据报，准备链路层帧，并将其放入帧适配器缓存中。</li><li>如果适配器侦听到信道空闲(即无信号能量从信道进入适配器)，它开始传输帧。在另一方面，如果适配器侦听到信道正在忙，它将等待，直到侦听到没有信号能量时才开始传输帧。</li><li>在传输过程中，适配器监视来自其他使用该广播信道的适配器的信号能量的存在。</li><li>如果适配器传输整个帧而未检测到来自其他适配器的信号能量，该适配器就完成了该帧。在另一方面，如果适配器在传输时检测到来自其他适配器的信号能量，它中止传输(即它停止了传输帧)。<strong>帧长得有下限</strong>， 不然在碰撞可能在传输结束后发送。</li><li>中止传输后，适配器等待一个随机时间量，然后返回步骤2</li></ol></li><li>随机等待的时间量不能一样的，不然一直碰撞。我们采用二进制指数后退算法(binary exponential backoff)。<ul><li>当传输一个给定帧时，在该帧经历了一连串的$n$次碰撞后，节点随机地从${ 0,1,2,…,2^n-1 }$ 中选择一个$K$值。因此一个帧经历的碰撞越多，$K$选择的间隔越大。对于以太网，一个节点等待的实际时间量是$K \cdot 512$ 比特时间(即发送512比特进入以太网所需时间量的$K$倍)， $n$能够取的最大值在$10$以内。</li></ul></li></ul></li><li>CSMA/CD 效率<ul><li>$d_{prop}$ 表示信号能量在任意两个适配器之间传播所需的最大时间</li><li>$d_{trans}$ 表示传输一个最大长度的以太网帧的时间</li><li>效率 =$\frac{1}{1+ 5 d<em>{prop}/d</em>{trans} }$ </li><li>当$d_{prop}$ 接近$0$时，效率接近1</li><li>当$d_{trans}$变得很大时，效率也接近于1</li></ul></li></ol><h4 id="6-3-3-轮流协议-taking-turns-protocol"><a href="#6-3-3-轮流协议-taking-turns-protocol" class="headerlink" title="6.3.3 轮流协议(taking-turns protocol)"></a>6.3.3 轮流协议(taking-turns protocol)</h4><p>两种：</p><ul><li>轮询协议(polling protocol)<ul><li>引入了轮询时延</li><li>主节点的单点故障</li><li>主要应用：802.15协议和蓝牙协议</li></ul></li><li>令牌传递协议(token-passing protocol)<ul><li>一个节点的故障可能会使整个信道崩溃</li><li>或者一个节点忘记了释放令牌</li></ul></li></ul><h3 id="6-4-交换局域网"><a href="#6-4-交换局域网" class="headerlink" title="6.4 交换局域网"></a>6.4 交换局域网</h3><h4 id="6-4-1-链路层寻址和ARP"><a href="#6-4-1-链路层寻址和ARP" class="headerlink" title="6.4.1 链路层寻址和ARP:"></a>6.4.1 链路层寻址和ARP:</h4><ul><li>MAC地址：6字节<ul><li>MAC地址是扁平结构，而IP地址是层次结构</li><li>广播地址是:<code>FF-FF-FF-FF-FF-FF</code> </li></ul></li><li>地址解析协议(Address Resolution Protocol, ARP)<ul><li>将网络层地址和链路层地址进行互相转换</li><li>与DNS类似，但不同的是ARP只为在同一个子网上的主机和路由器解析IP地址，而DNS为在因特网中任何地方的主机解析主机名</li><li>每台主机或路由器在其内存中具有一个ARP表，有IP地址和MAC地址的映射，还有TTL</li><li>ARP查询，构造一个ARP分组，通过广播帧发送，回应通过普通帧发送</li></ul></li></ul><h4 id="6-4-2-以太网："><a href="#6-4-2-以太网：" class="headerlink" title="6.4.2 以太网："></a>6.4.2 以太网：</h4><ul><li>集线器(hub):是一种物理层设备，它作用于各个比特而不是作用于帧。当一个比特到达接口后，集线器只是重新生成这个比特，放大它的能量强度，将其向其他所有接口发送出去。</li><li>以太网帧格式： <code>前同步码(8字节)|目的地址(6字节)|源地址(6字节)|类型(2字节)|数据(46-1500字节)|CRC(4字节)</code><ul><li>前同步码中前7个字节的值都是10101010；最后一个字节是10101011, 为了同步时钟，</li></ul></li><li>所有的以太网技术都向网络层提供无连接的服务</li><li>以太网技术都向网络层提供不可靠服务。无论CRC校验是否正确，都不回应。</li><li>在基于交换机的以太局域网中，不会有碰撞，因此没有必要使用MAC协议了。</li></ul><h4 id="6-4-3-链路层交换机"><a href="#6-4-3-链路层交换机" class="headerlink" title="6.4.3 链路层交换机"></a>6.4.3 链路层交换机</h4><ol><li>交换机转发和过滤<ul><li>过滤是决定一个帧应该转发到某个接口还是应当将其丢弃的交换机功能。</li><li>转发是决定一个帧应该被导向哪个接口，并把该帧移动到那些接口的交换机功能。</li><li>交换机的过滤和转发借助于交换机表(switch table), 表项中包含：MAC地址，通过该MAC地址的交换机接口</li><li>表项放置在表中的时间</li><li>当有一个帧从接口$x$进来，目的地址为$A$<ul><li>如果表中没有$A$的表项，向除了接口$x$的接口转发该帧</li><li>如果表中$A$对应接口$x$, 丢弃该帧</li><li>如果表中$A$对应接口$y \not= x$, 转发该帧到接口$y$ </li></ul></li></ul></li><li>自学习<ul><li>步骤如下：<ol><li>交换表初始为空</li><li>对于在每个接口接收到的每个入帧，该交换机在其表中存储：源MAC地址，到达的接口，当前时间</li><li>如果在一段时间(称为老化期(aging time))后，交换机没有接受到以该地址作为源地址的帧，就在表中删除这个地址。</li></ol></li><li>交换机是即插即用设备(plug-and-play device) </li></ul></li><li>链路层交换机的性质<ul><li>消除碰撞</li><li>异质的链路</li><li>管理</li><li>延伸知识：交换机毒化(switch poisoning). 它向交换机发送大量的具有不同伪造源MAC地址的分组，因为用伪造表项填满了交换机表，没有为合法主机留下空间。这使该交换机广播大多数帧，这些帧能够由嗅探器俘获到。由于这种攻击只有技艺高超的攻击者才能做到，因此交换机比起集线器和无线局域网来更难受到嗅探</li></ul></li><li>交换机和路由器比较</li></ol><p>交换和路由的区别 </p><p>交换功能 $\begin{cases} \text{主机为单位} \ \text{网段为单位} \end{cases}$</p><p>交换：交换表。 </p><p>不选最短路——支撑树算法</p><ol><li>帧转发——目的MAC</li><li>地址学习——源MAC</li><li>环路检测——</li></ol><p>链路层交换机</p><ul><li>交换机转发和过滤<ul><li>过滤(filtering)是决定一个帧应该转发到某个接口还是应当将其丢弃的交换机功能</li><li>转发(forwarding)是决定一个帧应该被导向哪个接口，并把该帧移动到那些接口的交换机功能。</li><li>交换机的过滤和转发借助于交换机表(switch table). 交换机表包括MAC地址，相应的交换机接口和时间戳</li></ul></li><li>自学习<pre><code>1. 交换表最初为空 2. 每个收到的帧，记录其源MAC地址和接口还有时间戳 3. 一段时间后，会删除该地址(aging time)老化期</code></pre></li><li>交换机是即插即用设备(plug-and-play device)</li><li>性质<ul><li>消除碰撞</li><li>异质的链路</li><li>管理</li></ul></li><li>交换机毒化<ul><li>向交换机发送大量具有不同伪造源MAC地址的分组，填满交换机的表项，没有为合法主机留下空间，使得交换机不得不广播帧，从而能嗅探。</li></ul></li><li>交换机是第二层的分组交换机</li><li>路由器是第三层的分组交换机</li></ul><h4 id="6-4-4-虚拟局域网"><a href="#6-4-4-虚拟局域网" class="headerlink" title="6.4.4 虚拟局域网"></a>6.4.4 虚拟局域网</h4><p>等级交换结构的缺点：</p><ul><li>缺乏流量隔离：尽管该等级结构把组流量局域化到一个单一交换机中，但广播流量(例如携带ARP和DHCP报文或那些目的地还没有被自学习交换机学习到的帧)仍然必须跨越整个机构网络</li><li>交换机的无效使用：每个组都比较小，交换机得不到充分的利用</li><li>管理用户</li></ul><p>我们可以通过支持虚拟局域网(Virtual Local Network, VLAN)的交换机来处理。支持VLAN的交换机允许经一个单一的物理局域网基础设施定义多个虚拟局域网。在一个基于端口的VLAN中，交换机的端口(接口)由网络管理员划分为组。每个组构成一个VLAN，在每个VLAN中的端口形成一个广播域。</p><h3 id="6-5-链路虚拟化：网络作为链路层"><a href="#6-5-链路虚拟化：网络作为链路层" class="headerlink" title="6.5 链路虚拟化：网络作为链路层"></a>6.5 链路虚拟化：网络作为链路层</h3><h3 id="6-6-数据中心网络"><a href="#6-6-数据中心网络" class="headerlink" title="6.6 数据中心网络"></a>6.6 数据中心网络</h3><ul><li>机架顶部(Top of Rack, TOR)交换机</li><li>负载均衡<ul><li>负载均衡器(load balancer)</li><li>“第四层交换机”</li><li>还提供类似NAT的功能</li></ul></li><li>等级体系结构<ul><li>路由器和交换机等级结构(hierarchy of router and switch)</li></ul></li><li>数据中心网络的发展趋势<ul><li>一个趋势是部署能够克服传统等级设计缺陷的新型互联体系结构和网络协议<ul><li>一种方法是采用全连接拓扑(fully connected topology)来替代交换机和路由器的等级结构</li></ul></li><li>另一个主要的趋势是采用基于船运集装箱的模块化数据中心(Modular Data Center, MDC)</li><li>另一种重要趋势是，大型云提供商正在其数据中心越来越多地建造或定制几乎所有东西，包括网络适配器。交换机路由器、TOR、软件和网络协议。</li></ul></li></ul><h3 id="6-7-Web页面请求的历程"><a href="#6-7-Web页面请求的历程" class="headerlink" title="6.7 Web页面请求的历程"></a>6.7 Web页面请求的历程</h3><h2 id="第七章：无线网络和移动网络"><a href="#第七章：无线网络和移动网络" class="headerlink" title="第七章：无线网络和移动网络"></a>第七章：无线网络和移动网络</h2><h3 id="7-1-概述"><a href="#7-1-概述" class="headerlink" title="7.1 概述"></a>7.1 概述</h3><p>无线网络分类：</p><ul><li>单跳，基于基础设施<ul><li>WiFi, 4G</li></ul></li><li>单跳，无基础设施<ul><li>蓝牙</li></ul></li><li>多跳，基于基础设施</li><li>多跳，无基础设施</li></ul><h3 id="7-2-无线链路和网络特征"><a href="#7-2-无线链路和网络特征" class="headerlink" title="7.2 无线链路和网络特征"></a>7.2 无线链路和网络特征</h3><p>无线链路与有线链路的区别：</p><ul><li>递减的信号强度</li><li>来自其他源的干扰</li><li>多径传播</li></ul><p>无线链路协议不仅采用有效的CRC错误检测码，还采用了链路层ARQ协议来重传受损的帧。</p><p>信噪比(Signal-to-Noise Ratio, SNR), 比特差错率(BER)</p><p>$SNR = 10 \log<em>{10} (\frac{P</em>{signal}}{P_{noise}})$ </p><ul><li>对于给定的调制方案，SNR越高，BER越低</li><li>对于给定的SNR，具有较高比特传输率的调制技术(无论差错与否)将具有较高的BER</li><li>物理层调制技术的动态选择能用于适配对信道条件的调制技术。</li></ul><p>隐藏终端问题(hidden terminal problem)： 即使A和C的传输确实是在目的地B发生干扰，环境的物理阻挡(例如，一座大山或者一座建筑)也可能会妨碍A和C互相听到对方的传输。</p><p>衰减可能也会导致无法检测碰撞。</p><h3 id="CDMA"><a href="#CDMA" class="headerlink" title="CDMA"></a>CDMA</h3><h3 id="7-3-WiFi-802-11-无线LAN"><a href="#7-3-WiFi-802-11-无线LAN" class="headerlink" title="7.3 WiFi: 802.11 无线LAN"></a>7.3 WiFi: 802.11 无线LAN</h3><p>802.11有好几个标准，它们都使用了相同的媒体访问协议CSMA/CA. 它们的链路层帧也都使用相同的帧结构</p><p>802.11设备工作在两个不同的频段上：2.4~2.485GHz(2.4GHz频段)和5.1~5.8GHz(称之为5GHz频段)。</p><h4 id="802-11体系结构"><a href="#802-11体系结构" class="headerlink" title="802.11体系结构"></a>802.11体系结构</h4><p>基本服务集(Basic Service Set, BSS)：一个BSS包含一个或多个无线站点和一个被称为接入点(Access Point, AP)的中央基站(base station).</p><p>配置AP的无线LAN经常被称作基础设施无线LAN(infrastructure wireless LAN). 其中基础设置是指AP连同互联AP和一台路由器的有线以太网。</p><p>信道与关联</p><ul><li>每个无线站点在能够发送或者接受网络层数据之前，必须与一个AP相关联</li><li>当管理员安装一个AP时，需要给接入点分配一个单字或双字的服务集标识符(Service Set Identifier, SSID). 管理员还必须为该AP分配一个信道号。SSID就是常用的WiFi名称，而BSSID是无线AP的MAC地址。</li><li>802.11定义了11个部分重叠的信道。当且仅当两个信道由4个或更多信道隔开时它们才无重叠。</li><li>WiFi丛林(WiFi jungle)是一个任意物理位置，在这里无线站点能从两个或多个AP中收到很强的信号。</li><li>802.11标准要求每个AP周期性地发送信标帧(beacon frame).每个信标帧包含了该AP的SSID和MAC地址。你的终端会扫描十一个信道以获取信标帧</li><li>扫描信道和监听信标帧的过程被称为被动扫描(passive scanning) 无线主机也能执行主动扫描(active scanning). 这是通过向位于无线主机范围内的所有AP广播探测帧完成的。</li><li>选定与之关联的AP后，无线主机向AP发送一个关联请求帧，并且该AP以一个关联响应帧进行响应。一旦与一个AP关联，该主机希望加入该AP所属的子网中。因此，该主机通常将通过关联的AP向该子网发送一个DHCP发现报文，以获取在该AP子网中的一个IP地址。一旦获得地址，网络的其他部分将直接视你为该子网中的另一台主机。</li><li>802.11无线LAN提供了几种不同的鉴别和接入方法。一种被许多公司采用的方法是，基于一个站点的MAC地址允许其接入一个无线网络。第二种，用用户名和口令。在两种情况下，AP通常与一个鉴别服务器进行通信。分离鉴别服务器和AP，使得一个鉴别服务器可以服务于多个AP。</li></ul><h4 id="7-3-2-802-11-MAC协议"><a href="#7-3-2-802-11-MAC协议" class="headerlink" title="7.3.2 802.11 MAC协议"></a>7.3.2 802.11 MAC协议</h4><p>802.11的设计者为802.11无线LAN选择了一种随机访问协议：带碰撞避免的CSMA(CSMA with collision avoidance),或简称为CSMA/CA</p><p>以太网和802.11虽然都使用载波侦听随机接入，但他们有区别：</p><ol><li>802.11使用碰撞避免而非碰撞检测</li><li>802.11使用链路层确认/重传(ARQ)方案</li></ol><p>802.11MAC协议使用碰撞避免而非碰撞检测。主要有两个原因</p><ul><li>检测碰撞的能力要求站点具有同时发送和接收的能力。</li><li>由于隐藏终端问题和衰减问题而无法检测到所有的碰撞。</li></ul><p>一旦一个站点开始发送一个帧，它就完全地发送该帧。</p><p>链路层确认方案(link-layer acknowledgment):目的站点收到一个通过CRC检验的帧后，它等待一个被称作短帧间间隔(Short Inter-Frame Spacing, SIFS)的一小段时间，然后发回一个确认帧。如果发送站点在给定的时间内未收到确认帧，它假定出现了错误并重传该帧，使用CSMA/CA协议访问该信道。如果在若干固定次重传后仍未收到确认，发送站点将放弃发送并丢弃该帧。</p><p>CSMA/CA协议：</p><ol><li>如果某站点最初监听到信道空闲，它将在一个被称作分布式帧间间隔(Distributed Inter-Frame Space, DIFS)的短时间段后发送该帧。</li><li>否则，该站点选取一个随机回退值并且在侦听信道空闲时递减该值。当侦听到信道忙时，计数值保持不变。</li><li>当计数值减为0时，该站点发送整个数据帧并等待确认。</li><li>如果收到确认，发送站点知道它的帧已被目的站正确接受了。如果该站点要发送另一帧，它将从第二步开始CSMA/CA协议。如果未收到确认，发送站点将重新进入第二步中的回退阶段，并从一个更大范围内选取随机值。</li></ol><p>IEEE 802.11协议允许站点使用一个短请求发送(Request to Send, RTS)控制帧和一个短允许发送(Clear to Send, CTS)控制帧来预约对信道的访问。尽管RTS/CTS交换有助于降低碰撞，但它同样引入了时延以及消耗了信道资源。因此RTS/CTS交换仅仅用于为长数据预约信道。在实际中，每个无线站点可以设置一个RTS门限值，仅当帧长超过门限值时，才使用RTS/CTS序列。对许多无线站点而言，默认的RTS门限值大于最大帧长值，因此对所有发送的DATA帧，RTS/CTS序列都被跳过。 </p><p>可以使用802.11 作为一个点对点链路。</p><h4 id="7-3-3-IEEE-802-11帧"><a href="#7-3-3-IEEE-802-11帧" class="headerlink" title="7.3.3 IEEE 802.11帧"></a>7.3.3 IEEE 802.11帧</h4><ol><li>有效载荷与CRC字段<ul><li>有限载荷允许的最大长度为2312字节，但它通常小于1500字节</li></ul></li><li>地址字段<ul><li>802.11帧中有4个地址字段，每个都可以包括一个6字节的MAC地址<ul><li>地址2是传输该帧站点的MAC地址。相当于源地址</li><li>地址1是要接受该帧的无线站点的MAC地址，相当于目标地址</li><li>地址3包含这个路由器接口的MAC地址。地址3在BSS和有限局域网互联中起着关键作用。</li><li>当AP在自组织模式中互相转发时使用第四个地址。</li></ul></li></ul></li><li>序号、持续期和帧控制字段<ul><li>使用序号可以使接收方区分新传输的帧和以前帧的重传。</li><li>802.11协议允许传输节点预约信道一段时间，包括传输其数据帧的时间和传输确认的时间。这个持续期值被包括在该帧的持续期字段中(在数据帧和RTS和CTS帧中均存在)。</li><li>帧控制字段包含很多子字段<ul><li>类型和子类型字段用于区分关联、RTS、CTS、ACK和数据帧</li><li>WEP字段指示了是否使用加密</li><li>To和From字段用于定义不同地址字段的含义。</li></ul></li></ul></li></ol><h4 id="7-3-4-在相同的IP子网中的移动性"><a href="#7-3-4-在相同的IP子网中的移动性" class="headerlink" title="7.3.4 在相同的IP子网中的移动性"></a>7.3.4 在相同的IP子网中的移动性</h4><p>保持自己的IP地址和所有正在进行的TCP连接</p><p>保持IP地址不变，两个AP有着相同的SSID，那交换机如何知道设备已经更换了AP(更换了交换机的端口)呢，可以通过新的AP，发送一个广播帧，那么就能更新交换机的表项。</p><h4 id="802-11中的高级特色"><a href="#802-11中的高级特色" class="headerlink" title="802.11中的高级特色"></a>802.11中的高级特色</h4><ol><li>802.11速率自适应：类似于TCP的拥塞控制</li><li>功率管理：节点睡眠。AP先缓存目标帧</li></ol><h4 id="6-3-6-个人域网络：蓝牙和ZigBee"><a href="#6-3-6-个人域网络：蓝牙和ZigBee" class="headerlink" title="6.3.6 个人域网络：蓝牙和ZigBee"></a>6.3.6 个人域网络：蓝牙和ZigBee</h4><ol><li>蓝牙<ul><li>802.15.1 也被称为无线个人域网络(Wireless Personal Area Network, WPAN)</li><li>以TDM方式工作于无须许可证的2.4GHz无线电波段，每个时隙长度为625 $\mu s$</li><li>在每个时隙内，发送方利用79个信道中的一个进行传输，同时从时隙到时隙以一个已知的伪随机方式变更信道。这种被称作跳频扩展频谱(frequency-Hopping Spread Spectrum, FHSS).</li><li>802.15.1网络是自组织网络</li><li>802.15.1设备首先组织成一个多达8个活动设备的皮可网(piconet). 这些设备之一被指定为主设备，其余充当从设备。</li><li>主节点真正控制皮可网，它的时钟确定了皮可网中的时间，它可以在每个奇数时隙中发送，而从设备仅当主设备在前一时隙与其通信后才可以发送，并且只能发送给主设备。除了从设备，网络中还可以有多达255个的寄放(parked)设备.这些设备仅其状态被主节点从寄放转换为活动之后才可以进行通信。</li></ul></li><li>ZigBee<ul><li>IEEE标准化的第二个个人域网络是802.14.5</li><li>ZigBee较之蓝牙其服务目标是低功率、低数据率、低周期的应用。</li></ul></li></ol><h2 id="第八章：计算机网络中的安全"><a href="#第八章：计算机网络中的安全" class="headerlink" title="第八章：计算机网络中的安全"></a>第八章：计算机网络中的安全</h2><h3 id="8-1-什么是网络安全"><a href="#8-1-什么是网络安全" class="headerlink" title="8.1 什么是网络安全"></a>8.1 什么是网络安全</h3><p>安全通信具有下列所需要的特性：</p><ul><li>机密性</li><li>报文完整性</li><li>端点鉴别</li><li>运行安全性</li></ul><h3 id="8-2-密码学原则"><a href="#8-2-密码学原则" class="headerlink" title="8.2 密码学原则"></a>8.2 密码学原则</h3><h4 id="8-2-1-对称密钥密码体制"><a href="#8-2-1-对称密钥密码体制" class="headerlink" title="8.2.1 对称密钥密码体制"></a>8.2.1 对称密钥密码体制</h4><ul><li>单码代替密码(monoalphabetic cipher)<ul><li>凯撒密码(Caesar cipher)</li></ul></li><li>多码代替密码(polyalphabetic encryption)</li></ul><p>攻击分三种：</p><ul><li>唯密文攻击</li><li>已知明文攻击</li><li>选择明文攻击</li></ul><h4 id="8-2-2-公开密钥加密"><a href="#8-2-2-公开密钥加密" class="headerlink" title="8.2.2 公开密钥加密"></a>8.2.2 公开密钥加密</h4><ol><li>RSA<ol><li>选择两个大素数$p$和$q$</li><li>计算$n=pq$ 和 $z=(p-1)(q-1)$</li><li>选择一个小于$n$的数$e$, 且使$e$ 和$z$ 没有(非1的)公因数</li><li>求一个数$d$ 使得$ed-1$ 可以被$z$整除</li><li>公钥是$(n,e)$ , 私钥是$(n,d)$ </li></ol></li><li>会话密钥<ul><li>用RSA加密会话密钥，使用对称的会话密钥进行通信。</li></ul></li></ol><h3 id="8-3-报文完整性和数字签名"><a href="#8-3-报文完整性和数字签名" class="headerlink" title="8.3 报文完整性和数字签名"></a>8.3 报文完整性和数字签名</h3><h4 id="8-3-1-密码散列函数"><a href="#8-3-1-密码散列函数" class="headerlink" title="8.3.1 密码散列函数"></a>8.3.1 密码散列函数</h4><p>密码散列函数要具有下列性质：找到任意两个不同的报文$x$和$y$使得$H(x)=H(y)$，在计算上是不可能的。</p><ul><li>MD5 散列算法：计算得到128比特的散列</li><li>SHA-1散列算法：生成一个160比特的报文摘要</li></ul><h4 id="8-3-2-报文鉴别码"><a href="#8-3-2-报文鉴别码" class="headerlink" title="8.3.2 报文鉴别码"></a>8.3.2 报文鉴别码</h4><p>Alice和Bob共享秘密$s$,被称为鉴别密钥(authentication key).</p><ol><li>Alice生成报文$m$, 加上$s$, 得到$m+s$, 然后计算散列$H(m+s)$(例如使用SHA-1). $H(m+s)$ 被称为报文鉴别码(Message Authentication Code, MAC). </li><li>然后Alice发送$(m,H(m+s))$</li><li>Bob根据$m$ 和$s$ 计算$H(m+s)$ 来判断是否正常。 </li></ol><h4 id="8-3-3-数字签名"><a href="#8-3-3-数字签名" class="headerlink" title="8.3.3 数字签名"></a>8.3.3 数字签名</h4><p>用公钥加密</p><p>公钥认证：</p><p>将公钥与特定实体绑定通常是认证中心(Certification Authority, CA)完成的，CA的职责就是使识别和发行证书合法化。</p><h3 id="8-4-端点鉴别-end-point-authentication"><a href="#8-4-端点鉴别-end-point-authentication" class="headerlink" title="8.4 端点鉴别(end-point authentication)"></a>8.4 端点鉴别(end-point authentication)</h3><h3 id="8-5-安全电子邮件"><a href="#8-5-安全电子邮件" class="headerlink" title="8.5 安全电子邮件"></a>8.5 安全电子邮件</h3><p>PGP</p><h3 id="8-6-使TCP连接安全：SSL"><a href="#8-6-使TCP连接安全：SSL" class="headerlink" title="8.6 使TCP连接安全：SSL"></a>8.6 使TCP连接安全：SSL</h3><p>安全套接字层(Secure Socket Layer, SSL)</p><p>运输层安全性(Transport Layer Security, TLS)</p><p>SSL记录： <code>类型| 版本 | 长度 | 数据 | MAC</code> </p><h4 id="8-6-2-更完整的描述"><a href="#8-6-2-更完整的描述" class="headerlink" title="8.6.2 更完整的描述"></a>8.6.2 更完整的描述</h4><ol><li>SSL握手<ol><li>客户发送它支持的密码算法的列表，连同一个客户的不重数</li><li>从该列表中，服务器选择一种对称算法(例如AES)、一种公钥算法(例如具有特定密钥长度的RSA)和一种MAC算法。它把它的选择以及证书和一个服务器不重数返回给客户。</li><li>客户验证该证书，提取服务器的公钥，生成一个前主密钥(Pre-Master Secret, PMS), 用服务器的公钥加密该PMS，并将加密的PMS发送给服务器。</li><li>使用相同的密钥导出函数，客户和服务器独立地从PMS和不重数中计算出主密钥(Master Secret, MS). 然后该MS被切片以生成两个密码和两个MAC密钥。此外，当选择的对称密码应用于CBC，则两个初始化向量(Initialization Vector, IV)也从该MS获得，这两个IV分别用于该连接的两段。自此以后，客户和服务器之间发送的所有报文均被加密和鉴别(使用MAC)。</li><li>客户发送所有握手报文的一个MAC</li><li>服务器发送所有握手报文的一个MAC</li></ol></li></ol><p>在SSL中，不重数用于防御”连接重放”，而序号用于防御在一个进行中的会话中重放个别分组。</p><ol><li>连接关闭</li></ol><h3 id="8-7-网络层安全性：IPsec和虚拟专用网"><a href="#8-7-网络层安全性：IPsec和虚拟专用网" class="headerlink" title="8.7 网络层安全性：IPsec和虚拟专用网"></a>8.7 网络层安全性：IPsec和虚拟专用网</h3><p>IP安全(IP Security)协议更常被称为IPsec，它为网络层提供了安全性。许多机构使用IPsec创建了运行在公共因特网之上的虚拟专用网(Virtual Private Network, VPN).</p><h4 id="8-7-1-IPsec和虚拟专用网"><a href="#8-7-1-IPsec和虚拟专用网" class="headerlink" title="8.7.1 IPsec和虚拟专用网"></a>8.7.1 IPsec和虚拟专用网</h4><p>当总部中的一台主机向某旅馆中的某销售员发送一个IP数据报时，总部中的网关路由器将经典的IPv4转换成为IPsec数据报，然后将该IPsec数据报转发进因特网。该IPsec数据报实际上具有传统的IPv4首部，因此在公共因特网中的路由器处理该数据报，仿佛它对路由器而言是一个传统的IPv4数据报。但是，IPsec数据报的载荷包括了一个IPsec首部，该首部被用于IPsec处理；此外，IPsec数据报的载荷是被加密的。当该IPsec数据报到达销售员的便携机时，便携机的操作系统解密载荷，并将解密的载荷传递给上层协议。</p><h4 id="8-7-2-AH协议和ESP协议"><a href="#8-7-2-AH协议和ESP协议" class="headerlink" title="8.7.2 AH协议和ESP协议"></a>8.7.2 AH协议和ESP协议</h4><p>在IPsec协议族中，有两个主要协议：鉴别首部(Authentication Header, AH) 协议 和 封装安全性载荷(Encapsulation Security Payload, ESP)协议。</p><ul><li>AH协议：提供源鉴别和数据完整性服务，但不提供机密性服务</li><li>ESP协议：提供源鉴别、数据完整性和机密性服务</li></ul><p>ESP协议的使用比AH协议要广泛得多。</p><h4 id="8-7-3-安全关联"><a href="#8-7-3-安全关联" class="headerlink" title="8.7.3 安全关联"></a>8.7.3 安全关联</h4><p>在从源实体向目的实体发送IPsec数据报之前，源和目的实体创建了一个网络层的逻辑连接。这个逻辑连接称为安全关联(Security Association, SA). 一个SA是一个单工逻辑连接；也就是说它是从源到目的地单向的。如果两个实体要互相发送安全数据报，则需创建两个SA，每个方向一个。</p><h3 id="8-9-运行安全性：防火墙和入侵检测系统"><a href="#8-9-运行安全性：防火墙和入侵检测系统" class="headerlink" title="8.9 运行安全性：防火墙和入侵检测系统"></a>8.9 运行安全性：防火墙和入侵检测系统</h3><h4 id="8-9-1-防火墙"><a href="#8-9-1-防火墙" class="headerlink" title="8.9.1 防火墙"></a>8.9.1 防火墙</h4><p>防火墙是一个硬件和软件的结合体，它将一个机构的内部网络与整个因特网隔离开，允许一些数据分组通过而阻止另一些分组通过。</p><p>防火墙具有3个目标：</p><ul><li>从外部到内部和从内部到外部的所有流量都通过防火墙</li><li>仅被授权的流量(由本地安全策略定义)允许通过</li><li>防火墙自身免于渗透</li></ul><p>防火墙能够分为3类：</p><ul><li>传统的分组过滤器(traditional packet filetr)<ul><li>在网关路由器设置过滤规则</li><li>过滤决定通常基于下列因素：<ul><li>IP源或目的地址</li><li>在IP数据报中的协议类型字段：TCP、UDP、ICMP、OSPF等</li><li>TCP或UDP的源或目的端口</li><li>TCP标志比特：SYN、ACK等</li><li>ICMP报文类型</li><li>数据报离开和进入网络的不同规则</li><li>对不同路由器接口的不同规则</li></ul></li><li>可以通过过滤所有ACK比特为0的包，这样外部无法发起TCP连接，只有内部能发起TCP连接</li></ul></li><li>状态过滤器(stateful filter)<ul><li>状态过滤器实际地跟踪TCP连接，并使用这种知识做出过滤决定</li><li>状态过滤器通过用一张连接表来跟踪所有进行中的TCP连接</li><li>此时的访问控制列表里多了一列，为是否核对连接。如果是的话，就要核对该TCP连接的状态。</li></ul></li><li>应用程序网关(application gateway)<ul><li>一个应用程序网关(application gateway)是一个应用程序特定的服务器，所有应用程序数据(入和出的)都必须通过它。该服务器还充当中继。</li></ul></li></ul><h4 id="8-9-2-入侵检测系统"><a href="#8-9-2-入侵检测系统" class="headerlink" title="8.9.2 入侵检测系统"></a>8.9.2 入侵检测系统</h4><p>为了检测多种攻击类型，我们需要执行深度分组检查(deep packet inspection)</p><p>当观察到潜在恶意流量时能产生告警的设备成为入侵检测系统(Instrusion Detection System, IDS). </p><p>滤除可疑流量的设备称为入侵防止系统(Intrusion Prevention System, IPS)</p><p>一个机构可能在它的机构网络中部署一个或多个IDS传感器。</p><p>IDS系统大致可分为两类：</p><ul><li>基于特征的系统(signature-based system)<ul><li>基于特征的IDS维护了一个范围广泛的攻击特征数据库。每个特征是与一个入侵活动相关联的规则集。<ul><li>缺点：<ul><li>对新攻击完全缺乏判断力</li><li>即使与一个特征相匹配，它也可能不是一个攻击的结果，因此产生了一个虚假告警</li><li>因为每个分组必须与范围广泛的特征集合相比较，IDS可能处于处理过载状态并因此难以检测出许多恶意分组</li></ul></li></ul></li></ul></li><li>基于异常的系统(anomaly-based system)<ul><li>当基于异常的IDS观察正常运行的流量，它会生成一个流量概况文件。然后，它寻找统计上不寻常的分组流，例如，ICMP分组不寻常的百分比，或端口扫描和ping掠过导致指数性突然增长。</li><li>最大特点：不依赖现有攻击的以前知识</li><li>但区分正常流量和统计异常流量是一个极具挑战性的问题。</li><li>迄今为止，大多数部署的IDS主要是基于特征的，尽管某些IDS包括了某些基于异常的特性</li></ul></li></ul><h2 id="第九章：多媒体网络"><a href="#第九章：多媒体网络" class="headerlink" title="第九章：多媒体网络"></a>第九章：多媒体网络</h2><h3 id="9-1-多媒体网络应用"><a href="#9-1-多媒体网络应用" class="headerlink" title="9.1 多媒体网络应用"></a>9.1 多媒体网络应用</h3><h4 id="9-1-1-视频的性质"><a href="#9-1-1-视频的性质" class="headerlink" title="9.1.1 视频的性质"></a>9.1.1 视频的性质</h4><p>视频最为显著的特点或许是它的高比特率(high bit rate).</p><p>视频有两种冗余：空间冗余和时域冗余。他们都可以用来进行视频压缩(video compression)</p><p>我们可以使用压缩来生成相同视频的多重版本(multiple version) </p><h4 id="9-1-2-音频的性质"><a href="#9-1-2-音频的性质" class="headerlink" title="9.1.2 音频的性质"></a>9.1.2 音频的性质</h4><h4 id="9-1-3-多媒体网络应用的类型"><a href="#9-1-3-多媒体网络应用的类型" class="headerlink" title="9.1.3 多媒体网络应用的类型"></a>9.1.3 多媒体网络应用的类型</h4><ol><li>流式存储音频和视频</li><li>会话式IP语音和视频<ul><li>高度时延敏感(delay-sensitive)</li><li>容忍丢包(loss-tolerant)</li></ul></li><li>流式实况音频和视频</li></ol><h3 id="9-2-流式存储视频"><a href="#9-2-流式存储视频" class="headerlink" title="9.2 流式存储视频"></a>9.2 流式存储视频</h3><p>流式视频系统可分为三种类型：</p><ul><li>UDP流(UDP streaming)</li><li>HTPP流(HTTP streaming)</li><li>适应性HTTP流(adaptive HTTP streaming) </li></ul><p>绝大多数今天的系统应用了HTTP流和适应性HTTP流</p><p>这三种形式的视频流的共同特点是广泛使用了客户端应用缓存，以此来缓解变化的端到端时延和变化的服务器和客户之间可用带宽量的影响。</p><h4 id="9-2-1-UDP流"><a href="#9-2-1-UDP流" class="headerlink" title="9.2.1 UDP流"></a>9.2.1 UDP流</h4><p>UDP流除了服务器到客户的视频流外，两者间还并行地维护一个单独的控制连接，通过该连接，客户可以发送有关会话状态的命令(如暂停、重新开始、重定位等)。</p><p>UDP流有三个重大不足：</p><ul><li>由于服务器和客户端之间的可用带宽无法预测且是变化的，恒定速率UDP流不能够提供连续的播放。</li><li>要求如RTSP服务器这样的媒体控制服务器，增加了部署大规模的按需视频系统的总体成本和复杂性</li><li>许多防火墙配置为阻塞UDP流量</li></ul><h4 id="9-2-2-HTTP流"><a href="#9-2-2-HTTP流" class="headerlink" title="9.2.2 HTTP流"></a>9.2.2 HTTP流</h4><p>客户端应用缓存</p><h3 id="9-3-IP语音"><a href="#9-3-IP语音" class="headerlink" title="9.3 IP语音"></a>9.3 IP语音</h3><h4 id="9-3-1-尽力而为的服务限制"><a href="#9-3-1-尽力而为的服务限制" class="headerlink" title="9.3.1 尽力而为的服务限制"></a>9.3.1 尽力而为的服务限制</h4><p>几乎所有现有的VoIP应用默认运行在UDP上。Skype使用了UDP，除非用户位于阻碍UDP报文段的NAT或防火墙之后。</p><h3 id="9-4-实时会话式应用的协议"><a href="#9-4-实时会话式应用的协议" class="headerlink" title="9.4 实时会话式应用的协议"></a>9.4 实时会话式应用的协议</h3><h4 id="9-4-1-RTP"><a href="#9-4-1-RTP" class="headerlink" title="9.4.1 RTP"></a>9.4.1 RTP</h4><p>RTP通常运行在UDP之上。发送端在RTP分组中封装媒体块，然后在UDP报文段中封装该分组。</p><h4 id="9-4-2-SIP"><a href="#9-4-2-SIP" class="headerlink" title="9.4.2 SIP"></a>9.4.2 SIP</h4><h3 id="9-5-支持多媒体的网络"><a href="#9-5-支持多媒体的网络" class="headerlink" title="9.5 支持多媒体的网络"></a>9.5 支持多媒体的网络</h3>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;计算机网络&quot;&gt;&lt;a href=&quot;#计算机网络&quot; class=&quot;headerlink&quot; title=&quot;计算机网络&quot;&gt;&lt;/a&gt;计算机网络&lt;/h1&gt;&lt;h2 id=&quot;课程概述&quot;&gt;&lt;a href=&quot;#课程概述&quot; class=&quot;headerlink&quot; title=&quot;课程概述&quot;&gt;&lt;/a&gt;课程概述&lt;/h2&gt;&lt;h3 id=&quot;参考教材&quot;&gt;&lt;a href=&quot;#参考教材&quot; class=&quot;headerlink&quot; title=&quot;参考教材&quot;&gt;&lt;/a&gt;参考教材&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;James F. Kurose, Keith W. Ross. 计算机网络-自顶向下方法(7th)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;William Stallings. 数据与计算机通信(10th)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;课程考核&quot;&gt;&lt;a href=&quot;#课程考核&quot; class=&quot;headerlink&quot; title=&quot;课程考核&quot;&gt;&lt;/a&gt;课程考核&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;分组实践，课程报告 (30%)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;课后作业(30%)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;期末考试(40%)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;nju2019autumn@163.com&lt;/p&gt;
&lt;h3 id=&quot;课程内容&quot;&gt;&lt;a href=&quot;#课程内容&quot; class=&quot;headerlink&quot; title=&quot;课程内容&quot;&gt;&lt;/a&gt;课程内容&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;端网络&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;前端网络：客户端&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;后端网络：服务端&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;骨干网&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>人工智能</title>
    <link href="https://ricky-ting.github.io/2019/12/02/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    <id>https://ricky-ting.github.io/2019/12/02/人工智能/</id>
    <published>2019-12-02T14:38:13.000Z</published>
    <updated>2019-12-02T14:56:39.169Z</updated>
    
    <content type="html"><![CDATA[<h1 id="人工智能"><a href="#人工智能" class="headerlink" title="人工智能"></a>人工智能</h1><h2 id="课程概述"><a href="#课程概述" class="headerlink" title="课程概述"></a>课程概述</h2><p>参考教材</p><ul><li><p>George F. Luger, Artificial Intelligence: Structures and Strategies for Complex Problem Solving. Fifth Edition, Addison Wesley.</p></li><li><p>Stuart Russell and Peter Norvig. Artificial Intelligence: A Modern Approach. Third Edition.</p></li></ul><p>参考网站</p><ul><li><p>CMU, <a href="http://www.cs.cmu.edu" target="_blank" rel="noopener">http://www.cs.cmu.edu</a></p></li><li><p>MIT, <a href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/index.htm" target="_blank" rel="noopener">http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/index.htm</a>.</p></li><li><p>Stanford University, <a href="http://www.stanford.edu/class/cs221/" target="_blank" rel="noopener">http://www.stanford.edu/class/cs221/</a>.</p></li></ul><p>前8周讲授完毕，并进行期中闭卷考试(40分)</p><p>全自动区分计算机和人类的图灵测试：Completely Automated Public Turing test to tell Computers and Humans Apart，简称CAPTCHA</p><a id="more"></a><h2 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h2><h3 id="状态空间搜索"><a href="#状态空间搜索" class="headerlink" title="状态空间搜索"></a>状态空间搜索</h3><p>状态空间的表示</p><ul><li>状态空间图：节点N和连接(弧)A</li><li>初始状态：S是N的非空子集</li><li>目标状态：G是N的非空子集</li><li>状态空间搜索：寻找从初始状态到目标状态的解路径(solution path)</li><li>状态转移图：有向无环图DAG，但也可能存在回路</li><li>状态转移树</li></ul><p>图搜索：需要检测和消除解路径上的循环</p><p>树搜索：免除检测的开销</p><p>搜索树</p><ul><li>根节点：初始状态</li><li>连接：父节点上的合法动作</li><li>后继：在父节点上采用合法动作所达到的子节点</li><li>搜索树：删除后继节点中已经出现的等价状态，所形成的树</li></ul><p>状态空间的搜索方向</p><ul><li>数据驱动-前向搜索，由数据向目标搜索</li><li>目标驱动-后向搜索，由目标向数据搜索</li></ul><p>回溯技术：通过试错方式搜索状态空间所有解路径</p><p>宽度优先搜索：</p><ul><li>先入先出FIFO，从右侧加入列表，左侧移出</li><li>可保证发现目标状态的最短路径</li><li>组合爆炸</li></ul><p>深度优先搜索：</p><ul><li>后入先出LIFO，从左侧加入列表，左侧移出</li><li>不保证发现目标状态的最短路径</li><li>“可能迷失”在深度空间中</li></ul><p>所以，将两者结合我们得到了迭代加深深度优先：有近似于BFS的时间复杂度和近似于DFS的空间复杂度，避免组合爆炸。</p><p>迭代加深深度优先与广度优先等价</p><h4 id="启发式搜索"><a href="#启发式搜索" class="headerlink" title="启发式搜索"></a>启发式搜索</h4><p>为什么需要启发：1.没有精确解；2.约简搜索的状态空间</p><p>爬山搜索：</p><ul><li>第一步:扩展当前节点以及其子节点，并进行评估;</li><li>第二步:选择“最优”的子节点作为下一节点;</li><li>第三步:如果所有子节点的评估，都比当前节点“劣”， 则算法终止。</li></ul><p>但爬山搜索容易陷入局部最优，我们可以增加回溯机制</p><p>最佳优先搜索，类似于宽度优先搜索，但把队列换成了优先队列</p><p>错位牌数是什么？？ 距离又是什么？？？</p><p>$A*$算法</p><ul><li>评估函数：$f(n)=g(n)+h(n)$</li><li>最优评估函数：$f^<em>(n) = g^</em>(n) +h^*(n)$ </li><li>$g(n) \ge g^*(n)$</li><li>如果$h(n) \le h^<em>(n)$, 则$A$算法为$A^</em>$算法</li></ul><p>把$h(n)$定义为0，且边权为1，就是BFS。DFS?</p><p>$A^*$算法具有可采纳性和单调性</p><p>可采纳性(admissible):最优评估函数一个算法是可采纳的，当存在一个解路径时，算法总是终止在此最优解路径上。</p><p>可采纳启发式是指它从不会过高估计到达目标的代价。</p><p>$A^*$算法是可采纳的：</p><ul><li>$A^*$可以终止</li><li>解路径上的节点总是会被$A^*$展开(访问到)</li><li>当存在解路径时,$A^*$算法终止在此解路径上</li></ul><p>$A^<em>$最优性：如果$h_1(n) &lt; h_2(n) $, 则$A_2^</em>$展开的节点数小于$A_1^*$  P92</p><p>$A^*$单调性：启发函数$h$是单调的</p><ul><li>$n_j$是$n_i$的后继节点，如果$h(n_i) - h(n_j) \le cost(n_i,n_j) $ 就是三角不等式</li><li>$h(goal) = 0$</li></ul><p>单调性：在首次访问的目标状态的路径，保证一定是最短路径。</p><p>$A^<em>$有如下性质：如果$h(n)$是可采纳的，那么$A^</em>$的树搜索版本是最优的；如果$h(n)$是一致的，那么图搜索的$A^*$算法是最优的。</p><h4 id="博弈树搜索"><a href="#博弈树搜索" class="headerlink" title="博弈树搜索"></a>博弈树搜索</h4><p>极小极大过程</p><ul><li>MAX:代表我方玩家，最大化其收益(赢得博弈)</li><li>MIN:代表对手，最小化MAX的收益</li></ul><p>将启发值自底向上传播</p><ul><li>如果父状态是MAX节点，将孩子节点中最大值传给它</li><li>如果父状态是MIN节点，将孩子节点中最小值传给它</li></ul><p>但这样状态数仍然很多，本质上还是穷竭搜索，所以要剪枝：</p><p>$\alpha - \beta$ 过程</p><p>极小极大过程：</p><ul><li>在预判层应用启发式评估</li><li>展开所有的后继分支</li><li>沿树向上传播评估值</li></ul><p>$\alpha -\beta$剪枝</p><ul><li>当确定是一个dead end时，停止展开其后继节点</li><li>对博弈树的深度优先搜索，且维护<ul><li>$\alpha$:与MAX节点关联，从不减小</li><li>$\beta$:与MIN节点关联，从不增大</li></ul></li><li>剪枝规则<ul><li>$Alpha$剪枝：任一MIN节点，如果其Beta值小于等于其祖先MAX节点的Alpha值，则停止搜索</li><li>Beta剪枝：任一MAX节点，如果其Alpha值大于等于其祖先MIN节点的Beta值，则停止搜索。</li></ul></li><li>特点<ul><li>对子节点排序非常敏感</li><li>静态启发：吃子启发</li><li>动态启发：历史启发、杀手启发、置换表启发</li></ul></li></ul><h3 id="Monte-Caro-树搜索"><a href="#Monte-Caro-树搜索" class="headerlink" title="Monte Caro 树搜索"></a>Monte Caro 树搜索</h3><p><a href="https://www.jiqizhixin.com/articles/monte-carlo-tree-search-beginners-guide" target="_blank" rel="noopener">参考资料</a></p><p>基本原理；随机抽样+假设检验+树搜索</p><p>解决：迭代产生游戏树，解决树空间太大的问题</p><p>性质：用概率的方式，产生合理的推理，但并不保证一定最优</p><p>预测值：</p><ul><li>第一个数字：代表在这个子树上赢的次数</li><li>第二个数字：在这个子树上模拟的次数</li></ul><p>SELECTION步骤：利用树策略选择节点</p><p>蒙特卡洛树的选择策略：</p><ul><li>UCT策略：<ul><li>平衡Exploration和Exploitation。</li><li>Exploration approach 促使去探索尚未发现的树的其他领域。 这会将倾向于探索树的广度，而不是深度。</li><li>Exploitation approach 倾向于选择拥有最大预测值的路径。这 种是属于贪心算法，趋于探索树的深度。</li><li>$UCT(node) = \frac{W(node)}{N(node)} + c \sqrt{\frac{\ln{N(parentNode)}}{N(node)}}$ </li></ul></li></ul><p>Expansion:添加一个 “?”的叶子节点。这是每次迭代中唯一添加的节点。</p><p>SImulation:又称 playout 或者 rollout。执行操作，直到达到结束状态，或者 满足设定的阈值，就停止该操作。然后基于模拟的结果，建立新 添加节点的值。</p><p>Backpropagation:利用新添加节点的值，对之前的树进行更新。从新的节点开始，<br>算法反向遍历回到根节点。</p><h2 id="推理"><a href="#推理" class="headerlink" title="推理"></a>推理</h2><p>合取范式(CNF),析取范式(DNF)</p><p>谓词演算的五大推理规则:取式假言推理、拒式假言推理、与消除、与引入、全称例化</p><ul><li>取式假言推理：如果已知语句$P$和$P \rightarrow Q$ 为真，那么$Q$为真</li><li>拒式假言推理：如果已知$P \rightarrow Q$ 为真，且$Q$为假，那么$P$为假</li><li>与消除：$P \wedge Q$ 为真，那么$P$、$Q$分别为真</li><li>与引入：$P$和$Q$都为真，$P \wedge Q$ 为真</li><li>全称例化：$\forall X, p(X)$ 为真，且$a$ 为$X$定义域中一值，$p(a)$为真。</li></ul><h3 id="合一"><a href="#合一" class="headerlink" title="合一"></a>合一</h3><p>合一：判断什么样的替换可以使两个谓词表达式匹配的算法。</p><p>合一表明了两个或多个表达式在什么条件下可以称为等价的。</p><p>替换：一个替换(Substitution)就是形如${t1/x1,t2/x2,…,tn/xn}$的有限集合，$x1,x2,…,xn$是互不相同的个体变元，$ti$不同于$xi$, $xi$也不循环出现在$tj$中。</p><p>斯柯伦标准化:去掉所有的存在量词：$(\forall X)(\exists Y) (mother(X,Y))$ 转换为$(\forall X) (mother(X,m(X))) $ </p><p>组合：在合一过程中，如果先后产生$S$和$S’$的替换，那么将S中的某个元素应用$S’$,所产生的新的替换，称为组合</p><p>最一般的合一式(MGU,Most Generalize Unify): 如果$g$是表达式$E$的最一般合一式，那么对于任何的其他合一式$s$,都存在另一个合一式$s’$,使$Es = Egs’$. 其中$Es$和$Egs’$是应用到表达式$E$的合一式的组合。</p><p>合一算法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1. 递归地对表达式的初始成分合一。如果成功，这次合一返回的任何代入式被用到两个表达式的剩下部分，然后以这两个表达式为参数。</span><br><span class="line">2. 当两个参数之一为一个符号(谓词名，函词名，变元，常元)， 或两个表达式的每一元素都已匹配了，算法终止。</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">UNIFY</span><br><span class="line">case</span><br><span class="line">E1, E2或者是常元或者是空表: %递归终止</span><br><span class="line">If E1=E2 then return &#123;&#125;;</span><br><span class="line">else return FAIL;</span><br><span class="line">E1是一个变元：</span><br><span class="line">If E1在E2中出现 then return FAIL;</span><br><span class="line">else return &#123;E2/E1&#125;;</span><br><span class="line">E2是一个变元：</span><br><span class="line">If E2在E1中出现then return FAIL;</span><br><span class="line">else return &#123;E1/E2&#125;;</span><br><span class="line">其他情况: %E1和E2都是表</span><br><span class="line">begin</span><br><span class="line">HE1:=E1的第一个元素;</span><br><span class="line">HE2:=E2的第二个元素;</span><br><span class="line">SUBS1:=unify*HE1,HE2;</span><br><span class="line">if(SUBS1=FAIL) then return FAIL;</span><br><span class="line">TE1:=apply(SUBS1,E1的后半部);</span><br><span class="line">TE2:=apply(SUBS1,E2的后半部);</span><br><span class="line">SUBS2:=unify(TE1,TE2);</span><br><span class="line">if(SUBS2=FAIL) then return FAIL;</span><br><span class="line">else return SUBS1与SUBS2的并集;</span><br><span class="line">end</span><br></pre></td></tr></table></figure><h3 id="归结"><a href="#归结" class="headerlink" title="归结"></a>归结</h3><p>归结法的基本思想：</p><ul><li>反证法：为了证明一个命题$P$恒真，则证明其反命题$\neg P$恒假。即不存在使得$\neg P$为真的解释。</li><li>设$F_1,F_2,…,F_n,G$为公式，$G$为$F_1,…,F_n$的逻辑推论,当且仅当公式$ (F_1 \wedge … \wedge F_n \wedge \neg G )$ 是不可满足的</li></ul><p>消解是一种应用于谓词演算中的定理证明技术，是人工智 能问题求解的一个组成部分。消解描述了如何用最少的合一次数在一个子句数据库中发现矛盾的方法。</p><p>消解否证包含以下步骤：</p><ul><li>具体方法为把前提或公理转换成子句形式。</li><li>把求证目标的否定的子句形式加到公理集合中。</li><li>对所有这些子句进行消解，产生它们的逻辑结果子句。</li><li>用产生空子句的方法来得出矛盾。</li></ul><p>产生子句的一系列过程：最后转换成不含量词的合取范式</p><p>归结的策略：</p><ul><li>宽度优先策略：时空开销大，保证能发现最短的解路径</li><li>支持策略<ul><li>本策略要求每次归结的归结式之一至少有一个是由 目标公式的否定所得到的 子句，或者是它们的后裔。</li><li>可以证明，该策略是完备的。</li></ul></li><li>单个优先策略：<ul><li>只要存在个体子句(一个文字的子句)就是用个体子句归结。</li><li>单个优先策略与成组支持策略一起使用，可以得到 了更加有效的完备策略。</li></ul></li></ul><h2 id="知识表示"><a href="#知识表示" class="headerlink" title="知识表示"></a>知识表示</h2><p>常见的知识表示方法：</p><ul><li>一阶谓词表示(First Order Predicate)</li><li>产生式表示(Production)</li><li>语义网络表示(Semantic Network)</li><li>框架表示(Framework)</li><li>脚本表示(Script)</li></ul><h3 id="一阶谓词知识表示"><a href="#一阶谓词知识表示" class="headerlink" title="一阶谓词知识表示"></a>一阶谓词知识表示</h3><p>优点：精确、自然、严密，易于实现</p><p>缺点：表示和处理分离，组合爆炸导致效率低</p><h3 id="产生式表示"><a href="#产生式表示" class="headerlink" title="产生式表示"></a>产生式表示</h3><p>一阶谓词中蕴含式表示的知识是精确的(真或假)，而产生式表示的知识可以是不精确的(可信度)，产生式的推理匹配过程也可以是部分匹配。</p><p>产生式系统：一组产生式，互相配合/协调，其中一个产生式产生的结论可以作为另一个产生式的事实使用，以求解问题。有三个组件：数据库、规则库、</p><p>规则库：</p><ul><li>有效表达领域内的过程性知识。</li><li>对知识进行合理的组织与管理，提高问题求解效率。</li></ul><p>数据库(工作内存)：</p><ul><li>存放问题求解过程中的各种信息的数据结构，包括初始<br>状态、原始证据、中间结论、最终结论。</li><li>其内容在推理过程中在动态、不断变化的。</li></ul><p>控制系统：</p><ul><li>从规则库中选择规则，并与数据库中的已知事实进行匹配。</li><li>发生冲突时调用相应策略进行消解。</li><li>如果执行规则的右部是一个或多个结论，则将结论加入到数据库中。</li><li>如果执行规则的右部是一个或多个的操作，则执行这些操作。并将操作产生的 事实加入到数据库中。</li><li>对不确定性的知识，也计算结论的不确定性。</li><li>在适当时候终止系统运行。</li></ul><p>产生式表示/系统的优点：</p><ul><li>知识和控制的分离;</li><li>自然映射到状态空间搜索;</li><li>产生式规则的模块性;</li><li>模式导向控制;</li><li>多种启发式控制;</li><li>易于跟踪和解释;</li><li>问题求解的模型之一。</li></ul><p>产生式表示适用范围</p><ul><li>领域中知识单元相对独立，不存在结构关系;</li><li>具有经验型或者不确定性的知识，领域对这些知识缺少完整<br> 的理论模型;</li><li>领域问题的求解过程可表示为一些列相对独立的操作，每个<br> 操作也可表示为一条或多条的产生式规则。</li></ul><h3 id="语义网络表示法"><a href="#语义网络表示法" class="headerlink" title="语义网络表示法"></a>语义网络表示法</h3><p>通过有向图，其顶点表示概念，边表示概念间的语义关系，来表达复杂的概念及其相互关系。</p><p>语义网络的推理</p><ul><li>继承：<ul><li>把对事物的描述从抽象节点传递到具体节点，通常沿着类<br>属关系ISA, AKO等具有继承关系的边进行。</li></ul></li><li>匹配<ul><li>把待求解问题构造为网络片段，其中某些节点或边的标识 是空的，称为询问点。</li><li>将网络片段与知识库中的某个语义网络片段进行匹配，则 与询问点相匹配的事实就是该问题的解。</li></ul></li></ul><p>语义网络表示的优缺点：</p><ul><li>优点：结构性、联想性、自索引性、自然语言的转换性</li><li>缺点：不严格性、处理复杂。本质和谓词演算等价。</li><li>强大在于:连接和推理规则的丰富和定义!</li></ul><h3 id="框架表示"><a href="#框架表示" class="headerlink" title="框架表示"></a>框架表示</h3><p>定义：是描述对象(一个事物、一个事件、一个概念)属性的一 种数据结构。在框架表示法中，框架被认为是知识表示的 最基本单元</p><p>表示形式：框架名、槽名(描述某一方面的属性)、侧面(描述属性的某 一方面)、值组成</p><p>框架网络系统：将多个相互关联的框架连接起来组织的知识表示和推理系统</p><ul><li>纵向联系：通过框架中增加”继承”槽来实现</li><li>横向联系：通过槽值或侧面值为另一个框架民</li></ul><p>框架表示的优缺点</p><ul><li>优点：<ul><li>结构性(不同于语义网络的结构性)、继承性、自然性</li><li>是语义网络的重要扩展</li><li>面向对象语言OO的产生</li></ul></li><li>缺点：<ul><li>缺乏过程性知识表示</li></ul></li></ul><h2 id="不确定性推理"><a href="#不确定性推理" class="headerlink" title="不确定性推理"></a>不确定性推理</h2><p>从不确定性的初始事实（证据），运用不确定性的知识，获得不确定性但却合理的结论，获得不确定性但却合理的结论。</p><h3 id="反绎推理"><a href="#反绎推理" class="headerlink" title="反绎推理"></a>反绎推理</h3><p>$P \rightarrow Q$ 与$Q$, 可能推出P</p><p>是一种寻找最佳解释的推理，是不可靠的推理。也称为溯因推理。</p><h4 id="基于谓词逻辑的推理"><a href="#基于谓词逻辑的推理" class="headerlink" title="基于谓词逻辑的推理"></a>基于谓词逻辑的推理</h4><p>三个重要假设（传统）</p><ul><li>谓词对领域描述是充分的；</li><li>知识库必须是一致的；</li><li>应用推理规则得到的信息，必须是单调增长的</li></ul><p>但如果假设不成立</p><h4 id="非单调推理"><a href="#非单调推理" class="headerlink" title="非单调推理"></a>非单调推理</h4><p>模态操作符的扩充</p><ul><li>unless操作符<ul><li>$ (p(x) \text{ unless } q(x)) \rightarrow r(x) $, $r(x) \rightarrow s(x)$</li><li>如果$p(W)$成立,且不知道$q(W)$是否为真，则$r(W)$, 进而$s(W)$为真</li><li>进一步已知$q(W)$为真，则$r(W)$和$s(W)$需要被撤回。</li><li>abnormal默认规则 $p(x) \text{ unless ab } p(x) \rightarrow r(x)$<ul><li>除非$p$有个反常的实例</li></ul></li></ul></li><li>is consistent with操作符<ul><li>$\forall x \ good_student(x) \wedge M \ study_hard(x) \rightarrow graduates(x) $ </li><li>如何判定”与….相一致”<ul><li>第一种方法：证明其反$\neg study_hard(x)$; 如果不能证明，则与…相一致</li><li>第二种方法：在有限空间上做启发式搜索</li></ul></li></ul></li><li>默认逻辑<ul><li>$A(x) \wedge : B(x) \rightarrow C(x)$</li><li>“如果A可被证实，且它与对B的假设相一致，则…”</li></ul></li></ul><h4 id="真值维护系统"><a href="#真值维护系统" class="headerlink" title="真值维护系统"></a>真值维护系统</h4><p>目标：维持推理系统的逻辑完整性</p><p>原理：通过存储每条推理的理由，再重新推断根据新的信念所得出的结论的支持情况</p><p>实现方式：</p><ol><li>时序回溯：从死状态或者末状态返回，系统的遍历所有可能路径。(低效!)</li><li>相关性指导回溯:直接回溯到出问题的点，并在那个状态 对解进行修正。<ul><li>TMS实现机制<ul><li>关联机制：将每条结论和其理由联系在一起</li><li>定位机制：当给定矛盾和其理由时，直接定位错误的假设。</li><li>回收机制：收回错误的假设</li><li>追溯机制：收回错误的假设的结论</li></ul></li></ul></li></ol><p>基于理由的真值维护系统JTMS</p><ul><li>检查理由网络<ul><li>通过问题求解程序的查询(是否相信命题p, 为什么要相信命题p, 哪些假设支持命题p)进行触发</li></ul></li><li>修改相关性网络<ul><li>由问题求解程序所提供的信息进行修改。添加新命题、<br>添加或删除前提等</li></ul></li><li>更新网络<ul><li>重新计算与现存理由相一致的命题</li></ul></li></ul><p>构造理由网络，并将网络与推理过程分离</p><p>理由网络</p><ul><li>结点：知识库中的信念</li><li>理由：支持结点上的信念</li><li>联系：IN,支持结点成立的信念集合; OUT,不支持结点成立的信念集合</li></ul><h4 id="基于最小模型的逻辑"><a href="#基于最小模型的逻辑" class="headerlink" title="基于最小模型的逻辑"></a>基于最小模型的逻辑</h4><p>模型:对所有变量赋值均满足谓词表达式集合S的解释</p><p>存在问题:实际的领域无需任意多的谓词</p><p>最小模型:对所有变量赋值满足谓词表达式S的模型中，最小的那个模型</p><h4 id="集合覆盖"><a href="#集合覆盖" class="headerlink" title="集合覆盖"></a>集合覆盖</h4><p>考虑反绎推理中解释的产生:一个反绎的解释为谓词的覆盖。</p><h4 id="确信度理论"><a href="#确信度理论" class="headerlink" title="确信度理论"></a>确信度理论</h4><p>MB(H|E):给定证据E时，假设H的可信度量</p><p>MD(H|E):给定证据E时，假设H的不可信度量</p><p>不确定性知识的表示：在CF模型中，知识是用产生式规则表示的，其一般形式为: IF E THEN H (CF(H|E))</p><h4 id="不-可信度量和概率"><a href="#不-可信度量和概率" class="headerlink" title="(不)可信度量和概率"></a>(不)可信度量和概率</h4><p>$MB(H|E) = \begin{cases} 1 &amp; P(H)=1 \ \frac{\max{P(H|E),P(H)}-P(H) }{1-P(H)} &amp; \text{otherwise} \end{cases}$</p><p>$MD(H|E) = \begin{cases} 1 &amp; P(H)=0 \ \frac{\min{P(H|E),P(H)}-P(H) }{-P(H)} &amp; \text{otherwise} \end{cases}$</p><ol><li>当$MB(H,E) &gt;0$时,有$P(H|E) &gt; P(H)$, $E$的出现增加了$H$的概率。</li><li>当$MD(H,E)&gt;0$时,有$P(H|E)&lt;P(H)$,$E$的出现降低了$H$的概率</li></ol><h4 id="确信度的性质"><a href="#确信度的性质" class="headerlink" title="确信度的性质"></a>确信度的性质</h4><p>互斥性：同一证据不可能既增加对$H$的信任程度，又同时增加对$H$的不信任程序，故$MB$和$MD$是互斥的。即有如下互斥性：</p><ul><li>当$MB(H,E)&gt;0$时，$MD(H,E)=0$; </li><li>当$MD(H,E)&gt;0$时，$MB(H,E)=0$;</li></ul><p>值域： $0 \le MB(H|E) \le 1$, $0 \le MD(H|E) \le 1$, $-1 \le CF(H|E) \le 1$ </p><p>典型值：</p><ol><li>当$CF(H|E)=1$时，有$P(H|E)=1$, $E$所对应证据的出现使$H$为真。此时，$MB(H|E)=1, MD(H|E)=0$</li><li>当$CF(H|E)=-1$时，有$P(H|E)=0$, $E$所对应证据的出现使$H$为真。此时，$MB(H|E)=0, MD(H|E)=1$</li><li>当$CF(H|E)=0$时，有$MB(H|E)=0, MD(H|E)=0$, $E$所对应证据的出现不证实$H$,也不否认$H$.</li></ol><p>CF(H | E) = MB(H | E) - MD(H | E)</p><p>实际应用中，P(H)和P(H|E)的值难以获得，因此CF(H|E)的值要 求由领域专家直接给出。</p><ol><li><p>否定证据不确定性的计算： $CF(\neg E) = - CF(E)$</p></li><li><p>组合证据不确定性的计算：</p><ol><li>合取：当规则前提(组合证据)是多个单一证据的组合，即$E = E_1 \land … \land E_n$时，若已知$CF(E_1),CF(E_2),…,CF(E_n)$ , 则$CF(E) = \min {CF(E_1,…,CF(E_n))}$</li><li>析取：当规则前提(组合证据)是多个单一证据的析取，即$E = E_1 \lor … \lor E_n$时，若已知$CF(E_1),CF(E_2),…,CF(E_n)$ , 则$CF(E) = \max {CF(E_1,…,CF(E_n))}$</li></ol></li></ol><p>不确定性的更新公式： $CF(H) = CF(H,E) \times \max{0,CF(E)}$</p><ol><li>若$CF(E)&lt;0$,则$CF(H)=0$,即该模型没考略$E$为假对$H$的影响</li><li>若$CF(E)=1$,则$CF(H) = CF(H,E)$, 即规则强度$CF(H,E)$实际上是在$E$为真时，$H$的确信度。</li></ol><h4 id="结论不确定性的合成"><a href="#结论不确定性的合成" class="headerlink" title="结论不确定性的合成"></a>结论不确定性的合成</h4><p>原理:多条知识支持同一个结论，且这些知识的前提相互独立， 结论的确信度不相同时，可利用不确定性的合成算法求出结论 的综合确信度。</p><p>设有知识: If E1 then H (CF(H|E1)), If E2 then H (CF(H|E2))</p><p>我们先计算每个CF(H): CF1(H) = CF(H|E1) <em> max{0,CF(E1)}, CF2(H) = CF(H|E2) </em> max{0,CF(E2)}, 然后用如下公式求E1与E2对H的综合确信度</p><p>$CF(H) = \begin{cases} CF1(H)+CF2(H)-CF1(H)<em>CF2(H) &amp; \text{若} CF1(H) \ge 0 \text{且} CF2(H) \ge 0 \  CF1(H)+CF2(H)+CF1(H)</em>CF2(H) &amp; \text{若} CF1(H) &lt; 0 \text{且} CF2(H) &lt; 0 \ \frac{CF1(H)+CF2(H)}{1- \min{|CF1(H)|, |CF2(H)|}} &amp; \text{若} CF1(H)\text{与} CF2(H)异号 \end{cases}$</p><p>合并计算公式所含特性：</p><ul><li>计算出来的CF值保证在1和-1之间</li><li>在合并相反符号的CF时，它们能够相互削弱</li><li>合并后的CF是一个单调函数</li></ul><h3 id="证据理论"><a href="#证据理论" class="headerlink" title="证据理论"></a>证据理论</h3><p>原理:基于收集到的证据数量，将概率论中的单点赋值扩展为集合赋值，<br> 处理由“不知道”所引起的不确定性。</p><p>形式定义:考虑命题集，赋给区间值[belief, plausibility]，每个命题的可信度(belief<br>measure)必须在这个区间内。</p><ol><li>从相关问题的主观概念得到其可信度的思想</li><li>基于相互独立的证据时，合并可信度的规则</li></ol><h4 id="信任函数"><a href="#信任函数" class="headerlink" title="信任函数"></a>信任函数</h4><p>Bel: $ 2^{\Omega} \rightarrow [0,1]$,  $Bel(A) = \sum\limits_{B \subseteq A} m(B)$, 其中 $A \subseteq \Omega$.</p><p>Bel为下限函数，Bel(A)表示对$A$的总信任度</p><h4 id="似然函数："><a href="#似然函数：" class="headerlink" title="似然函数："></a>似然函数：</h4><p>Pl: $2^{\Omega} \rightarrow [0,1]$, $PI(A) = 1- Bel(\neg A)$, 其中$A \subseteq \Omega$, $\neg A = \Omega -A$</p><p>$PI$为上限函数，$Bel(\neg A)$表示对$\neg A$的总信任度， 即$A$为假的信任度，因此$PI(A)$ 表示对$A$为非假的信任度。</p><h4 id="信任函数与似然函数"><a href="#信任函数与似然函数" class="headerlink" title="信任函数与似然函数"></a>信任函数与似然函数</h4><p>$PI(A) \ge Bel(A)$</p><p>称$Bel(A)$ 和 $PI(A)$为对A信任程度的下限和上限，记为：$A[Bel(A),PI(A)]$</p><p>$PI(A) - Bel(A)$:描述”不知道”的情况</p><h4 id="Dempster证据合并规则"><a href="#Dempster证据合并规则" class="headerlink" title="Dempster证据合并规则"></a>Dempster证据合并规则</h4><p>对于$\forall A \subseteq \Omega, \Omega$上的两个$m$函数$m_1$, $m_2$,其Dempster合成规则为: $m_1 \oplus m<em>2 (A) = \frac{1}{K} \sum\limits</em>{B \cap C =A} m_1(B) \times m<em>2(C)$.  $K= \sum\limits</em>{B \cap C \not= \emptyset} m_1(B) \times m<em>2(C) = 1- \sum\limits</em>{B \cap C = \emptyset} m_1(B) \times m_2(C)$ </p><ul><li>$K$为冲突因子，反应证据的冲突程度</li><li>$\frac{1}{K}$为归一化因子，相当于在组合中将空集(冲突)等比例分配给各个集合</li><li>前提：证据是相互独立的。</li></ul><h2 id="贝叶斯网络"><a href="#贝叶斯网络" class="headerlink" title="贝叶斯网络"></a>贝叶斯网络</h2><p>先验概率 vs 后验概率</p><ul><li><p>先验概率：在得到任何新证据之前，统计的事件概率。即非条件概率，P(事件)</p></li><li><p>后验概率：给定新证据之后，统计的事件概率。即条件概率，P(事件|证据)。</p></li></ul><p>演绎推理 vs 归纳推理</p><ul><li>演绎推理：不要求前件是真实的</li><li>归纳推理：要求前件必须为真，结论未必为真(从特殊到一般)</li><li>贝叶斯决策(贝叶斯归纳推理)：<ul><li>已知先验概率和类条件概率表达式;</li><li>转换成后验概率;</li><li>根据后验概率大小进行决策/推理。</li></ul></li></ul><p>贝叶斯定理： 通过先验概率和类条件概率表达式，计算后验概率</p><h3 id="贝叶斯信念网络"><a href="#贝叶斯信念网络" class="headerlink" title="贝叶斯信念网络"></a>贝叶斯信念网络</h3><p>贝叶斯网络</p><ul><li>是一个有向无环图</li><li>节点代表随机变量</li><li>边代表节点间的关系(因果关系)，用条件概率表达关系的强<br>度。</li><li>没有父节点的用先验概率表达信息。</li></ul><p>贝叶斯网络中的独立性：</p><ul><li>顺序连接<ul><li>$Z \rightarrow Y \rightarrow X$</li><li>给定$Y$的知识，那么$X$和$Z$独立。如果$Y$未知，则$X$和$Z$不独立。</li></ul></li><li>分支连接<ul><li>$Y \rightarrow X, Y \rightarrow Z$</li><li>给定$Y$的知识，那么$X$和$Z$独立。如果$Y$未知，则$X$和$Z$不独立。</li></ul></li><li>汇合连接<ul><li>$X \rightarrow Y, Z \rightarrow Y$</li><li>$Y$ 未知时，$X$和$Z$独立，但给定$Y$, $X$和$Z$不独立</li></ul></li><li>分支和汇合<ul><li>$Z \rightarrow U, Z \rightarrow V$, $U \rightarrow X, V \rightarrow X$</li><li>仅给定$U$, $Z$和$X$不独立。当且仅当给定$U$和$V$时，$Z$和$X$独立。</li></ul></li></ul><p>d-可分</p><ul><li><p>判断贝叶斯网络中任意两个节点之间是否独立</p></li><li><p>定义：$A$和$B$被一组随机变量E d-可分，当且仅当他们之间的所有路径都是堵塞的。</p></li><li><p>堵塞：如果$A$和$B$上有这样的一个中间节点$V$,那么路径是堵塞的。$V$满足以下两个属性之一：</p><ol><li><p>连接是顺序的或者分支的，$V$在$E$中</p></li><li><p>连接是汇合的，则$V$和它的子节点都不在$E$中</p></li></ol></li></ul><p>网络结构确定：</p><ul><li>选择一组刻画问题的随机变量${ X_1, X_2,…,X_n}$</li><li>确定一个变量顺序$a = &lt; X_1, X_2,…,X_n&gt;$</li><li>参数学习从一个空图出发，按照顺序$a$ 逐个将变量加入$\zeta$中</li><li>假设当前需要加入的是变量$X_i$,此时$\zeta$中已经包含变量$X_1,X<em>2,…,X</em>{i-1}$<ul><li>在$X_1,X<em>2,…,X</em>{i-1}$选择一个尽可能小的子集$\pi(X_i)$, 使得假设”给定$\pi(X_i)$, $X_i$ 与$\zeta$ 中的其他变量条件独立”合理</li><li>从$\pi(X_i)$ 中的每一个节点添加一条指向$X_i$的有向边</li></ul></li></ul><p>$a$的顺序会影响网络的结构。</p><p>贝叶斯信念网络推理</p><ul><li>因果推理(自顶向下的推理)<ul><li>由原因推出结论，即根据一定的原因，推理出在该原因情况下结果发生的概率。</li></ul></li><li>诊断推理(自底向上的推理)<ul><li>由结论推出原因，即根据产生的结果，利用贝叶斯网推理算法，得出导致该结果的原因的概率</li></ul></li><li>支持推理<ul><li>对所发生的现象提供解释，目的是分析原因之间的相互影响。</li></ul></li></ul><h2 id="马尔科夫逻辑网络"><a href="#马尔科夫逻辑网络" class="headerlink" title="马尔科夫逻辑网络"></a>马尔科夫逻辑网络</h2><h3 id="Markov链"><a href="#Markov链" class="headerlink" title="Markov链"></a>Markov链</h3><p>考虑一个$N$(有限)状态${s_1,s_2,…,s_n}$的系统：在离散的时间序列中${t_1,t_2,…}$, 其在时间$t$的状态记为$X_t$. </p><p>系统在时间$t$处在状态$s_j(1 \le j \le n)$ 的概率取决于其在时间${1,2,..,t-1}$的状态： $P(X_t = s_k | X_1,X<em>2,…,X</em>{t-1})$ </p><p>一阶马尔科夫链：$P(X_t = s_k | X_1,X<em>2,…,X</em>{t-1}) = P(X_t = s<em>k | X</em>{t-1})$ </p><h3 id="Markov网"><a href="#Markov网" class="headerlink" title="Markov网"></a>Markov网</h3><p>有向图+概率分布：Bayesian Network </p><p>无向图+概率分布：Markov Network(Markov Random Field, MRF), $G=(V,E)$ </p><p>顶点：随机变量$V$</p><p>边：变量间的依赖关系$E$ </p><p>团(Clique):各边所在的最大全联通子图(必须全连接)</p><p>势函数：为非负函数，表示团的一个状态</p><p>联合分布函数</p><ul><li>吉布斯测度：已知一种分配方案$x$,求MLN刚好为该情况的联合分布概率<ul><li>$P(X=x) = \frac{1}{Z} \prod\limits_{k} f<em>k(X</em>)  $</li></ul></li><li>配分函数：所有分配方案的测度总和<ul><li>$Z = \sum\limits<em>{x \in \mathcal{X}} \prod\limits</em>{k} f<em>k(x</em>)$ </li></ul></li></ul><p>对数线性模型：</p><ul><li>对数线性模型：马尔可夫网络常表示为该模型，通过引入特征函数$\phi_k$ <ul><li>$f_k = \exp(w_k^T \phi<em>k(x</em>))$</li><li>$P(X=x) = \frac{1}{Z} \exp(\sum\limits_k w<em>k^T \phi)k(x</em>)$</li></ul></li><li>配分函数：<ul><li>$Z= \sum\limits_{x \in \mathcal{X}} \exp(w_k^T \phi<em>k(x</em>))$ </li></ul></li><li>将每个团的势函数表示为指数函数，指数项为对应团的加权特征量</li></ul><p>在马尔可夫网络中，我们可以使用类似的直觉，但因为其中没有有方向的边（箭头），所以其条件独立陈述相对简单——如果节点 A 和 B 之间没有路径能使得该路径上的所有节点都被观察到，那么 A 和 B 就是相互独立的。换种说法：如果在 A 和 B 之间至少有一条路径上的所有中间节点都未被观察到，那么 A 和 B 就不是相互独立的。</p><h3 id="Markov逻辑网的独立性"><a href="#Markov逻辑网的独立性" class="headerlink" title="Markov逻辑网的独立性"></a>Markov逻辑网的独立性</h3><ul><li>Pairwise Markov Property: 给定所有其他变量，任意两个不相邻变量条<br>件独立。<ul><li>$X_u \parallel X<em>v | X</em>{V \backslash {u,v} } $ If ${ u,v } \notin E$</li></ul></li><li>Local Markov Property:一个变量如果给定所有邻居变量后与所有其他<br>变量条件独立。<ul><li>$X<em>v \parallel X</em>{V \backslash cl(v)} | X_{ne}(v)$</li></ul></li><li>Global Markov Property:A、B两个子集间任何一条路径都经过子集S，<br>则给定S后，A、B两个子集相互条件独立。<ul><li>$X_A \parallel X_B | X_S$ </li></ul></li></ul><p>一个无向图$G=(V,E)$,是马尔科夫网络的充分必要条件是：当且仅当其满足以上三条独立性质</p><h3 id="构建马尔科夫网络"><a href="#构建马尔科夫网络" class="headerlink" title="构建马尔科夫网络"></a>构建马尔科夫网络</h3><ul><li>方法一：基于Pairwise Markov Property<ul><li>如果满足下面条件，则在$X$和$Y$之间加边：<ul><li>$P \not\models (X \perp Y | \mathcal{X} - {X,Y})$.</li></ul></li></ul></li><li>方法二：基于Local Markov Property<ul><li>集合$U$是$X$的马尔科夫毯(Markov blanket, $X$的邻居节点集合)，给定$U$, $X$独立于余下的变量；<ul><li>$(X \perp \mathcal{X} - {X} -U | U) \in \mathcal{I}(P)$ </li></ul></li></ul></li></ul><h3 id="马尔科夫逻辑网"><a href="#马尔科夫逻辑网" class="headerlink" title="马尔科夫逻辑网"></a>马尔科夫逻辑网</h3><p>一个可能世界(A Possible World):为每个可能的闭谓词指定真值。</p><p>可满足:一个一阶公式是可满足的，当且仅当该公式至少在一个世界中为真。</p><p>一阶逻辑的推理:判断一个知识库中是否包含公式F，即F是否在 所有满足知识库的世界中为真。</p><p>Markov逻辑网(Markov Logic Networks, MLNs): Markov网+一阶逻辑，其本质是公式附加权值的一阶逻辑知识库</p><p>基本思想：将一阶逻辑的限制放松，即一个可能世界违反公式越多，其发生的概率越小，但未必为0。</p><p>公式权重：表示公式限制强度的大小。权值越大，满足该公式世界的发生概率与不满足该公式世界的发生概率之间的差越大。</p><h4 id="Markov逻辑网的定义"><a href="#Markov逻辑网的定义" class="headerlink" title="Markov逻辑网的定义"></a>Markov逻辑网的定义</h4><p>马尔科夫逻辑网$L$:是$(F_i,w_i)$对的集合，其中$F_i$代表一阶逻辑规则，$w_i$是用一个实数表示权重；有限的常数集为$C= {c_1,c_2,…,c_n}$</p><p>马尔科夫逻辑网$M_{L,C}$: </p><ul><li>L中的任意闭原子(ground atom)都对应了$M_{L,C}$中的一个二值节点。若此闭原子为真，则对应的二值节点取值为1;若为假，则取值为0。</li><li>L中的任意闭规则(ground formula)都对应着一个特征值。若此闭规则为真，则对应的特征值为1;若为假，则特征值为0。并且这个特征值$F_i$ 的权重为二元项中该规则对应的权重$w_i$ </li></ul><h4 id="MLN特例：一阶逻辑"><a href="#MLN特例：一阶逻辑" class="headerlink" title="MLN特例：一阶逻辑"></a>MLN特例：一阶逻辑</h4><ul><li>只有一条规则<ul><li>$\forall x \ R(x) \rightarrow S(x)$, 权重为$w$,常数集$C= {A}$</li></ul></li><li>只有4个事件<ul><li>${\neg R(A), \neg S(A) }$, ${\neg R(A),  S(A) }$, ${R(A), \neg S(A) }$, ${R(A), S(A) }$</li></ul></li></ul><p>$\Pr({ { R(A), \neg S(A) } }) = 1/(3e^w + 1)$, 其他均为$e^w/(3e^w+1)$ </p><h3 id="MLN推理"><a href="#MLN推理" class="headerlink" title="MLN推理"></a>MLN推理</h3><ul><li>条件概率查询(Conditional Probability Query)<ul><li>证据：$\vec{E} = \vec{e}$</li><li>查询：变量子集$\vec{Y}$</li><li>计算：$P(\vec{Y}| \vec{E} =\vec{e})$ </li></ul></li><li>最大化后验(Maximum a Posterior, MAP)<ul><li>证据：$\vec{E} = \vec{e}$</li><li>查询：所有其他变量$\vec{Y} (\vec{Y} = {X_1,X_2,…X_n} - \vec{E})$ </li><li>计算：$MAP(\vec{Y} | \vec{E} = \vec{e}) = \arg \max_{\vec{y}}P(\vec{Y}=\vec{y} | \vec{E} = \vec{e})$ </li></ul></li></ul><p>贝叶斯公式：$P(A,B) = P(A) P(B|A)$ </p><p>边缘概率求取公式$P(A) = \sum_B P(A,B)$ </p><p>BN中的和积(Sum-Product)</p><ul><li>我们可以根据任意一个贝叶斯网络写出所有节点对应的随机变量的联合概率分布为：$p(\vec{x}) = \prod\limits_{k=1}^K p(x_k | pa_k)$ , 其中$pa_k$为节点$x_k$的所有父节点构成的集合。</li></ul><p>MN中的和积</p><h3 id="变量消除算法"><a href="#变量消除算法" class="headerlink" title="变量消除算法"></a>变量消除算法</h3><ul><li>精确算法<ul><li>变量消除(Variable elimination)</li></ul></li><li>近似算法<ul><li>信念传播(Belief propagation)</li><li>随机采样(Random sampling)<ul><li>Markov chain</li><li>Gibbs sampling</li></ul></li></ul></li></ul><h2 id="符号学习"><a href="#符号学习" class="headerlink" title="符号学习"></a>符号学习</h2><h3 id="概念学习-Concept-Learning"><a href="#概念学习-Concept-Learning" class="headerlink" title="概念学习(Concept Learning)"></a>概念学习(Concept Learning)</h3><p>定义：给定样例集合，以及每个样例是否属于某个概念，自动地推断出该概念的一般定义。</p><p>实例集合$X$: 如PPT中用六个属性表示</p><p>目标概念$c$: 定义在实例集上的布尔函数：$c: X \rightarrow {0,1}$</p><p>训练样例：正例$(c(x)=1)$, 反例$(c(x)=0)$</p><p>假设集$H$:每个假设$h$表示$X$上定义的布尔函数$h: X \rightarrow {0,1}$</p><p>概念学习：寻找一个假设$h$, 使对于$X$中的所有$x$, $h(x)=c(x)$</p><h4 id="实例空间和假设数"><a href="#实例空间和假设数" class="headerlink" title="实例空间和假设数"></a>实例空间和假设数</h4><p>最一般的假设:</p><p>最特殊的假设：</p><p>实例空间：</p><p>假设空间：</p><p>归纳学习假设：任一假设如果在足够大的训练样例集合中能很好的逼近目标概念函数，它也能在未见实例中很好的逼近目标概念。</p><h4 id="假设的一般到特殊序"><a href="#假设的一般到特殊序" class="headerlink" title="假设的一般到特殊序"></a>假设的一般到特殊序</h4><p>$h1=<sunny,?,?,strong,?,?>$, $h2=<sunny,?,?,?,?,?>$, </sunny,?,?,?,?,?></sunny,?,?,strong,?,?></p><p>$h2$包含的实例数多于$h_1$ </p><p><strong>更泛化</strong>(more general greater than or equal to): 令$h_j$和$h_k$是定义在$X$上的布尔函数，若$h_j \ge_g h_k$ 当且仅当，$(\forall x \in X)[h_k(x)=1 \rightarrow h_j(x)=1]$</p><p><strong>严格泛化</strong>： $h_j &gt;_g h_k $</p><p><strong>更特化</strong>： $h_j \ge_s h_k$</p><h4 id="Find-S-寻找极大特殊假设"><a href="#Find-S-寻找极大特殊假设" class="headerlink" title="Find-S:寻找极大特殊假设"></a>Find-S:寻找极大特殊假设</h4><ol><li>将$h$初始化为$H$中最特殊的假设</li><li>对每个正例$x$ <ul><li>对$h$的每个属性约束$a_i$，如果$x$满足$a_i$ 那么不做任何处理，否则将$h$中$a_i$替换为$x$满足的另一个最一般的约束</li></ul></li><li>输出假设$h$ </li></ol><h3 id="变型空间"><a href="#变型空间" class="headerlink" title="变型空间"></a>变型空间</h3><ul><li><p>一致(Consistent): 一个假设$h$与训练样例集合$D$一致 当且仅当，$Consistent(h,D) \equiv (\forall <x,c(x)> \in D) h(x)=c(x)$ </x,c(x)></p></li><li><p>变型空间(version space):关于假设空间$H$和训练样例集合$D$的变型空间，是$H$中与训练样例$D$一致的所有假设构成的子集： $VS_{H,D} = { h\in H | Consistent(h,D) }$</p></li></ul><h4 id="列表消除算法：List-Then-Eliminate"><a href="#列表消除算法：List-Then-Eliminate" class="headerlink" title="列表消除算法：List-Then-Eliminate"></a>列表消除算法：List-Then-Eliminate</h4><ol><li>变型空间VersionSpace,包含$H$中所有假设的列表</li><li>对每个样例$<x,c(x)>$: 从变型空间中移除$h(x) \not=c(x)$的假设$h$ </x,c(x)></li><li>输出VersionSpace中的假设列表</li></ol><p>缺点：要列出所有假设，在实际中往往不可能</p><p>极大泛化(maximally general): $H$中与训练样例集合$D$一致的极大一般成员的集合。 $G={g\in H | Consistent(g,D)\wedge (\neg \exists g’ \in H [ (g’ &gt;_g g) \wedge Consitent(g’,D)]  ) }$</p><p>极大特化(maximally specific):$H$中与训练样例集合$D$一致的极大特殊成员的集合：$S \equiv { s\in H | Consistent(s,D) \wedge (\neg \exists s’ \in H [(s &gt;_s s’) \wedge Consitent(s’,D) ]) }$ </p><h4 id="变型空间表示定理"><a href="#变型空间表示定理" class="headerlink" title="变型空间表示定理"></a>变型空间表示定理</h4><p>表示定理：令$X$为任意的实例集合，$H$为$X$上定义的布尔函数集合。令$c: X \rightarrow [0,1]$为$X$上定义的任一目标概念，并令$D$为任意训练样例的集合${<x,c(x)> }$. 对所有的$X,H,c,D$以及良好定义的$S$和$G$: $VS_{H,D} \equiv { h\in H | (\exists s \in S)(\exists g \in G) [g &gt;_g h &gt;_s s]  }$</x,c(x)></p><p>正例和反例的作用</p><ul><li>正例用于泛化，搜索$S$集合</li><li>反例用于特化，缩小$G$集合</li></ul><h4 id="候选消除算法：Candidate-Eliminate"><a href="#候选消除算法：Candidate-Eliminate" class="headerlink" title="候选消除算法：Candidate-Eliminate"></a>候选消除算法：Candidate-Eliminate</h4><ul><li>如果$d$是正例<ul><li>从$G$中移去所有和$d$不一致的假设</li><li>对$S$中每一个与$d$不一致的假设$s$<ul><li>从$S$中移除$s$</li><li>把$s$的所有极小泛化假设$h$加入到$S$中， 其中$h$满足与$D$ 一致，而且$G$中的某个成员比$h$更一般</li><li>从$S$中移去这样的假设，它比$S$中另一假设更一般</li></ul></li></ul></li><li>如果$d$是反例<ul><li>从$S$中移去所有和$d$不一致的假设</li><li>对$G$中每一个与$d$不一致的假设$g$<ul><li>从$G$中移除$g$</li><li>把$g$的所有极小特化假设$h$加入到$G$中，其中$h$满足与$D$一致，而且$S$中的某个成员比$h$更特殊</li><li>从$G$中移去这样的假设，它比$G$中另一假设更特殊</li></ul></li></ul></li></ul><h3 id="归纳偏置"><a href="#归纳偏置" class="headerlink" title="归纳偏置"></a>归纳偏置</h3><h3 id="决策树学习"><a href="#决策树学习" class="headerlink" title="决策树学习"></a>决策树学习</h3><p>决策树学习：</p><ul><li>实例：”属性-值”对表示，应用最广的归纳推理算法之一</li><li>目标函数具有离散的输出值</li><li>很好的健壮性(样例可以包含错误，也可以处理缺少属性值的实例)</li><li>能够学习析取表达式</li></ul><p>算法：</p><ul><li>ID3，Assistant,C4.5</li><li>搜索一个完整表示的假设空间，表示为多个If-then规则</li></ul><p>归纳偏置</p><ul><li>优先选择较小的树</li></ul><p>信息增益： $Entropy(S) = \sum\limits_{i=1}^c -p_i \log_2{p_1}$ </p><h2 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h2><p>激活函数</p><p>A saturating activation function squeezes the input.</p><p>$f$ is non-saturating iff ($|\lim\limits<em>{z \rightarrow - \infty} f(z)| = + \infty$) $\lor (|\lim\limits</em>{z \rightarrow + \infty } f(z)| = + \infty) $  </p><ul><li>饱和型激励函数：tanh,Sigmoid<ul><li>缺点： <ol><li>梯度消失</li><li>非以0为中心</li><li>指数计算代价大</li></ol></li></ul></li><li>非饱和型激励函数：ReLU,ELU,…</li></ul><p>感知机的学习方法：</p><ul><li>$c$是常数，表示学习率</li><li>$d$是期望的输出，取值为1或-1</li><li>$sign$是感知机的输出，取值为1或-1<ul><li>$\Delta W_i = c(d-sign(\sum w_i * x_i)) X_i$</li><li>期望输出和实际输出相同，不改变权值</li><li>实际输出为-1,期望输出为+1, 则增加$2cX_i$</li><li>实际输出为+1,期望输出为-1, 则减少$2cX_i$ </li></ul></li></ul><p>感知机学习缺点：感知机模型属于单层神经网络，它不能解决一类非线性可分的问题。典型的例子就是异或。</p><p>二层神经网络可以表达所有的布尔函数</p><h3 id="Delta规则"><a href="#Delta规则" class="headerlink" title="Delta规则"></a>Delta规则</h3><p>Delta规则是基于错误(误差)平面的，错误(误差)平面是神经 网络所表示的函数在数据集上的累积误差。每一个神经网络 权值向量都对应误差平面中的一个点。</p><p>应用delta规则时，激励函数必须是连续的和可微分的。</p><p>$\Delta W_k = c(d_i - O_i) f’(net_i) * X_k$</p><p>Delta规则分析</p><ul><li>学习常数c对delta规则的性能有很重要的影响，c决定了在一 步学习过程中权值变化的快慢，c越大，权值朝最优值移动 的速度越快。然而，c过大会越过最优值或在最优值附近震 荡。</li><li>尽管delta规则本身不能克服单层神经网络的局限，但是它的 一般形式是反传算法(BP)的核心，反传算法是多层神经网络 中的学习算法。</li><li>梯度下降(gradient descent)<ul><li>搜索无限假设空间的有效策略</li><li>无限假设空间：连续的参数/可微</li><li>缺点：收敛速度慢/局部极小</li></ul></li><li>随机梯度下降(stochastic gradient descent)<ul><li>每次随机选择样本更新权重</li><li>不需要计算总误差，快/可以有效避免局部极小</li></ul></li></ul><h3 id="多层神经网络"><a href="#多层神经网络" class="headerlink" title="多层神经网络"></a>多层神经网络</h3><p>隐藏层神经元实际为特征检测算子 (feature detector)，在多层神经网络 的学习过程中，隐藏层神经元开始 逐步“发现”刻画训练数据的突出 特征。</p><h3 id="反向传播算法-Back-Propagation"><a href="#反向传播算法-Back-Propagation" class="headerlink" title="反向传播算法(Back Propagation)"></a>反向传播算法(Back Propagation)</h3><ul><li>前向阶段：网络突触的权值固定，输入信号在网络中正向一层一层传播，直到到达输出端，获得网络的输出。</li><li>反向阶段：通过比较网络的输出与期望输出，产生一个误差信号。误差信号通过网络反向一层一层传播，在传播过程中对网络突触的权值进行修正。</li></ul><p>BP神经网络：</p><ul><li>三层或三层以上结构</li><li>无反馈</li><li>层内无互连</li><li>输入层+输出层+隐含层</li><li>采用误差反向传播学习算法</li></ul><h2 id="遗传算法"><a href="#遗传算法" class="headerlink" title="遗传算法"></a>遗传算法</h2><p>遗传算法GA:受生物进化启发的学习算法：</p><ul><li>通过对当前最好的假设重组来产生后续假设</li><li>生成并测试(generate-and-test)的柱状搜索(beam-search)</li></ul><p>假设的表示：可以用01位串表示</p><p>适应函数(fitness)</p><p>染色体的选择：</p><ul><li>基于适应度函数的选择<ul><li>轮盘赌选择(roulette wheel selection)<ul><li>与适应度成比例选择</li></ul></li><li>锦标赛选择(tournament selection)<ul><li>按预定义概率$p$选择较大适应度的假设</li><li>按概率1-p选择其他假设</li></ul></li><li>排序选择(rank selection)<ul><li>根据序而不是适应度进行选择</li></ul></li></ul></li></ul><p>遗传算子(GA operator): 对从当前群体中选择的染色体进行重组，以产生后代</p><p>交叉： 选择两个候选个体，分解每一个个体，然后交换分量形成两个新的候选个体</p><p>变异：选择一个候选个体，随机的选择一位，然后取反</p><p>遗传算法的优势：</p><ul><li>无需理解问题内部的相关性和因果性</li><li>以一个随机的群体开始，以适应度作为某种”启发式</li><li>”进化论”保证整个种群的演化</li></ul><p>未解决的问题：</p><ul><li>表示的问题:编码不规范及编码存在表示的不准确性</li><li>约束的问题:单一的遗传算法编码不能全面地将优化问题的约束表 示出来。考虑约束的一个方法就是对不可行解采用阈值，这样，计 算的时间必然增加</li><li>搜索效率的问题:遗传算法通常的效率比其他传统的优化方法低; 遗传算法容易出现过早收敛</li><li>理论保证的问题:遗传算法对算法的精度、可行度、计算复杂性等 方面，还没有有效的定量分析方法</li></ul><h3 id="模式定理"><a href="#模式定理" class="headerlink" title="模式定理"></a>模式定理</h3><p>Short schemata with large fitness will increase their representation in the<br>population during the evolution</p><p>模式H的阶，o(H):模式H中确定位置的个数</p><p>模式H的长度，d(H):模式H中第一个确定的位置到最后一个确定位置的距离</p><h4 id="模式的进化"><a href="#模式的进化" class="headerlink" title="模式的进化"></a>模式的进化</h4><p>$m(s,t)$ 表示在第$t$代种群$p_t$中模式$s$的实例数量</p><p>模式理论：</p><ul><li>根据GA的原理，去推断$m(s,t+1)$的期望值</li><li>$f(h)$: 染色体$h$的适应度</li><li>$\bar{f}(t)$:第$t$代种群染色体的平均适应度</li><li>$n$:种群中个体的总数量</li><li>$h \in s \cap p_t$: 染色体$h$属于模式$s$,又是$p_t$的成员</li><li>$\hat{u}(s,t):$ 第$t$代中模式$s$的染色体的平均适应度</li></ul><p>轮盘赌选择：$\Pr(h) = \frac{f(h)}{\sum\limits_{i=1}^n f(h_i)} = \frac{f(h)}{n\bar{f}(t)}$ </p><p>选择的假设是模式$s$的实例的概率：$\Pr(h \in s) = \sum\limits_{h \in s \cap p_t}\frac{f(h)}{n\bar{f}(t)} = \frac{\hat{u}(s,t)}{n \bar{f}(t)} m(s,t)$ </p><p>如果选择$n$次，得到$s$的实例的期望值是$\mathbb{E}[m(s,t+1)] = \frac{\hat{u}(s,t)}{\bar{f}(t)} m(s,t)$ </p><ul><li>单点交叉的概率$p_c$</li><li>任意染色体任意位变异的概率$p_m$</li><li>模式$s$的阶(确定位数的个数) o(s)</li><li>模式$s$的长度(从最左确定位到最右确定位的距离)$d(s)$</li><li>染色体的长度$l$</li></ul><p>模式定理：$E[m(s,t+1)] \ge \frac{\hat{u}(s,t)}{\bar{f}(t)} m(s,t) (1 - p_c \frac{d(s)}{l-1}) (1-p_m)^{o(s)}$ </p><ul><li>适应度越高的模式影响力越大</li><li>包含较少确定位的模式(也就是有较多#)影响力越大</li><li>确定位彼此靠近的模式影响力越大</li></ul><h2 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h2><p>强化学习的本质：奖惩和试错(Trial and Error)</p><h3 id="Markov-Decision-Process-MDP"><a href="#Markov-Decision-Process-MDP" class="headerlink" title="Markov Decision Process(MDP)"></a>Markov Decision Process(MDP)</h3><ul><li>S- set of states, 状态集合</li><li>A- set of actions, 动作集合 </li><li>$\delta$- transition probability, 状态转移概率</li><li>$R$- immediate reward function, 即时奖赏函数</li></ul><p>MDP模型-返回函数</p><ul><li>有限函数(Finite Horizon): <ul><li>return= $\sum\limits_{1 \le i \le H} R(s_i,a_i)$ </li></ul></li><li>无穷窗口(Infinite Horizon)<ul><li>有折扣： return = $\sum\limits_{i=0}^{\infty} \gamma^i R(s_i,a_i)$ </li><li>无折扣：return= $ \frac{1}{N}\sum\limits_{i=0}^{N-1} R(s_i,a_i), N \rightarrow \infty$ </li></ul></li><li>通常返回函数是即时奖赏值的线性组合</li></ul><p>MDP模型-动作选择：</p><ul><li>目标<ul><li>最大化期望返回(Return)</li></ul></li><li>策略<ul><li>状态到动作的映射($\pi : S \rightarrow A$)</li></ul></li><li>最优策略<ul><li>如果$\pi$是最优策略，则其从任一状态出发，均是最优的策略</li></ul></li><li>定理：必然存在着一个确定性的最优策略</li></ul><p>监督学习 VS 强化学习</p><ul><li>监督学习<ul><li>(正/反例)在样本上的分布是确定的。</li></ul></li><li>强化学习<ul><li>(状态/奖赏)的分布是策略依赖的(Policy Dependent!!!)</li><li>策略上小的变换都会导致返回值的巨大改变</li></ul></li></ul><h3 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h3><p>给定一个完全已知的MDP模型</p><ul><li>策略评估(Policy Evaluation)<ul><li>给定一个策略$\pi$, 评估其返回值</li></ul></li><li>最优控制(Optimal Control)<ul><li>寻找一个最优策略$\pi^*$(从任一状态出发，其返回值都为最大)</li></ul></li></ul><p>$V^{\pi} (s):$ 从s状态出发，采用$\pi$策略，所获得的期望返回值</p><p>$Q^{\pi} (s,a):$ 从$s$状态出发，采用$a$动作，继而采用$\pi$策略，所获得的期望返回值</p><p>最优值函数($V^<em>(s)$ 和 $Q^</em>(s,a)$): 采用最优策略$\pi^*$所获得的期望返回值</p><p>定理：策略$\pi$为最优策略当且仅当，在每一个状态s, $V^*(s) = \max_{\pi} V^{\pi} (s)$, $V^{\pi}(s) = \max_a Q^{\pi}(s,a)$ </p><p>最优策略： $\pi^* =\arg \max \limits_{\pi} V^{\pi}(s), (\forall s) $ </p><p>Bellman等式(有折扣无限窗口)：</p><ul><li>$V^{\pi}(s) = E_{s’ ~ \pi(s) } [R(s,\pi(s)) + \gamma V^{\pi} (s’)]$</li><li>重写之后：</li><li>$V^{\pi}(s) = E[R(s,\pi(s))] + \gamma \sum_{s’} \delta (s, \pi(s),s’) V^{\pi} (s’) $</li></ul><p>动态规划-最优控制</p><ul><li>贪心策略<ul><li>$\pi(s) = \arg \max_a Q^{\pi} (s,a)$</li></ul></li><li>$\varepsilon-$贪心策略<ul><li>以$1-\varepsilon$概率选择， $\pi(s) = \arg \max_a Q^{\pi} (s,a)$</li><li>以$\varepsilon$概率选择其他动作</li></ul></li></ul><h3 id="Monte-Carlo策略"><a href="#Monte-Carlo策略" class="headerlink" title="Monte Carlo策略"></a>Monte Carlo策略</h3><p>策略评价：</p><ul><li>目标：学习$V^{\pi}(s)$</li><li>给定：在访问状态$s$, 采用策略$\pi$下，获得的若干经验</li><li><p>在访问状态$s$后，对所获得的返回，进行平均</p></li><li><p>Every-Visit MC: 在一次经验中，对每次访问到的$s$进行平均</p></li><li>First-Visit MC: 在一次经验中，只对首次访问到的$s$ 进行平均</li></ul><p>策略优化：$V(s_t) \leftarrow V(s_t) + \alpha(R_t - V(s_t))$ </p><p>最优控制：</p><ul><li>MC策略迭代：使用MC方法对策略进行评估，计算值函数</li><li>MC策略修正：根据值函数(或者状态-动作对值函数)，采用贪心策略进行策略修正。</li></ul><h3 id="时差学习-Temporal-Difference-Learning"><a href="#时差学习-Temporal-Difference-Learning" class="headerlink" title="时差学习(Temporal-Difference Learning)"></a>时差学习(Temporal-Difference Learning)</h3><p>蒙特卡洛的方法可以看做是最大步数的时差学习</p><p>单步时差方法：$V(s_t) = V(s_t) + \alpha[r<em>t + \gamma V(s</em>{t+1}） - V(s_t)]$ </p><p>$R_t^{(2)} = r<em>t + \gamma V(s</em>{t+1})$ </p><p>N步时差方法：$R<em>t^{(n)} = \sum\limits</em>{i=0}^{n-1} \gamma^i r<em>{t+i} + \gamma^n V(s</em>{t+n})$</p><p>N步回退方法：$R_t $</p><h4 id="Bootstaps和Sampling"><a href="#Bootstaps和Sampling" class="headerlink" title="Bootstaps和Sampling"></a>Bootstaps和Sampling</h4><p>Bootstraps</p><ul><li>通过一个估计值进行更新</li><li>动态规划/时差学习中采用</li><li>蒙特卡洛方法不采用</li></ul><p>采样</p><ul><li>不通过估计值进行更新，而根据经验进行更新</li><li>蒙特卡洛方法/时差学习中采用</li><li>动态规划中不采用</li></ul><h2 id="博弈"><a href="#博弈" class="headerlink" title="博弈"></a>博弈</h2><p>囚徒困境</p><p>布雷斯悖论：它是指在一个交通网络上增加一条路段反而使网络上的旅行时间增加；这一附加路段不但没有减少交通延滞，反而降低了整个交通网络的服务水准。这种出力不讨好且与人们直观感受相背的交通网络现象主要源于纳什均衡点并不一定使社会最优化。</p><p>社会福利(Social Welfare):最大化所有参与者的受益和</p><p>帕里托优(Pareto Efficiency)</p><p>纳什均衡(Nash Equilibrium)</p><p>优超(Dominant):不依赖其他参与者</p><h3 id="帕里托优"><a href="#帕里托优" class="headerlink" title="帕里托优"></a>帕里托优</h3><p>一个方案$x$是帕里脱最优，当且仅当不存在另一个方案$x’$满足</p><ul><li>$\exists agent \ ag: ut<em>{ag}(x’) &gt; ut</em>{ag}(x)$</li><li>$\forall agent \ ag’: ut<em>{ag’}(x’) \ge ut</em>{ag’} (x)$ </li></ul><p>帕里托最优：不考虑跨Agent效益比较的情况下满足一个全局最优</p><p>帕里托改善：在不减少一方利益的同时，通过改变现有的资源配置而提高另一方的利益</p><p>社会福利是帕利脱最优的一个子集：一个agent要想提高自己的利益，必然存在其他agent的利益受损</p><h3 id="纳什均衡"><a href="#纳什均衡" class="headerlink" title="纳什均衡"></a>纳什均衡</h3><p>Agent的策略依赖于其他agent</p><p>如果$S_A^<em> = &lt;S_1^</em>,S<em>2^*,…,S</em>{|A|^<em>}&gt;$ 为纳什均衡策略，当且仅当对agent $i$:$S_i^</em>$ 对于agent $i$ 是最优策略当其他agent选择以下策略时$<s_1^*,s_2^*,...,s_{i-1}^*,s_{i+1}^*,...,s_{|a|}^*>$ </s_1^*,s_2^*,...,s_{i-1}^*,s_{i+1}^*,...,s_{|a|}^*></p><p>没有参与者可以独自行动而增加受益</p><p>问题:</p><ul><li>无纯Nash均衡解</li><li>多个Nash均衡解</li></ul><p>不同准则下的最优策略</p><ul><li>社会福利：&lt;抗拒，抗拒&gt;</li><li>帕里托优：除了&lt;坦白,坦白&gt;之外的其他情况</li><li>纳什均衡：&lt;坦白,坦白&gt;</li><li>优超：&lt;坦白，坦白&gt;</li></ul><p>分布式决策下的博弈??</p><h3 id="协商"><a href="#协商" class="headerlink" title="协商"></a>协商</h3><h4 id="投票"><a href="#投票" class="headerlink" title="投票"></a>投票</h4><p>投票机制：</p><ul><li>Agents给予一个投票机输入，投票机结果作为Agents的解决方案</li><li>设$A$为所有Agents的集合，$O$为所有投票结果的集合</li><li>一个agent $i$的投票结果可以被描述为$\succ_i \subseteq O \times O $ </li></ul><p>投票机制的六原则</p><ul><li>对所有可能的输入组合，都存在一个社会偏序$\succ^*$</li><li>$\succ^*$对任意候选人的二元组$o,o’ \in O$都有定义</li><li>$\succ^*$在$O$上是非对称且传递的</li><li>结果满足帕里脱最优，即$\forall i \in A, o \succ_i o’$, 则$o \succ^* o’$</li><li>投票方案对不相关的候选人是独立的</li><li>没有Agent可以是独裁的</li></ul><p>不同的投票机制：</p><ul><li>多数投票<ul><li>机制<ul><li>所有候选人同时进行比较，得票最高者获胜</li></ul></li><li>分析<ul><li>不满足无关方案独立原则</li></ul></li></ul></li><li>二叉投票<ul><li>机制<ul><li>候选人成对PK</li><li>胜者和其他候选人继续PK</li><li>败者淘汰</li></ul></li><li>分析<ul><li>不满足无关方案独立原则</li><li>投票的结果依赖于比较的次序</li></ul></li></ul></li><li>计分投票<ul><li>机制<ul><li>设置一个分值$|O|$</li><li>排名第一的得$|O|$分，排名第二的得$|O|-1$分，依次类推</li><li>累加所有候选人的得分</li></ul></li><li>分析<ul><li>不满足无关方案独立原则！</li><li>投票的结果依赖于分值！</li></ul></li></ul></li></ul><h4 id="拍卖"><a href="#拍卖" class="headerlink" title="拍卖"></a>拍卖</h4><ul><li>投票机制的设计，其目的是使结果帕里脱优</li><li><p>拍卖机制的设计，其目的是使拍卖者增加自己的利益</p></li><li><p>拍卖者尽可能高价卖出物品</p></li><li>竞拍者尽可能使自己以低价获得物品</li></ul><p>拍卖机制：</p><ul><li>英格兰拍卖：first-price open-cry</li><li>密封拍卖 first-price sealed-bid</li><li>荷兰式拍卖<ul><li>减价式拍卖</li></ul></li><li>Vickery拍卖second-price sealed-bid：<ul><li>最好的策略是诚实</li><li>可以达到帕里脱最优</li></ul></li></ul><h4 id="谈判"><a href="#谈判" class="headerlink" title="谈判"></a>谈判</h4><p>谈判机制：</p><ul><li>公理谈判机制<ul><li>不变形、对称性、无关性、帕里脱优</li></ul></li><li>策略谈判机制<ul><li>物品的折扣因素，谈判的代价因素</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;人工智能&quot;&gt;&lt;a href=&quot;#人工智能&quot; class=&quot;headerlink&quot; title=&quot;人工智能&quot;&gt;&lt;/a&gt;人工智能&lt;/h1&gt;&lt;h2 id=&quot;课程概述&quot;&gt;&lt;a href=&quot;#课程概述&quot; class=&quot;headerlink&quot; title=&quot;课程概述&quot;&gt;&lt;/a&gt;课程概述&lt;/h2&gt;&lt;p&gt;参考教材&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;George F. Luger, Artificial Intelligence: Structures and Strategies for Complex Problem Solving. Fifth Edition, Addison Wesley.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Stuart Russell and Peter Norvig. Artificial Intelligence: A Modern Approach. Third Edition.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;参考网站&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;CMU, &lt;a href=&quot;http://www.cs.cmu.edu&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://www.cs.cmu.edu&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;MIT, &lt;a href=&quot;http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/index.htm&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/index.htm&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Stanford University, &lt;a href=&quot;http://www.stanford.edu/class/cs221/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://www.stanford.edu/class/cs221/&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;前8周讲授完毕，并进行期中闭卷考试(40分)&lt;/p&gt;
&lt;p&gt;全自动区分计算机和人类的图灵测试：Completely Automated Public Turing test to tell Computers and Humans Apart，简称CAPTCHA&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>SQL学习</title>
    <link href="https://ricky-ting.github.io/2019/11/14/SQL%E5%AD%A6%E4%B9%A0/"/>
    <id>https://ricky-ting.github.io/2019/11/14/SQL学习/</id>
    <published>2019-11-14T06:22:19.000Z</published>
    <updated>2019-11-14T06:22:45.569Z</updated>
    
    <content type="html"><![CDATA[<h1 id="SQL学习"><a href="#SQL学习" class="headerlink" title="SQL学习"></a>SQL学习</h1><h2 id="MySQL相关使用"><a href="#MySQL相关使用" class="headerlink" title="MySQL相关使用"></a>MySQL相关使用</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">show</span> <span class="keyword">databases</span>; <span class="comment">--展示所有数据库</span></span><br><span class="line"><span class="keyword">use</span> db1; <span class="comment">--使用db1数据库</span></span><br><span class="line"><span class="keyword">show</span> <span class="keyword">tables</span>; <span class="comment">--展示当前数据库里所有的表</span></span><br><span class="line"><span class="keyword">describe</span> tb1; <span class="comment">--展示tb1的相关信息</span></span><br><span class="line"><span class="comment">/*这是多行注释*/</span></span><br><span class="line"><span class="comment">--这是单行注释</span></span><br></pre></td></tr></table></figure><h2 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">databases</span> db1;</span><br><span class="line"><span class="keyword">use</span> db1;</span><br></pre></td></tr></table></figure><h2 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a>创建表</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> tb1 </span><br><span class="line">(</span><br><span class="line">col1_name <span class="built_in">char</span>(<span class="number">40</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span> PRIMARY <span class="keyword">KEY</span>,</span><br><span class="line">col2_name <span class="built_in">char</span>(<span class="number">30</span>) <span class="keyword">NOT</span> <span class="literal">NULL</span>,</span><br><span class="line">col3_name <span class="built_in">real</span></span><br><span class="line">);</span><br><span class="line"><span class="keyword">describe</span> tb1;</span><br></pre></td></tr></table></figure><h2 id="向表中插入数据"><a href="#向表中插入数据" class="headerlink" title="向表中插入数据"></a>向表中插入数据</h2><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> table_name</span><br><span class="line"><span class="keyword">VALUES</span> (value1,value2,value3,...); </span><br><span class="line"><span class="comment">--或者</span></span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> table_name (column1,column2,column3,...)</span><br><span class="line"><span class="keyword">VALUES</span> (value1,value2,value3,...);</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;SQL学习&quot;&gt;&lt;a href=&quot;#SQL学习&quot; class=&quot;headerlink&quot; title=&quot;SQL学习&quot;&gt;&lt;/a&gt;SQL学习&lt;/h1&gt;&lt;h2 id=&quot;MySQL相关使用&quot;&gt;&lt;a href=&quot;#MySQL相关使用&quot; class=&quot;headerlink&quot; ti
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>由边缘计算综述引出的一些知识点</title>
    <link href="https://ricky-ting.github.io/2019/11/06/%E7%94%B1%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%E7%BB%BC%E8%BF%B0%E5%BC%95%E5%87%BA%E7%9A%84%E4%B8%80%E4%BA%9B%E7%9F%A5%E8%AF%86%E7%82%B9/"/>
    <id>https://ricky-ting.github.io/2019/11/06/由边缘计算综述引出的一些知识点/</id>
    <published>2019-11-06T11:57:44.000Z</published>
    <updated>2019-11-06T12:18:11.089Z</updated>
    
    <content type="html"><![CDATA[<h1 id="由边缘计算综述引出的一些知识点"><a href="#由边缘计算综述引出的一些知识点" class="headerlink" title="由边缘计算综述引出的一些知识点"></a>由边缘计算综述引出的一些知识点</h1><h2 id="CDN"><a href="#CDN" class="headerlink" title="CDN"></a>CDN</h2><p><em>Insight and Perspectives for Content Delivery Network, 2006</em> </p><p>CDN的思想很简单，把内容缓存在离用户较近的服务器上。但在实际的实施过程中，有很多问题需要解决。</p><p>如：</p><ol><li>代理服务器的选址。</li><li>缓存内容的选择：把所有内容都缓存很不经济，在很多情况下也不现实。如何选择的缓存内容，(个人认为有两种方式：一种是手动的推送，由人来预判，然后推送到代理服务器，还有一种是自动地靠算法来选择，可以模仿cpu里的cache算法，也可以根据这一地区用户看的比较多的内容，预测他们的偏好(可以用一些数据挖掘和机器学习)，缓存一些他们偏好的内容。还有根据内容相关性，如同一url下的内容更有可能被同时访问到。)</li><li>访问机制：<ol><li>cooperative push-based: 代理服务器有去代理服务器，否则去中心服务器。代理服务器之间协作来减少备份的数量</li><li>uncooperative pull-based: 去最近的代理服务器，如果没有，由代理服务器向中心服务器请求。但代理服务器之间不协作</li><li>Cooperative pull-based:与上一个的区别是：代理服务器之间是协作的。</li></ol></li><li>定价问题</li></ol><h2 id="移动边缘计算"><a href="#移动边缘计算" class="headerlink" title="移动边缘计算"></a>移动边缘计算</h2><p><em>The case for VM-based cloudlets in mobile computing. 2009</em></p><p>这应该是工业界的一份报告，内容有点长，粗略浏览了一下：主要关注了一下它提出的应用场景。</p><ol><li>增强现实，如在博物馆中，可以根据用户的站立方向和眼神来给用户全方位地展示内容，因此在边缘需要一些AR的计算设备，但云也不可少，因为需要一些AR的内容，但边缘服务器也有一些缓存。我个人觉得也可以这样理解：博物馆很大，它有一个中心服务器，存放了很多内容，用户所在的是很多边缘，边缘识别和计算并缓存内容。边缘还可以为中心服务器提供数据，分析用户的偏好等等。</li><li>智能视频加速，因为无线链路的不稳定性，所以网速可能会出现很大的波动，而TCP不能很好地应对，所以我们在边缘部署无线信道分析程序来分析、预测可能的信道速率并告诉视频服务器，这样视频服务器能做出调整。</li><li>联网汽车，可以部署边缘设备，收集汽车上报的信息，来衡量这附近的路况等等，并能够返回信息给车辆，让它们做好准备。</li></ol><h2 id="NDN和SDN-待了解"><a href="#NDN和SDN-待了解" class="headerlink" title="NDN和SDN(待了解)"></a>NDN和SDN(待了解)</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;由边缘计算综述引出的一些知识点&quot;&gt;&lt;a href=&quot;#由边缘计算综述引出的一些知识点&quot; class=&quot;headerlink&quot; title=&quot;由边缘计算综述引出的一些知识点&quot;&gt;&lt;/a&gt;由边缘计算综述引出的一些知识点&lt;/h1&gt;&lt;h2 id=&quot;CDN&quot;&gt;&lt;a href=
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>边缘计算：现状与展望</title>
    <link href="https://ricky-ting.github.io/2019/11/06/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97%EF%BC%9A%E7%8E%B0%E7%8A%B6%E4%B8%8E%E5%B1%95%E6%9C%9B/"/>
    <id>https://ricky-ting.github.io/2019/11/06/边缘计算：现状与展望/</id>
    <published>2019-11-06T08:30:22.000Z</published>
    <updated>2019-11-06T08:35:25.523Z</updated>
    
    <content type="html"><![CDATA[<h1 id="边缘计算：现状与展望"><a href="#边缘计算：现状与展望" class="headerlink" title="边缘计算：现状与展望"></a>边缘计算：现状与展望</h1><h2 id="云计算模型的不足："><a href="#云计算模型的不足：" class="headerlink" title="云计算模型的不足："></a>云计算模型的不足：</h2><ol><li>实时性不够，网络延迟（云计算模型更适合批处理）</li><li>带宽不足，边缘设备产生的数据很多，但广域网的带宽不足。</li><li>能耗较大，（这点存疑）虽然数据中心消耗了很多能源，但也提供了很强的计算能力，如果把这些计算能力分布到边缘，是不是总的能耗会更高呢？？ </li><li>不利于数据安全和隐私。如家庭摄像头等隐私数据</li></ol><h2 id="边缘计算的概念"><a href="#边缘计算的概念" class="headerlink" title="边缘计算的概念"></a>边缘计算的概念</h2><p>边缘计算并不是不需要云了，否则边缘设备之间就孤立了，它需要云。边缘指的是从数据源到云计算中心路径之间的任意计算和网络资源，是一个连续统。</p><p>边缘计算的一些优点：</p><ul><li>减轻了网络带宽和数据中心能耗的压力</li><li>减少了系统的延迟</li><li>保护了隐私</li></ul><a id="more"></a><h2 id="边缘计算的发展历程"><a href="#边缘计算的发展历程" class="headerlink" title="边缘计算的发展历程"></a>边缘计算的发展历程</h2><p>作者将其大致划分为三个阶段：</p><ol><li>2015年以前——原始技术积累阶段</li><li>2015-2017年——飞速发展阶段</li><li>2018年及以后——稳健发展阶段</li></ol><h3 id="技术储备期"><a href="#技术储备期" class="headerlink" title="技术储备期"></a>技术储备期</h3><p>最早追溯到1998年CDN的提出。但CDN主要强调的是内容(即数据)的缓存，而边缘计算强调的是功能缓存(function cache).</p><p>2005年，施巍松教授团队已提出功能缓存的概念，并将其应用在个性化的邮箱管理服务中，以节省延迟和带宽。</p><p>2009年，Satyanarayanan等人提出了Cloudlet的概念，Cloudlet是一个可信且自愿丰富的主机，部署在网络边缘，可以为用户提供服务，也被称作“小朵云”，这里强调下行，把云服务器的功能下移至边缘服务器。</p><p>至于上行，则在靠近数据生产者的边缘增加数据处理的功能，代表性的是移动边缘计算、雾计算和海云计算。</p><p>移动边缘计算：位于无线接入网内，在云计算中心和边缘计算设备之间建立边缘服务器，在边缘服务器上完成计算，但移动边缘设备不认为具有计算能力。而在边缘计算中，终端设备具有较强的计算能力。</p><p>雾计算：由思科在2012年提出，定义为迁移云计算中心任务到网络边缘设备执行的一种高度虚拟化计算平台。雾计算关注基础设施之间分布式资源共享问题。</p><p>海云计算：由中科院在2012年提出，强调“云计算”系统和“海计算”系统之间的系统和集成，“海”指的是物理世界的一些设备。</p><h3 id="快速增长期"><a href="#快速增长期" class="headerlink" title="快速增长期"></a>快速增长期</h3><p>2016年，NSF将边缘计算列为突出领域，标志着边缘计算的发展已经在美国政府层面上引起了重视。</p><p>2016年，施巍松教授团队给出了边缘计算的一个正式定义：</p><p>学术界….</p><p>工业界…..</p><h3 id="稳健发展期"><a href="#稳健发展期" class="headerlink" title="稳健发展期"></a>稳健发展期</h3><p>很多活动</p><h2 id="支持边缘计算的核心技术"><a href="#支持边缘计算的核心技术" class="headerlink" title="支持边缘计算的核心技术"></a>支持边缘计算的核心技术</h2><p>7项核心技术：网络、隔离技术、体系结构、边缘操作系统、算法执行框架、数据处理平台以及安全和隐私。</p><h3 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h3><ol><li>服务发现：计算服务请求者会动态变化，请求者如何发现周围的服务，DNS服务发现机制需要一定时间来同步，会造成一定的网络抖动</li><li>快速配置：计算设备可能会被用户频繁开关，服务往往要随之迁移，会导致大量的突发网络流量。因此，如何从设备层支持服务的快速配置，是边缘计算中的一个核心问题。</li><li>负载均衡：如何动态调度任务。</li></ol><p>命名数据网络(named data networking, NDN)是一种将数据和服务进行命名和寻址，以P2P和中心化方式相结合进行自组织的一种数据网络，可以很好地解决服务发现问题。</p><p>软件定义网络(SDN)是一种控制面和数据面分离的可编程网络，以及简单网络管理。可以较为快速地进行路由器和交换机的配置，减少网络抖动性，以支持快速的流量迁移。</p><h3 id="隔离技术"><a href="#隔离技术" class="headerlink" title="隔离技术"></a>隔离技术</h3><p>两大隔离：计算资源的隔离和数据的隔离</p><p>现在云计算中主要使用的有VM虚拟机和Docker技术。</p><p>Li等人建立了一个基于Docker迁移的有效服务切换系统。</p><p>Ha等人提出了一种VM切换技术。</p><h3 id="体系结构"><a href="#体系结构" class="headerlink" title="体系结构"></a>体系结构</h3><p>异构硬件</p><p>ShiDianNao首次提出将人工智能处理器放置在靠近图像传感器的位置，处理器直接从传感器读取数据，避免内存存取开销，将模型放置在SRAM中，避免了权值数据在DRAM中的存取开销。</p><p>Phi-Stack提出了针对边缘计算的一整套技术栈，其中针对物联网设备设计的PhiPU，使用异构多核的结构并行处理深度学习任务和普通的计算任务(实时操作系统).</p><p>还有一些工作探索了FPGA在边缘计算场景中的应用</p><p>针对边缘计算的计算系统结构设计仍然具有很多挑战。</p><h3 id="边缘操作系统"><a href="#边缘操作系统" class="headerlink" title="边缘操作系统"></a>边缘操作系统</h3><p>边缘操作系统向下需要管理异构的计算资源，向上需要处理大量的异构数据以及多用的应用负载，需要负责将复杂的计算任务在边缘计算节点上部署、调度及迁移，从而保证计算任务的可靠性以及资源的最大化利用。</p><p>ROS, ROS2.0, EdgeOS$_H$ , PhiOS</p><h3 id="算法执行框架"><a href="#算法执行框架" class="headerlink" title="算法执行框架"></a>算法执行框架</h3><p>边缘设备更多地是执行预测任务，需要关注算法执行框架预测时的速度、内存占用量和能效。</p><p>TensorFlow Lite, Caffe2, PyTorch, MXNet</p><h3 id="数据处理平台"><a href="#数据处理平台" class="headerlink" title="数据处理平台"></a>数据处理平台</h3><p>边缘设备的数据的来源和类型具有多样化的特征，大多具有时空属性，构建一个针对边缘数据进行管理、分析和共享的平台十分重要。</p><h3 id="安全和隐私"><a href="#安全和隐私" class="headerlink" title="安全和隐私"></a>安全和隐私</h3><p>通过基于密码学的方案来进行信息保护、通过访问控制策略来对越权访问等进行防护。</p><p>也有一些新兴的安全技术，如硬件协助的可信执行环境，使用机器学习来增强系统的安全防护。</p><p>可信执行环境(TEE)：Intel软件防护扩展、Intel管理引擎、x86系统管理模式、AMD内存加密技术、AMD平台安全处理器和ARM TrustZone技术</p><h2 id="边缘计算的典型应用"><a href="#边缘计算的典型应用" class="headerlink" title="边缘计算的典型应用"></a>边缘计算的典型应用</h2><p>6个成功典型应用</p><h3 id="公共安全中实时数据处理"><a href="#公共安全中实时数据处理" class="headerlink" title="公共安全中实时数据处理"></a>公共安全中实时数据处理</h3><p>武汉的“雪亮工程”建设</p><p>网约车的视频、音频保障安全</p><p>安柏报警助手：对绑匪车辆实时追踪</p><p>用于消防系统的边缘计算系统：实时获得消防员位置信息和周边情况。</p><h3 id="智能网联车和自动驾驶"><a href="#智能网联车和自动驾驶" class="headerlink" title="智能网联车和自动驾驶"></a>智能网联车和自动驾驶</h3><h3 id="虚拟现实"><a href="#虚拟现实" class="headerlink" title="虚拟现实"></a>虚拟现实</h3><p>将VA/AR的计算任务卸载到边缘服务器。</p><p>Furion</p><h3 id="工业物联网"><a href="#工业物联网" class="headerlink" title="工业物联网"></a>工业物联网</h3><h3 id="智能家居"><a href="#智能家居" class="headerlink" title="智能家居"></a>智能家居</h3><p>工业界的Echo、SmartThings、Google Home。 Home OS和Home Kit.</p><p>学术界：EdgeOS$_H$ </p><h3 id="智慧城市"><a href="#智慧城市" class="headerlink" title="智慧城市"></a>智慧城市</h3><h2 id="边缘计算面临的紧迫问题"><a href="#边缘计算面临的紧迫问题" class="headerlink" title="边缘计算面临的紧迫问题"></a>边缘计算面临的紧迫问题</h2><p>6个方向是未来几年迫切需要解决的问题：编程模型、软硬件选型、基准程序与标准、动态调度、与垂直行业的紧密结合以及边缘节点的落地</p><h3 id="编程模型"><a href="#编程模型" class="headerlink" title="编程模型"></a>编程模型</h3><p>边缘计算模型与云计算模型存在较大的区别。边缘计算具有弹性管理、协同执行和环境异构的特点。</p><p>应用程序/服务功能可分割，数据可分布、资源可分布</p><h3 id="软硬件选型"><a href="#软硬件选型" class="headerlink" title="软硬件选型"></a>软硬件选型</h3><p>设计并实现一套能够帮助用户对边缘计算平台进行性能、功耗分析并提供软硬件选型参考的工具十分重要。</p><h3 id="基准程序和标准"><a href="#基准程序和标准" class="headerlink" title="基准程序和标准"></a>基准程序和标准</h3><h3 id="动态调度"><a href="#动态调度" class="headerlink" title="动态调度"></a>动态调度</h3><p>云计算中心和边缘设备之间的调度，边缘设备和云计算中心之间的调度。</p><p>降低传输带宽，减少任务完成时间，减少响应时间，还需要考虑能耗</p><h3 id="和垂直行业紧密合作"><a href="#和垂直行业紧密合作" class="headerlink" title="和垂直行业紧密合作"></a>和垂直行业紧密合作</h3><ol><li>减少与行业标准间的隔阂</li><li>完善数据保护和访问机制</li><li>提高互操作性</li></ol><h3 id="边缘节点落地问题"><a href="#边缘节点落地问题" class="headerlink" title="边缘节点落地问题"></a>边缘节点落地问题</h3><ol><li>新型的商业模式</li><li>边缘节点的选择</li><li>边缘数据的选择</li><li>边缘节点的可靠性</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;边缘计算：现状与展望&quot;&gt;&lt;a href=&quot;#边缘计算：现状与展望&quot; class=&quot;headerlink&quot; title=&quot;边缘计算：现状与展望&quot;&gt;&lt;/a&gt;边缘计算：现状与展望&lt;/h1&gt;&lt;h2 id=&quot;云计算模型的不足：&quot;&gt;&lt;a href=&quot;#云计算模型的不足：&quot; class=&quot;headerlink&quot; title=&quot;云计算模型的不足：&quot;&gt;&lt;/a&gt;云计算模型的不足：&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;实时性不够，网络延迟（云计算模型更适合批处理）&lt;/li&gt;
&lt;li&gt;带宽不足，边缘设备产生的数据很多，但广域网的带宽不足。&lt;/li&gt;
&lt;li&gt;能耗较大，（这点存疑）虽然数据中心消耗了很多能源，但也提供了很强的计算能力，如果把这些计算能力分布到边缘，是不是总的能耗会更高呢？？ &lt;/li&gt;
&lt;li&gt;不利于数据安全和隐私。如家庭摄像头等隐私数据&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;边缘计算的概念&quot;&gt;&lt;a href=&quot;#边缘计算的概念&quot; class=&quot;headerlink&quot; title=&quot;边缘计算的概念&quot;&gt;&lt;/a&gt;边缘计算的概念&lt;/h2&gt;&lt;p&gt;边缘计算并不是不需要云了，否则边缘设备之间就孤立了，它需要云。边缘指的是从数据源到云计算中心路径之间的任意计算和网络资源，是一个连续统。&lt;/p&gt;
&lt;p&gt;边缘计算的一些优点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;减轻了网络带宽和数据中心能耗的压力&lt;/li&gt;
&lt;li&gt;减少了系统的延迟&lt;/li&gt;
&lt;li&gt;保护了隐私&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>数据通信期中复习</title>
    <link href="https://ricky-ting.github.io/2019/04/29/%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1%E6%9C%9F%E4%B8%AD%E5%A4%8D%E4%B9%A0/"/>
    <id>https://ricky-ting.github.io/2019/04/29/数据通信期中复习/</id>
    <published>2019-04-29T14:24:02.000Z</published>
    <updated>2019-09-07T13:42:23.322Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数据通信期中复习"><a href="#数据通信期中复习" class="headerlink" title="数据通信期中复习"></a>数据通信期中复习</h1><p>通信模型： 源点-&gt;发送器-&gt;传输系统-&gt;接收器-&gt;终点</p><p>单工、半双工、双工。</p><p>数字通信系统:利用数字信号来传递信息的通信系统</p><p>模拟通信系统: 利用模拟信号来传递信息的通信系统</p><p>混成系统</p><p>TCP/IP 5层模型</p><ul><li><p>应用层：用于支持各种不同应用程序的逻辑 (SMTP,FTP,SSH,HTTP)</p></li><li><p>运输层：提供端到端的传输服务 (TCP,UDP)</p></li><li><p>网际层：提供多个网络的路由选择功能，能够让数据跨越多个互联的网路 (IPv4,Ipv6))</p></li><li><p>数据链路层：为与同一个网络相连的两个系统提供网络接入 (以太网,WiFi,ATM,帧中继)</p></li><li><p>物理层：负责数据传输设备与传输媒体的物理接口 (双绞线,光纤,卫星,地面微波)</p></li></ul><a id="more"></a><p>网络体系结构分层的好处：</p><ul><li><p>为应用提供一个抽象，对应用设计者<strong>隐藏网络的复杂性</strong></p></li><li><p>促进<strong>标准化</strong></p></li><li><p>各层互相独立，技术升级和扩展<strong>灵活性好</strong></p></li><li><p>便于方案设计和<strong>维护</strong></p></li></ul><p>信源编码与译码的目的：</p><ul><li><p>提高信息传输的有效性</p></li><li><p>完成模/数转换</p></li></ul><p>信道编码与译码的目的：</p><ul><li>增强抗干扰能力</li></ul><p>加密与解密的目的：</p><ul><li>保证所传信息的安全</li></ul><p>数字调制与解调的目的：</p><ul><li>形成适合在信道中传输的带通信号</li></ul><p>数字通信的特点</p><ul><li><p>优点：</p><ul><li><p>抗干扰能力强，且噪声不积累</p></li><li><p>传输差错可控</p></li><li><p>便于处理、变换、存储</p></li><li><p>便于将来自不同信源的信号综合到一起传输</p></li><li><p>易于集成，使通信设备微型化，重量轻</p></li><li><p>易于加密处理，且保密性好</p></li></ul></li><li><p>缺点：</p><ul><li><p>需要较大的传输带宽</p></li><li><p>对同步要求高</p></li></ul></li></ul><p>套接字：</p><ul><li><p>流套接字(TCP)： 面向连接的可靠数据传输，并保证按发送时的顺序到达</p></li><li><p>数据报套接字(UDP): 快速，交付没有保证，也不一定会保留初始顺序</p></li><li><p>原始套接字：直接访问底层协议。</p></li></ul><h2 id="数据传输"><a href="#数据传输" class="headerlink" title="数据传输"></a>数据传输</h2><p>成功的数据传输依赖于两个因素：</p><ul><li><p>传输信号的质量</p></li><li><p>传输媒体的特性</p></li></ul><p>传输媒体：</p><ul><li><p>导向媒体：电磁波在导线引导下 沿某一物理路径前进， 双绞线，光纤，同轴电缆</p></li><li><p>非导向媒体：无线传输，提供传输电磁波方式，但不引导传输方向，空气，真空，海水</p></li></ul><p>傅里叶变换</p><p>方波信号：$s(t) = A \times \frac{4}{\pi} \sum_{k=1,k \ is \ odd}^{\infty} \frac{sin(2\pi kft)}{k}$</p><p>频谱：信号所包含的频率范围</p><p>绝对带宽：信号的频谱宽度</p><p>有效带宽：包含信号绝大多数能量的窄带</p><p>直流分量：信号中频率为零的成份</p><p>$R_b = 2f$</p><p>信号的能量与功率：</p><p>能量：$E<em>x = \int</em>{-\infty} ^{\infty} |x(t)|^2 dt$</p><p>功率：$P_x = \frac{1}{t_2-t<em>1} \int</em>{t_1}^{t_2} |x(t)|^2 dt$.</p><p>一个周期的平均功率为$P= \frac{1}{T} \int_{0}^{T} |x(t)|^2 dt$</p><p>模拟信号：用连续变化电磁波来表示数据</p><p>数字信号：用电压脉冲序列来表示数据</p><p>3dB带宽：即$P<em>{\text{半功}} = 0.5 P</em>{\text{峰值}}$， 也就是说该区间边界的功率值比峰值功率值低3dB.</p><p>数字信号传输：</p><ul><li><p>比传输模拟信号便宜</p></li><li><p>不易受噪声干扰</p></li><li><p>比传输模拟信号更容易受衰减影响</p></li></ul><p>目前普遍采用数字技术的原因：</p><ul><li><p>大规模集成电路在体积和价格上都不断降低</p></li><li><p>数据完整性：不使用放大器而使用转发器，噪声和其他损伤的影响不会被累积</p></li><li><p>容量利用率：实现复用，数字技术(时分)比模拟技术(频分)更容易也更便宜</p></li><li><p>安全与保密：数字数据可以直接加密，而模拟数据还得数字化之后才能加密</p></li><li><p>综合性：所有信号具有相同的格式并且处理方法也相同。经济方便</p></li></ul><p>主要考虑的损伤：</p><ul><li><p>衰减：解决方法：放大器和转发器</p></li><li><p>失真： 时延失真，码间串扰</p></li><li><p>噪声：包括热噪声、互调噪声、串扰、冲激噪声</p></li></ul><p>信噪比：$SNR_{dB} = 10 lg \frac{S}{N}$.</p><p>热噪声：由电子的热运动造成的。 热噪声均匀地分布在通信系统常用的频率范围内，因此通常称为白噪声。$N_0 = kT(W/Hz)$</p><p>互调噪声：当不同频率的信号共享同一传输媒体时，可能会产生互调噪声。互调噪声的产生是由于在发送器、接收器中存在非线性因素，或者是传输系统受到干扰。 额外的信号，频率是两个原频率之和或差。</p><p>串扰：载有多路信号的相邻双绞线之间发生电耦合，有时在同轴电缆之间也会发生。 双绞线的扭绞结构是为了减少相邻导线 间的串扰和消除外界干扰。</p><p>以上噪声都是可预测的，并有着比较固定的强度。</p><p>冲激噪声：是非连续的，由不规则的脉冲或持续时间短而振幅大的噪声尖峰组成。它的产生有多种原因，包括外部电磁波干扰以及通信通信系统本身的故障和缺陷。</p><p>信道容量：给定条件下，某一通信信道上所能达到的最大数据传输速率。</p><p>奈奎斯特带宽： $C = 2B log_2M$</p><p>波特率$R_B$与比特率$R_b$</p><p>$R_b = R_B log_2 M$ </p><p>香农公式: $C = B log_2 (1+SNR)$</p><p>$E_b$为每比特信号的能量, $N_0$ 为每赫兹噪声功率密度</p><p>$\frac{E_b}{N_0} = \frac{S/R}{N_0} = \frac{S}{kTR}$</p><h2 id="传输媒体"><a href="#传输媒体" class="headerlink" title="传输媒体"></a>传输媒体</h2><p>双绞线：</p><ul><li><p>廉价</p></li><li><p>方便</p></li><li><p>数据率低</p></li><li><p>传输距离短</p></li></ul><p>插入损耗，近端串扰</p><p>同轴电缆可以被用于长距离传输和更多的复用</p><p>光纤的特点：</p><ul><li><p>容量更大</p></li><li><p>体积更小、质量更轻</p></li><li><p>衰减更小</p></li><li><p>隔绝电磁场 (可以提高安全性)</p></li><li><p>转发器的间隔更远</p></li></ul><p>分类：</p><ul><li><p>多模突变传播：有多个角度可以发生反射。存在多条传播路径</p></li><li><p>单模传播：</p></li><li><p>多模渐变</p></li></ul><p>天线增益：$G_{dB} = 10 lg(P_2/p_1)$ </p><p>天线增益和有效面积的关系：$G = \frac{4 \pi A_e}{\lambda^2} = \frac{4 \pi f^2 A_e}{c^2}$  $A_e = 0.56 A$</p><p>无线传播:</p><ul><li><p>地波： f&lt;2MHz, AM</p></li><li><p>天波： BBC</p></li><li><p>视距： f&gt;30MHz.  $d = 3.57 (\sqrt{Kh_1} + \sqrt{Kh_2})$ </p></li></ul><p>自由空间损耗：$\frac{P_t}{P_r} = \frac{(4 \pi d)^2}{\lambda^2} = \frac{(4\pi f d)^2}{c^2}$  </p><h2 id="信号编码技术"><a href="#信号编码技术" class="headerlink" title="信号编码技术"></a>信号编码技术</h2><p>极性</p><ul><li><p>单极性：正电平和零电平对应二进制码1和0。 有直流分量，不适用有交流耦合的远距离传输。</p></li><li><p>双极性：正电平和负电平对应1和0. 1和0等概率出现时无直流分量</p></li></ul><p>归零:</p><ul><li><p>归零：电脉冲宽度小于码元宽度，即信号电压在一个码元终止时刻前总要回到零电平 (易于提取同步信息)</p></li><li><p>不归零：占空比100%</p></li></ul><p>占空比：电脉冲宽度/码元宽度</p><p>双相位：’0’用’01’两个相位表示, ‘1’用’10’两个相位表示</p><p>差分波形：利用相邻码元的电平跳变和不变来表示消息代码</p><p>数字信号编码：</p><ul><li><p>不归零电平(NRZ-L)</p><ul><li><p>0=高电平</p></li><li><p>1=低电平</p></li></ul></li><li><p>不归零1制(NRZI)</p><ul><li><p>0=在间隔的起始位置没有跳变</p></li><li><p>1=在间隔的起始位置跳变</p></li></ul></li><li><p>双极性AMI</p><ul><li><p>0=没有线路信号</p></li><li><p>1=正电平或负电平，如果是连续的比特1，则在正负电平之间不断交替</p></li></ul></li><li><p>伪三进制码</p><ul><li><p>0= 正电平或负电平，如果是连续的比特0，则在正负电平之间不断交替</p></li><li><p>1=没有线路信号</p></li></ul></li><li><p>曼彻斯特编码</p><ul><li><p>0=在间隔的中间位置从高向低跳变</p></li><li><p>1=在间隔的中间位置从低向高跳变</p></li></ul></li><li><p>差分曼彻斯特编码：在间隔的中间位置总是有一个跳变</p><ul><li><p>0 = 在间隔的起始位置跳变</p></li><li><p>1 = 在间隔的起始位置没有跳变</p></li></ul></li><li><p>8零替换(B8ZS)</p><ul><li>与双极性AMI类似，除了连续的8个零的比特串被另一个比特串所取代，这个比特串中有两个码是违反编码规则的</li></ul></li><li><p>高密度双极性3零码(HDB3)</p><ul><li>与双极性AMI类似，除了连续的4个零的比特串被另一个比特串所取代，这个比特串中有一个码是违反编码规则的</li></ul></li></ul><p>NRZ特点：</p><ul><li><p>简单</p></li><li><p>有效利用带宽</p></li><li><p>具有直流成份</p></li><li><p>缺乏同步能力</p></li></ul><p>扰码技术：使用扰码替代产生恒定电压的序列</p><p>填充序列</p><ul><li><p>必须产生足够的跳变以利于同步</p></li><li><p>必须被接收器识别并以原始序列替换回来</p></li><li><p>和原始序列长度相同</p></li></ul><p>设计目标：</p><ul><li><p>不含直流</p></li><li><p>含有丰富的定时信息</p></li><li><p>不会降低数据率</p></li><li><p>可提供差错检测</p></li><li><p>易于检测，不会被接收端误判</p></li></ul><p>三角公式</p><p>正交调幅： QAM : $s(t) = d_1(t)cos 2\pi f_c t + d_2(t) sin 2\pi f_c t$.</p><p>在同样的载波频率上发送两个不同的信号：</p><ul><li><p>使用两个载波，具备90偏移</p></li><li><p>每个载波通过ASK调制</p></li><li><p>在同样的传输媒体发送两个独立的信号</p></li></ul><p>脉码调制</p><p>压扩函数</p><p>AM: $S_{AM}(t) = (A_0+m(t)) cos \omega_c t$</p><p>PM: $S(t) = Acos[w_ct + n_p m(t)]$</p><p>FM: $S(t) = Acos[w_c t + n_f \int m(\tau) d \tau]$ </p><h2 id="数据链路控制协议"><a href="#数据链路控制协议" class="headerlink" title="数据链路控制协议"></a>数据链路控制协议</h2><p>性能指标</p><ul><li><p>传输时延: 数据量/数据率</p></li><li><p>传播时延: 从一端到另一端</p></li><li><p>处理时延</p></li><li><p>排队时延</p></li></ul><h3 id="流量控制-确保发送的数据不会超出接收实体接收数据能力的技术"><a href="#流量控制-确保发送的数据不会超出接收实体接收数据能力的技术" class="headerlink" title="流量控制: 确保发送的数据不会超出接收实体接收数据能力的技术"></a>流量控制: 确保发送的数据不会超出接收实体接收数据能力的技术</h3><h4 id="停止等待流量控制"><a href="#停止等待流量控制" class="headerlink" title="停止等待流量控制"></a>停止等待流量控制</h4><p>流程:</p><ol><li><p>源点发送帧</p></li><li><p>终点接收帧并返回ACK</p></li><li><p>源点收到ACK后发送下一帧</p></li><li><p>终点可以通过不发送ACK来终止流</p></li></ol><p>停止等待流量控制对于少量但比较长的帧是比较有效的，但对于多量但比较短的帧不是很高效。</p><p>但把数据分割成较小的数据块更为常见，原因如下:</p><ol><li><p>接收方缓存有限</p></li><li><p>大数据块容易发生错误，出现错误时，重传的数据量也比较小。</p></li><li><p>避免一个站点长时间占用传输媒体</p></li></ol><p>一些计算:</p><ul><li><p>链路的比特长度: $B = R \times \frac{d}{v}$ , $R$ 是数据率(bps), $d$ 是链路长度$m$, $V$ 是传播速度$m/s$.</p></li><li><p>传播时延/时间(归一化值) : $a  = \frac{t<em>{prop}}{t</em>{frame}} = \frac{d/V}{L/R} = \frac{B}{L}$   , $L$ 是一个帧中的比特数</p></li><li><p>链路利用率: $U = \frac{t<em>{frame}}{t</em>{all}} = \frac{t<em>{frame}}{2t</em>{prop} + t_{frame}} = \frac{1}{2a+1}$   </p></li></ul><h4 id="滑动窗口流量控制"><a href="#滑动窗口流量控制" class="headerlink" title="滑动窗口流量控制"></a>滑动窗口流量控制</h4><p>流程:</p><ul><li><p>接收端缓存大小W</p></li><li><p>发送端在没有收到ACK前可以发送W个帧</p></li><li><p>每个帧通过序号来标识</p><ul><li><p>序号大小受字段长度限制(k bits)</p></li><li><p>帧以$2^k$ 为模编号($0 … 2^k - 1$) </p></li></ul></li><li><p>ACK 包含下一个期望收到的帧编号</p></li></ul><p>协议优化</p><ul><li><p>接收端允许发送RNR,切断对方的帧流</p></li><li><p>之后，接收端必须通过一个正常的确认帧来重启滑窗</p></li><li><p>如果是双向链路,可以使用捎带“piggybacking”</p><ul><li><p>一个帧包含发送数据和ACK</p></li><li><p>如果没有数据发送，发送独立的确认帧</p></li><li><p>如果需要发送数据，但是没有新的确认，则重新发送上一次已经发送过的确认</p></li></ul></li></ul><p>计算:</p><ul><li><p>链路利用率: $W$ 为窗口宽度</p><ul><li><p>$U = 1$, $W \ge 2a+1$ </p></li><li><p>$U = \frac{W}{2a+1}$, $W&lt; 2a+1$ </p></li></ul></li></ul><h3 id="差错控制-用于检测和纠正帧传输过程中出-现差错的机制"><a href="#差错控制-用于检测和纠正帧传输过程中出-现差错的机制" class="headerlink" title="差错控制: 用于检测和纠正帧传输过程中出 现差错的机制"></a>差错控制: 用于检测和纠正帧传输过程中出 现差错的机制</h3><p>针对以下两种类型的差错:</p><ul><li><p>帧丢失: 帧没有到达另一方</p></li><li><p>帧损伤: 帧到达，但是有一些比特有差错</p></li></ul><p>数据链路层差错控制采用自动请求重传(automatic repeat request)机制</p><p>ARQ使得一个不可靠的数据链路变为可靠链路：</p><ul><li><p>差错检测</p></li><li><p>肯定确认</p></li><li><p>超时重传</p></li><li><p>否认与重传</p></li></ul><p>三种ARQ标准:</p><ul><li><p>停止等待ARQ(stop-and-wait ARQ)</p></li><li><p>返回N ARQ(go-back-N ARQ)</p></li><li><p>选择拒绝ARQ(selective-reject ARQ)</p></li></ul><p>停止等待ARQ</p><ul><li><p>基于停止等待流量控制</p></li><li><p>要保存一个发送帧的拷贝, 在终点确认返回前，源点不发送其他帧</p></li><li><p>帧损伤:</p><ul><li><p>接收端检测到差错，丢弃该帧</p></li><li><p>发送端超时重传</p></li></ul></li><li><p>ACK损伤:</p><ul><li><p>发送端超时重传</p></li><li><p>接收端收到用两份相同编号的帧</p></li><li><p>使用 ACK0 / ACK1 来确认希望接收的帧</p><ul><li>ACKi means“I am ready to receive frame i”</li></ul></li></ul></li></ul><p>返回N ARQ</p><ul><li><p>最常用的差错控制协议</p></li><li><p>基于滑动窗口流控机制,没有收到确认的帧的最大数目取决于窗口大小</p></li><li><p>如果没有差错，使用ACK确认接收就绪</p></li><li><p>如果错误发生，为错误帧发送rejection(negativeACK)</p><ul><li><p>接收端丢弃该帧和所有后来收到的帧，直到错误帧被正确接收</p></li><li><p>发送端必须重传有差错的帧和差错帧后所有已 经传输过的帧</p></li></ul></li><li><p>窗口大小最大为$2^k -1$ </p></li><li><p>Go-back-N 接收不允许乱序? </p></li></ul><p>选择拒绝ARQ</p><ul><li><p>仅重传拒绝帧或超时帧，也叫做选择重传ARQ</p></li><li><p>后续帧被接收端接收并缓存起来</p></li><li><p>最小化重传帧的数量</p></li><li><p>接收端需要维护足够大的缓存</p></li><li><p>发送端和接收端逻辑更为复杂</p><ul><li><p>能够按照正确的顺序重组帧</p></li><li><p>判断并仅发送失序帧</p></li></ul></li><li><p>用于传播时延长的卫星链路</p></li><li><p>窗口大小最大为$2^{k-1}$</p></li></ul><h3 id="HDLC"><a href="#HDLC" class="headerlink" title="HDLC"></a>HDLC</h3><ul><li><p>站点类型:</p><ul><li><p>主站:负责控制链路操作. 由主站发出的帧称为命令</p></li><li><p>从站: 在主站的控制下操作。由从站发出的帧称为响应。主站为链路上的每个从站维护一条独立的逻辑链路。</p></li><li><p>混合站: 结合了主站和从站的特点。混合站发出的帧既可能是命令，也可能是响应。</p></li></ul></li><li><p>链路设置:</p><ul><li><p>非平衡设置 – 1个主站、 多个从站， 可支持全双工或半双工传输。</p></li><li><p>平衡设置 – 2个混合站组成， 可支持全双工或半双工传输。</p></li></ul></li><li><p>数据传送方式:</p><ul><li><p>正常响应方式(NRM)</p><ul><li><p>非平衡设置</p></li><li><p>主站能够发起到从站的数据传送</p></li><li><p>从站只有在接收到主站的命令式才传输数据</p></li></ul></li><li><p>异步平衡方式(ABM)</p><ul><li><p>平衡设置</p></li><li><p>两个混合站都能够发起数据传输，不需要对方混合站 的许可</p></li><li><p>使用最广泛</p></li></ul></li></ul></li><li><p>帧结构: </p><ul><li><p>使用同步传输</p></li><li><p>传输以帧的形式进行</p></li><li><p>一个帧格式满足所有数据和控制交换</p></li></ul></li></ul><h2 id="复用"><a href="#复用" class="headerlink" title="复用"></a>复用</h2><h3 id="FDM-频分复用"><a href="#FDM-频分复用" class="headerlink" title="FDM 频分复用"></a>FDM 频分复用</h3><ul><li><p>概念: 将多个信号调制到不同的载波频率上，且有足够间隙防止其带宽重叠，以同时运载</p></li><li><p>信道: 每个信号以各自载波频率为中心的一定的带宽。</p></li><li><p>防护频带: 在载波频率中，信道之间未被占用的部分</p></li><li><p>流程: </p><ul><li>信号$m_i(t)$  —副载波调制器$f_i$–&gt;  副载波$s_i(t)$ —叠加$\Sigma$ —&gt; 复合基带调制信号$m_b(t)$ —–发送器$f_c$ —&gt; FDM信号$s(t)$  —-接收器—&gt; 复合基带信号$m_b(t)$  —– 带通滤波器$f_i$ ——&gt; 副载波$s_i(t)$ —–解调器$f_i$ —-&gt; 信号$m_i(t)$. </li></ul></li><li><p>波分复用:</p><ul><li><p>波分复用是光纤通信中使用的一种复用方式</p></li><li><p>不同波长的光信号通过同一根光纤传输</p></li><li><p>在概念上与频分复用相同</p></li><li><p>采用不同源的窄带光组成一个宽带光</p><ul><li>棱镜用作波分复用及其多路分解</li></ul></li></ul></li></ul><h3 id="Synchronous-TDM-同步时分复用"><a href="#Synchronous-TDM-同步时分复用" class="headerlink" title="Synchronous TDM  同步时分复用"></a>Synchronous TDM  同步时分复用</h3><p>概念</p><ul><li><p>可以用于数字信号或模拟信号传输数字数据</p></li><li><p>数据被组织成“帧”:每帧包含一组循环使用的时隙;每个数据源可以被分配一个或多个时隙</p></li><li><p>间隔可以是比特级，也可以是字符级或更大的粒度</p></li><li><p>同步时分复用中同步是指时隙被提前分配给数据源且是固定的</p></li></ul><p>流程:</p><ul><li>数据$m_i(t)$ —-缓存—&gt; 数据$m_i(t)$  —–扫描操作—-&gt; TDM流$m_c(t)$ ——调制调节器—–&gt; 经调制的TDM流$s(t)$  ——-调制解调器—–&gt;  TDM流$m_c(t)$  —–扫描操作—–&gt; 数据$m_i(t)$  —–缓存—–&gt; 数据$m_i(t)$</li></ul><p>链路控制:</p><ul><li><p>数据流不存在头部和尾部,不需要数据链路控制</p></li><li><p>数据率是固定的，如果没有信息将发送空时隙</p></li><li><p>差错控制: 基于单信道的差错控制</p></li></ul><p>组帧:</p><ul><li><p>不需要flag或SYNC字符为TDM帧定界</p></li><li><p>仍然需要提供源和宿端的同步(clock)机制</p></li><li><p>增加数字组帧技术</p><ul><li><p>每个TDM帧附加一个控制比特</p></li><li><p>可识别的比特模式</p></li><li><p>一个典型的交替比特模式 101010……</p></li><li><p>同步搜索模式:接收器将接收到的帧中的比特位与预 期的模式相比较，直到这个模式在多个帧里持续传输， 建立帧同步</p></li></ul></li></ul><p>数字载波系统:</p><ul><li><p>E体系: PCM30/32路数字载波系统, </p><ul><li><p>以2.048Mbps作为基群速率(E1速率) 的数字系列</p></li><li><p>欧洲、中国采用，并用于国际间传输</p></li></ul></li><li><p>T体系 PCM24路数字载波系统</p><ul><li><p>– 以1.544Mbps作为基群速率(T1速率) 的数字系列</p></li><li><p>用于北美、日本</p></li></ul></li></ul><h3 id="Statistical-TDM-统计时分复用"><a href="#Statistical-TDM-统计时分复用" class="headerlink" title="Statistical TDM 统计时分复用"></a>Statistical TDM 统计时分复用</h3><ul><li><p>概念</p><ul><li><p>每个源有一缓存，填满时作为一帧发送</p></li><li><p>根据需求分配时隙，解决空时隙和浪费问题</p></li></ul></li><li><p>电缆调制解调器</p><ul><li>让用户通过有线电视网访问Internet</li></ul></li></ul><h3 id="ADSL-非对称用户数字线路"><a href="#ADSL-非对称用户数字线路" class="headerlink" title="ADSL 非对称用户数字线路"></a>ADSL 非对称用户数字线路</h3><ul><li><p>用户和广域网络之间的线路(最后一公里)</p></li><li><p>使用已安装好的双绞线(电话线)</p></li><li><p>非对称 – 下行流容量高于上行流</p></li><li><p>使用频分复用uses Frequency Division Multiplexing</p><ul><li><p>最低的 25kHz用于话音业务 (POTS)</p></li><li><p>使用回声抵消(echo cancellation)或者FDM提供双向传 输</p></li></ul></li><li><p>距离范围可达5.5km</p></li></ul><h2 id="交换"><a href="#交换" class="headerlink" title="交换"></a>交换</h2><h3 id="电路交换"><a href="#电路交换" class="headerlink" title="电路交换"></a>电路交换</h3><ul><li><p>用于公众电话网 PSTN， 为处理话音通信量(voice traffic)而开发，但 也能处理数字数据</p></li><li><p>在两个站点之间建立固定通路</p></li><li><p>通信期间在网络内部保留交换与传输资源</p></li><li><p>一旦电路建立，网络连接是透明的</p></li><li><p>流程: 建立通路，通信，断开通路</p></li></ul><h3 id="空分交换"><a href="#空分交换" class="headerlink" title="空分交换"></a>空分交换</h3><ul><li><p>Cross Switch: 两两交叉，$n$ 入$n$ 出, 有$n^2$个交叉点，至多用$n$ 个交叉点。 非阻塞</p></li><li><p>3-Stage Space Division Switching: </p><ul><li><p>第一级: $\frac{N}{n}$ 个 $N \times m$ 单元</p></li><li><p>第二级: $m$ 个$n \times n$ 单元</p></li><li><p>第三极: $\frac{N}{n}$ 个 $N \times m$ 单元</p></li><li><p>$m \ge 2n-1$ 时非阻塞， 否则阻塞。</p></li></ul></li><li><p>Banyan Switch: 利用输入端的二进制编码来构建空分交换, </p></li></ul><h3 id="分组交换"><a href="#分组交换" class="headerlink" title="分组交换"></a>分组交换</h3><ul><li><p>概念: </p><ul><li><p>数据交换,大数据段分为较小的数据包，包括用户数据和控制信息</p></li><li><p>途径多个节点，可被缓存</p></li></ul></li></ul><p>数据包交换:</p><ul><li><p>每个数据包都被当做单独的数据包对待</p></li><li><p>无建立时间，灵活，可靠</p></li></ul><p>虚电路交换:</p><ul><li><p>先建立(虚拟)路径，此后数据包都按此路径发送</p></li><li><p>可提供排序和错误控制,可以按序发送，传送速度更快(无需选择路由)，较不可靠。</p></li></ul><h3 id="异步传输模式-ATM"><a href="#异步传输模式-ATM" class="headerlink" title="异步传输模式 ATM"></a>异步传输模式 ATM</h3><p>概念:</p><ul><li><p>信元: 小的，固定长度的分组，减小时延</p></li><li><p>面向连接的分组交换技术，提供类似电路交换网络的性能，同时又提供分组交换的灵活性和效率</p></li><li><p>数据率:高</p></li><li><p>支持数据，语音，视频</p></li><li><p>传输: 基于优先级和QoS，用户可选择服务等级</p></li></ul><p>ATM逻辑连接:</p><ul><li><p>虚通路: VCC,类似虚电路,速率可变，全双工，定长信元流</p></li><li><p>虚通道连接: VPC, 一群具有相同端点的虚通路</p></li></ul><h2 id="蜂窝无线网络"><a href="#蜂窝无线网络" class="headerlink" title="蜂窝无线网络"></a>蜂窝无线网络</h2><p>概念:</p><ul><li><p>区域被分成蜂窝</p></li><li><p>使用低功率发送器，100W以下，控制功率防止频率逃逸</p></li><li><p>每个蜂窝一个基站: 发送器，接收器和控制单元。</p></li><li><p>相邻蜂窝频率不同:防止干扰</p></li><li><p>蜂窝形状为六边形: 蜂窝半径为R,则相邻蜂窝中心距离$\sqrt{3} R$ </p></li></ul><p>频率重用:</p><ul><li><p>$D$: 使用相同频率的蜂窝中心之间的距离</p></li><li><p>$R$: 蜂窝半径</p></li><li><p>$d$: 相邻蜂窝中心之间的距离</p></li><li><p>$N$: 重复模式中的蜂窝数量，重用系数，其可能值仅有这些: $N = I^2 + J^2 + I \times J$, $I,J = 0,1,2,3,…$</p></li><li><p>$D/R = \sqrt{3N}$ </p></li></ul><p>增大容量:</p><ul><li><p>添加新信道</p></li><li><p>频率借用</p></li><li><p>蜂窝分裂</p></li><li><p>蜂窝扇区化</p></li><li><p>微蜂窝</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;数据通信期中复习&quot;&gt;&lt;a href=&quot;#数据通信期中复习&quot; class=&quot;headerlink&quot; title=&quot;数据通信期中复习&quot;&gt;&lt;/a&gt;数据通信期中复习&lt;/h1&gt;&lt;p&gt;通信模型： 源点-&amp;gt;发送器-&amp;gt;传输系统-&amp;gt;接收器-&amp;gt;终点&lt;/p&gt;
&lt;p&gt;单工、半双工、双工。&lt;/p&gt;
&lt;p&gt;数字通信系统:利用数字信号来传递信息的通信系统&lt;/p&gt;
&lt;p&gt;模拟通信系统: 利用模拟信号来传递信息的通信系统&lt;/p&gt;
&lt;p&gt;混成系统&lt;/p&gt;
&lt;p&gt;TCP/IP 5层模型&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;应用层：用于支持各种不同应用程序的逻辑 (SMTP,FTP,SSH,HTTP)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;运输层：提供端到端的传输服务 (TCP,UDP)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;网际层：提供多个网络的路由选择功能，能够让数据跨越多个互联的网路 (IPv4,Ipv6))&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;数据链路层：为与同一个网络相连的两个系统提供网络接入 (以太网,WiFi,ATM,帧中继)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;物理层：负责数据传输设备与传输媒体的物理接口 (双绞线,光纤,卫星,地面微波)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Android Studio Installation</title>
    <link href="https://ricky-ting.github.io/2019/04/03/Android-Studio-Installation/"/>
    <id>https://ricky-ting.github.io/2019/04/03/Android-Studio-Installation/</id>
    <published>2019-04-03T03:07:18.000Z</published>
    <updated>2019-04-03T03:11:38.845Z</updated>
    
    <content type="html"><![CDATA[<p>出现错误的话，把<code>~/.gradle</code>删除, 并把代理全部关掉，重新打开build。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;出现错误的话，把&lt;code&gt;~/.gradle&lt;/code&gt;删除, 并把代理全部关掉，重新打开build。&lt;/p&gt;

      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>proxy for bash</title>
    <link href="https://ricky-ting.github.io/2019/04/01/proxy-for-bash/"/>
    <id>https://ricky-ting.github.io/2019/04/01/proxy-for-bash/</id>
    <published>2019-04-01T03:04:55.000Z</published>
    <updated>2019-04-01T03:06:15.893Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export ALL_PROXY=socks5://127.0.0.1:1086</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span cla
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>数据通信笔记</title>
    <link href="https://ricky-ting.github.io/2019/03/12/%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1%E7%AC%94%E8%AE%B0/"/>
    <id>https://ricky-ting.github.io/2019/03/12/数据通信笔记/</id>
    <published>2019-03-12T06:02:49.000Z</published>
    <updated>2019-03-12T07:51:10.247Z</updated>
    
    <content type="html"><![CDATA[<h1 id="数据通信笔记"><a href="#数据通信笔记" class="headerlink" title="数据通信笔记"></a>数据通信笔记</h1><h2 id="课程介绍"><a href="#课程介绍" class="headerlink" title="课程介绍"></a>课程介绍</h2><p>课程主页：<a href="http://cs.nju.edu.cn/yafeng/" target="_blank" rel="noopener">http://cs.nju.edu.cn/yafeng/</a> </p><p>考核形式：</p><ul><li><p>课程习题：考试重点(6-8次)</p></li><li><p>课外作业：文档阅读，完成报告(&gt;=6页)</p></li><li><p>期中小测验+期末考试</p></li><li><p>成绩：期末(70%)+期中(10%)+课程习题(10%)+课外作业(10%)</p></li></ul><a id="more"></a><h2 id="数据通信综述"><a href="#数据通信综述" class="headerlink" title="数据通信综述"></a>数据通信综述</h2><p><strong>数字通信系统：</strong>利用数字信号来传递信息的通信系统</p><p><strong>模拟通信系统:</strong>   利用模拟信号来传递信息的通信系统</p><p><strong>混成系统：</strong> 同一系统中包含模拟通信和数字通信</p><p>网络术语：</p><ul><li><p>节点(node): 网络中通信线路连接的计算机和交换机</p></li><li><p>线路(line): 节点间通信的物理连接</p></li><li><p>链路(link): 建立在相邻节点物理连接上的逻辑信道</p></li><li><p>电路(circuit): 源站点与目的站点之间建立的传输通路</p></li><li><p>交换(switching): 交换节点建立、保持和改变数据传输通路的过程</p></li><li><p>路由选择(routing): 交换技术中选择传输路径的功能</p></li><li><p>传输中继/传输网</p></li><li><p>接入线/接入网</p></li></ul><p>网络拓扑：</p><ul><li><p>星型</p></li><li><p>树型</p></li><li><p>环型</p></li><li><p>总线型</p></li></ul><h2 id="数据传输"><a href="#数据传输" class="headerlink" title="数据传输"></a>数据传输</h2><p>成功的数据传输依赖于两个因素：</p><ul><li><p>传输信号的质量 Quality of the Signal</p></li><li><p>传输媒体的特性</p></li></ul><p>导向媒体(点对点、多点)， 非导向媒体</p><p>噪声:通信通路上的平均噪声电平</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;数据通信笔记&quot;&gt;&lt;a href=&quot;#数据通信笔记&quot; class=&quot;headerlink&quot; title=&quot;数据通信笔记&quot;&gt;&lt;/a&gt;数据通信笔记&lt;/h1&gt;&lt;h2 id=&quot;课程介绍&quot;&gt;&lt;a href=&quot;#课程介绍&quot; class=&quot;headerlink&quot; title=&quot;课程介绍&quot;&gt;&lt;/a&gt;课程介绍&lt;/h2&gt;&lt;p&gt;课程主页：&lt;a href=&quot;http://cs.nju.edu.cn/yafeng/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://cs.nju.edu.cn/yafeng/&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;考核形式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;课程习题：考试重点(6-8次)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;课外作业：文档阅读，完成报告(&amp;gt;=6页)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;期中小测验+期末考试&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;成绩：期末(70%)+期中(10%)+课程习题(10%)+课外作业(10%)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>问题求解2019Spring</title>
    <link href="https://ricky-ting.github.io/2019/03/06/%E9%97%AE%E9%A2%98%E6%B1%82%E8%A7%A32019Spring/"/>
    <id>https://ricky-ting.github.io/2019/03/06/问题求解2019Spring/</id>
    <published>2019-03-06T02:26:24.000Z</published>
    <updated>2019-03-24T14:39:59.744Z</updated>
    
    <content type="html"><![CDATA[<h1 id="问题求解-2019Spring"><a href="#问题求解-2019Spring" class="headerlink" title="问题求解 2019Spring"></a>问题求解 2019Spring</h1><h2 id="4-1线性规划"><a href="#4-1线性规划" class="headerlink" title="4.1线性规划"></a>4.1线性规划</h2><p>In linear programming, we do not allow strict inequalities.</p><p><strong>minimization linear program</strong> and <strong>maximization program</strong></p><p>The simplex algorithm does not run in polynomial time in the worst case, but it is fairly efficient and widely used in practice.</p><p>We use two forms, <strong>standard</strong> and <strong>slack</strong>.</p><p>Informally, a linear program in standard form is the maximization of a linear function subject to linear inequalities, whereas a linear program in slack form is the maximization of a linear function subject to linear equalities.</p><a id="more"></a><p>We call the feasible region formed by the intersection of these half-spaces a <strong>simplex</strong>.</p><p>The <strong>simplex</strong> algorithm starts at some vertex of the simplex and performs a sequence of iterations. In each iteration, it moves along an edge of the simplex from a current vertex to a neighboring vertex whose objective value is no smaller than that of the current vertex(and usually is larger.) The simplex algorithm terminates when it reaches a local maximum, which is a vertex from which all neighboring vertices have a smaller objective value.</p><p>If we add to a linear program the additional requirement that all variables take on integer values, we have an <strong>integer linear program</strong>.</p><p>An arbitrary linear program need not have nonnegativity constraints, but standard form requires them.</p><p>We say that two maximization linear programs $L$ and $L’$ are <strong>equivalent</strong> if for each feasible solution $\bar{x}$ to $L$ with objective value $z$, there is a corresponding feasible solution $\bar{x}’$ to $L’$  with objective value $z$ and for each feasible solution $\bar{x}’’$ to $L’$ with objective value $z$, there is a corresponding feasible solution $\bar{x}$ to $L$ with objective value $z$.(This definition does not imply a one-to-one correspondence between feasible solutions.)</p><p>How to convert linear programs into standard form?</p><p>如何添加非负限制的设计很精巧</p><p>How to convert linear programs into slack form?</p><p>We call $s$ a <strong>slack variable</strong> because it measures the <strong>slack</strong>, or the difference, between the left-hand and right-hand sides of equation.</p><p>We call the variables on the left-hand side of the equalities <strong>basic variables</strong> and those on the right-hand side <strong>nonbasic variables</strong>.</p><h2 id="4-2-群论初步"><a href="#4-2-群论初步" class="headerlink" title="4.2 群论初步"></a>4.2 群论初步</h2><h3 id="Some-definations"><a href="#Some-definations" class="headerlink" title="Some definations"></a>Some definations</h3><p>A <strong>symmetry</strong> of a geometric figure is a rearrangement of the figure preserving the arrangement of its sides and vertices as well as its distances and angles. </p><p>A map from the plane to itself preserving the symmetry of an object is called a <strong>rigid motion</strong>.</p><p>A <strong>binary operation</strong> or <strong>law of composition</strong> on a set $G$ is a function $G \times G \rightarrow G$ that assigns to each pair $(a,b) \in G \times G$  a unique element  $a \circ b$, or $ab$ in $G$, called the composition of $a$ and $b$. A <strong>group</strong> $(G,\circ)$ is a set $G$ together with a law of composition $(a,b) \mapsto a \circ b$ that satisfies the following axioms.</p><ul><li><p><strong>associative</strong>:     $(a \circ b) \circ c = a \circ (b \circ c)$ </p></li><li><p><strong>identity element</strong>:  $e \circ a = a \circ e =a$</p></li><li><p><strong>inverse element</strong> : $a \circ a^{-1} = a^{-1} \circ a =e$ </p></li></ul><p>A group $G$ with the property that $a \circ b = b \circ a$ for all $a,b \in G$  is called <strong>abelian</strong> or <strong>commutative</strong>. Groups not satisfying this property are said to be <strong>nonabelian</strong> or <strong>noncommutative</strong>.</p><p><img src="/images/" alt=""></p><p>A <strong>Cayley table</strong> .</p><p>Every nonzero $k$ does have an inverse in $Z<em>{n}$ if $k$ is relatively prime to $n$. Denote the set of all such nonzero elements in $Z</em>{n}$ by $U(n)$. Then $U(n)$  is  a group called the <strong>group of units</strong> of $Z_{n}$ .</p><p>The set of invertible matrices forms a group  called the <strong>general linear group</strong>. </p><p>A group is <strong>finite</strong>, or has <strong>finite order</strong>, if it contains a finite number of elements; otherwise, the group is said to be <strong>infinite</strong> or to have <strong>infinite</strong> order. The <strong>order</strong> of a finite group is the number of elements that it contains.</p><h3 id="Basic-Properties-of-Groups"><a href="#Basic-Properties-of-Groups" class="headerlink" title="Basic Properties of Groups"></a>Basic Properties of Groups</h3><p><strong>Proposition 3.17.</strong> The identity element in a group $G$ is unique; that is, there exists only one element $e \in G$</p><p> such that $eg=ge=g$ for all $g \in G$.</p><p><strong>Proposition 3.18.</strong> If $g$ is any element in a group $G$, then the inverse of $g$ , denoted by $g^{-1}$ , is unique.</p><p><strong>Proposition 3.19</strong> Let $G$  be a group. If $a,b \in G$, then $(ab)^{-1} = b^{-1}a^{-1}$.</p><p><strong>Proposition 3.20.</strong> Let $G$ be a group. For any $a \in G$, $(a^{-1})^{-1}=a$.</p><p><strong>Proposition 3.21</strong> Let $G$ be a group and $a$ and $b$ be any two elements in $G$. Then the equations $ax=b$ and $xa=b$ have unique solutions in $G$.</p><p><strong>Proposition 3.22. (right and left cancellation laws)</strong>  If $G$ is a group and $a,b,c\in G$, then $ba=ca$ implies $b=c$ and $ab=ac$ implies $b=c$.</p><p><strong>Theorem 3.23.</strong> In a group, the usual laws of exponents hold; that is, for all $g,h \in G$,</p><ol><li><p>$g^m G^n = g^{m+n}$ for all $m,n \in Z$</p></li><li><p>$(g^m)^n = g^{mn}$ for all $m,n \in Z$ </p></li><li><p>$(gh)^n = (h^{-1} g^{-1})^{-n}$ for all $n\in Z$. Furthermore, if $G$ is abelian, then $(gh)^n = g^n h^n$.</p></li></ol><h3 id="Subgroups"><a href="#Subgroups" class="headerlink" title="Subgroups"></a>Subgroups</h3><p>We define a <strong>subgroup</strong> $H$ of a group $G$ to be a subset $H$ of $G$ such that when the group operation of $G$ is restricted to $H$, $H$ is a group in its own right.</p><p>Every group has at least two subgroups. The subgroup $H={e}$ of a group $G$ is called the <strong>trivial subgroup</strong>. A subgroup that is a proper subset of $G$ is called a <strong>proper subgroup</strong>.</p><h3 id="Some-Subgroup-Theorems"><a href="#Some-Subgroup-Theorems" class="headerlink" title="Some Subgroup Theorems"></a>Some Subgroup Theorems</h3><p><strong>Proposition 3.30</strong> A subset $H$ of $G$ is a subgroup if and only if it satisfies the following conditions.</p><ol><li><p>The identity of $e$ of $G$ is in $H$.</p></li><li><p>If $h_1,h_2 \in H$, thne $h_1h_2 \in H$.</p></li><li><p>If $h \in H$, then $h^{-1} \in H$.</p></li></ol><p><strong>Proposition 3.31</strong> Let $H$ be a subset of a group $G$. Then $H$ is a subgroup of $G$ if and only if $H \not= \emptyset$, and whenever $g,h \in H$ then $gh^{-1}$ is in $H$.</p><h3 id="Cyclic-Subgroups"><a href="#Cyclic-Subgroups" class="headerlink" title="Cyclic Subgroups"></a>Cyclic Subgroups</h3><p><strong>Theorem 4.3</strong> Let $G$ be a group and $a$ be any element in $G$. Then the set $<a> = { a^k : k \in Z }$ is a subgroup of $G$. Furthermore, $<a>$ is the smallest subgroup of $G$ that contains $a$.</a></a></p><p>For  $a\in G$, we call $<a>$ the <strong>cyclic subgroup</strong> generated by $a$. If $G$ contains some element $a$ such that $G=<a>$, then $G$ is a <strong>cyclic group</strong>. In this case $a$ is a <strong>generator</strong> of $G$. If $a$ is an element of a group $G$, we define the <strong>order</strong> of $a$ to be the smallest positive integer $n$ such that $a^n =e$, and we write $|a|=n$. If there is no such integer $n$, we say that the order of $a$ is inifinte and write $|a|= \infty$ to denote the order of $a$.</a></a></p><p><strong>Theorem 4.9.</strong> Every cyclic group is abelian.</p><p><strong>Theorem 4.10</strong> Every subgroup of a cyclic group is cyclic.</p><p><strong>Corollary 4.11</strong> The subgroups of $Z$ are exactly $nZ$ for $n=0,1,2,….$</p><p><strong>Proposition 4.12</strong> Let $G$ be a cyclic group of order $n$ and suppose that $a$ is a generator for $G$. Then $a^k=e$ if and only if $n$ divides $k$.</p><p><strong>Theorem 4.13</strong> Let $G$ be a cyclic group of order $n$ and suppose that $a \in G$ is a generator of the group. If $b= a^k$, then the order of $b$ is $n/d$, where $d=gcd(k,n)$.</p><p><strong>Corollary 4.14</strong> The generators of $Z_n$ are the integers $r$ such that $1 \le r &lt; n$ and $gcd(r,n)=1$.</p><h3 id="置换群与拉格朗日定理"><a href="#置换群与拉格朗日定理" class="headerlink" title="置换群与拉格朗日定理"></a>置换群与拉格朗日定理</h3><p>In general, the permutations of a set $X$ form a group $S_X$. If $X$ is a finite set, we can assume $X={1,2,…,n}$. In this case we write $S_n$ instead of $S_X$.  We call this group the <strong>symmetric group</strong> on $n$ letters.</p><p><strong>Theorem 5.1</strong> The symmetric group on $n$ letters, $S_n$ is a group with $n!$ elements, where the binary operation is the composition of maps.</p><p>A subgroup of $S_n$ is called a <strong>permutation group</strong>.</p><p>Permutation multiplication is not usually commutative.</p><p>A permutation $\sigma \in S_X$ is a <strong>cycle of length</strong> $k$ if there exist elements $a_1, a_2, …, a_k \in X$ such that $ \sigma(a_1)=a_2,\sigma(a_2)=a_3,…,\sigma(a_k)=a_1  $ and $\sigma(x)=x$ for all other elements $x \in X$. We will write $(a_1,a_2,..,a_k)$ to denote the cycle $\sigma$. </p><p>Cycles are the building blocks of all permutations.</p><p>Two cycles in $S_X$ , $\sigma = (a_1, a_2,…,a_k)$ and $\tau = (b_1,b_2,…,b_l)$, are <strong>disjoint</strong> of $a_i \not= b_i$ for all $i$ and $j$.</p><p><strong>Proposition 5.8.</strong> Let $\sigma$ and $\tau$ be two disjoint cycles in $S_X$. Then $\sigma \tau = \tau \sigma$.</p><p><strong>Theorem 5.9</strong> Every permutation in $S_n$ can be written as the product of disjoint cycles.</p><h4 id="Transpositions"><a href="#Transpositions" class="headerlink" title="Transpositions"></a>Transpositions</h4><p>The simplest permutation is a cycle of length $2$. Such cycles are called <strong>transpositions</strong>. Since $(a_1,a_2,…,a_n)=(a_1a_n)(a<em>1 a</em>{n-1})…(a_1a_3)(a_1a_2)$</p><p><strong>Proposition 5.12.</strong> Any permutation of a finite set containing at least two elements can be written as the product of transpositions.</p><p>No permutation can be written as the product of both an even number of transpositions and an odd number of transpositions.</p><p><strong>Lemma 5.14</strong> If the identity is written as the product of $r$ transpositions, $id = \tau_1 \tau_2 \cdot \cdot \cdot \tau_r , $  then $r$ is an even number.   (Proof need to be understood)</p><p><strong>Theorem 5.15</strong> If a permutation $\sigma$ can be expressed as the product of an even number of transpositions, then any other product of transpositions equaling $\sigma$ must also contain an even number of transpositions. Similarly, if $\sigma$ can be expressed as the product of an odd number of transpositions, then any other product of transpositions equaling $\sigma$ must also contain an odd number of transpositions.</p><p><strong>My comment on the proof of 5.14:</strong>  The fact that the inverse of $\sigma$ is $\sigma_m \cdot \cdot \cdot  \sigma_1$ confuses me some time. By introducing the fact that two identity transpositions equals to the identity, it is much clear.  Also note that the inverse of any transposition is itself.</p><p>We define a permutation to be <strong>even</strong> if it can be expressed as an even number of transpostions and <strong>odd</strong> if it can be expressed as an odd number of transpositions.</p><h4 id="The-Alternating-Groups"><a href="#The-Alternating-Groups" class="headerlink" title="The Alternating Groups"></a>The Alternating Groups</h4><p>One of the most important subgroups of $S_n$ is the set of all even permutations, $A_n$. The group $A_n$ is called the <strong>alternating group on $n$ letters</strong>.</p><p><strong>Theorem 5.16</strong> The set $A_n$ is a subgroup of $S_n$.</p><p><strong>Proposition 5.17</strong> The number of even permutations in $S_n, n&gt;2$, is equal to the number of odd permutations; hence, the order of $A_n$ is $n!/2$ .</p><h4 id="Dihedral-Groups"><a href="#Dihedral-Groups" class="headerlink" title="Dihedral Groups"></a>Dihedral Groups</h4><p>For $n=3,4,…,$, we define the $n$<strong>th dihedral group</strong> to be the group of rigid motions of a regular $n$-gon.</p><p><strong>Theorem 5.20.</strong> The dihedral group, $D_n$, is a subgroup of $S_n$ of order $2n$.</p><p><strong>Theorem 5.23.</strong> The group $D_n$ , $n \ge 3$, consists of all products of two elements $r$ and $s$, satisfying the relations $r^n=1, s^2=1, srs=r^{-1}$.</p><p><strong>Proposition 5.27.</strong> The group of rigid motions of a cube contains $24$ elements.</p><p><strong>Theorem 5.28.</strong> The group of rigid motions of a cube is $S_4$.</p><h4 id="Cosets"><a href="#Cosets" class="headerlink" title="Cosets"></a>Cosets</h4><p>Let $G$ be a group and $H$ a subgroup of $G$. Define a <strong>left coset</strong> of $H$ with <strong>representative</strong> $g \in G$ to be the set $gH = { gh : h \in H }$. <strong>Right cosets</strong> can be defined similarly by $Hg = { hg:h \in H }$. </p><p><strong>Lemma 6.3.</strong> Let $H$ be a subgroup of a group $G$ and suppose that $g_1,g_2 \in G$. The following conditions are equivalent.</p><ol><li><p>$g_1 H = g_2 H$</p></li><li><p>$H g_1^{-1} = H g_2^{-1}$</p></li><li><p>$g_1 H \subset g_2 H $</p></li><li><p>$g_2 \in g_1 H$</p></li><li><p>$ g_1^{-1} g_2 \in H$.</p></li></ol><p><strong>Theorem 6.4</strong> Let $H$ be a subgroup of a group $G$. Then the left cosets of $H$ in $G$ partition $G$. That is, the group $G$ is the disjoint union of the left cosets of $H$ in $G$.</p><p>Let $G$ be a group and $H$ be a subgroup of $G$. Define the <strong>index</strong> of $H$ in $G$ to be the number of left cosets of $H$ in $G$. We will denote the index by $[G:H]$.</p><p><strong>Theorem 6.8.</strong>  Let $H$ be a subgroup of a group $G$. The number of left cosets of $H$ in $G$ is the same as the number of right cosets of $H$ in $G$.</p><p><strong>Proposition 6.9.</strong> Let $H$ be a subgroup of $G$ with $g \in G$ and define a map $\phi : H \rightarrow gH$ by $\phi(h) = gh$. The map $\phi$ is bijective; hence, the number of elements in $H$ is the same as the number of elements in $gH$.</p><p><strong>Theorem 6.10 Lagrange.</strong> Let $G$ be a finite group and let $H$ be a subgroup of $G$. Then $|G|/|H|=[G:H]$ is the number of distinct left cosets in $G$. In particular, the number of elements in $H$ must divide the number of elements in $G$.</p><p><strong>Corollary 6.11.</strong> Suppose that $G$ is a finite group and $g \in G$. Then the order of $g$ must divide the number of elements in $G$.</p><p><strong>Corollary 6.12</strong> Let $|G|=p$ with $p$ a prime number. Then $G$ is cyclic and any $g \in G$ such that $g\not= e$ is a generator.</p><p><strong>Corollary 6.13.</strong> Let $H$ and $K$ be subgroups of a finite group $G$ such that $G \supset H \supset K.$ Then $[G:K]=[G:H][H:K].$</p><p><strong>Proposition 6.15</strong> The group $A_4$ has no subgroup of order $6$.</p><p><strong>Theorem 6.16.</strong> Two cycles $\tau$ and $\mu$ in $S_n$ have the same length if and only if there exists $a \sigma \in S_n$ such that $\mu = \sigma \tau \sigma^{-1}$.</p><h4 id="Fermat’s-and-Euler’s-Theorems"><a href="#Fermat’s-and-Euler’s-Theorems" class="headerlink" title="Fermat’s and Euler’s Theorems"></a>Fermat’s and Euler’s Theorems</h4><p>The <strong>Euler</strong> $\phi$ <strong>-function</strong> is the map $\phi:N \rightarrow N$ defined by $\phi(n)=1$ for $n=1$, and, for $n&gt;1$, $\phi(n)$ is the number of positive integers $m$ with $1 \le m &lt; n$ and $gcd(m,n)=1$.</p><p><strong>Theorem 6.17.</strong> Let $U(n)$ be the group of units in $Z_n$. Then $|U(n)| = \phi(n)$.</p><p><strong>Theorem 6.18 Euler’s Theorem.</strong> Let $a$ and $n$ be integers such that $n&gt;0$ and $gcd(a,n)=1$. Then $a^{\phi(n)} \equiv 1$(mod $n$).</p><p><strong>Theorem 6.19. Fermat’s Little Theorem.</strong> Let $p$ be any prime number and suppose that $ p \nmid a$ ($p$ does not divide $a$). Then $a^{p-1} \equiv 1$ (mod $p$). Furthermore, for any integer $b$, $b^p \equiv b$ (mod $p$). </p><h3 id="群同态基本定理与正规子群"><a href="#群同态基本定理与正规子群" class="headerlink" title="群同态基本定理与正规子群"></a>群同态基本定理与正规子群</h3><h4 id="Isomorphisms"><a href="#Isomorphisms" class="headerlink" title="Isomorphisms"></a>Isomorphisms</h4><p>Two groups $(G, \cdot )$ and $(H, \circ)$ are <strong>isomorphic</strong> if there exists a one-to-one and onto map $\phi : G \rightarrow H$ such that the group operation is preserved; that is, $\phi (a \cdot b) = \phi(a) \circ \phi (b)$ for all $a$ and $b$ in $G$. If $G$ is isomorphic to $H$, we write $G \cong H$. The map $\phi$ is called an <strong>isomorphism</strong>.</p><p><strong>Theorem 9.6.</strong> Let $\phi : G \rightarrow H$ be an isomorphism of two subgroups. Then the following statements are true.</p><ol><li><p>$\phi^{-1}: H \rightarrow G$ is an isomorphism.</p></li><li><p>$|G| = |H|.$</p></li><li><p>If $G$ is abelian, then $H$ is abelian.</p></li><li><p>If $G$ is cyclic, then $H$ is cyclic.</p></li><li><p>If $G$ has a subgroup of order $n$, then $H$ has a subgroup of order $n$.</p></li></ol><p><strong>Theorem 9.7.</strong> All cyclic groups of infinite order are isomorphic to $Z$.</p><p><strong>Theorem 9.8.</strong> If $G$ is a cyclic group of order $n$, then $G$ is isomorphic to $Z_n$.</p><p><strong>Corollary 9.9.</strong> If $G$ is a group of order $p$, where $p$ is a prime number, then $G$ is isomorphic to $Z_p$.</p><p><strong>Theorem 9.10.</strong> The isomorphism of groups determines an equivalence relation on the class of all groups.</p><p><strong>Theorem 9.12 Cayley.</strong> Every group is isomorphic to a group of permutations.</p><p>The isomorphism $g \mapsto \lambda_g$ is known as the <strong>left regular representation</strong> of $G$.</p><h4 id="External-Direct-Products"><a href="#External-Direct-Products" class="headerlink" title="External Direct Products"></a>External Direct Products</h4><p>If $(G, \cdot)$ and $(H,\circ)$ are groups, then we can make the Cartesian product of $G$ and $H$ into a new group. As a set, our group is just the ordered pairs $(g,h) \in G \times H$ where $g \in G$ and $h \in H$. We can define a binary operation on $G \times H$ by $(g_1,h_1)(g_2,h_2) = (g_1 \cdot g_2, h_1 \cdot h_2)$.</p><p><strong>Proposition 9.13.</strong> Let $G$ and $H$ be groups. The set $G \times H$ is a group under the operation $(g_1,h_2)(g_2,h_2) = (g_1g_2, h_1h_2)$ where $g_1,g_2 \in G$ and $h_1,h_2 \in H$.</p><p>The group $G \times H$ is called the <strong>external direct product</strong> of $G$ and $H$. </p><p><strong>Theorem 9.17.</strong> Let $(g,h) \in G \times H$. If $g$ and $h$ have finite orders $r$ and $s$ respectively, then the order of $(g,h)$ in $G \times H$ is the least common multiple of $r$ and $s$.</p><p><strong>Corollary 9.18.</strong> Let $(g_1, …, g_n) \in \prod G_i$. If $g_i$ has finite order $r_i$ in $G_i$, then the order of $(g_1,…,g_n) \in \prod G_i$ is the least common multiple of $r_1,…,r_n$.</p><p><strong>Theorem 9.21.</strong> The group $Z_m \times Z<em>n$ is isomorphic to $Z</em>{mn}$ if and only if $gcd(m,n)=1$.</p><p><strong>Corollary 9.22.</strong> Let $n_1,…,n<em>k$ be positive integers. Then $\prod\limits</em>{i=1}^{k}Z_{n<em>i} \cong Z</em>{n_1…n_k}$  if and only if $gcd(n_i,n_j)=1$ for $i \not= j$.</p><p><strong>Corollary 9.23.</strong> If $m = p_1^{e_1} \cdot \cdot \cdot p_k^{e_k}$, where the $p_is$ are distinct primes, then $Z<em>m \cong Z</em>{p_1 ^{e<em>1}} \times \cdot \cdot \cdot \times Z</em>{p_k^{e_k}}$.</p><h4 id="Internal-Direct-Products"><a href="#Internal-Direct-Products" class="headerlink" title="Internal Direct Products"></a>Internal Direct Products</h4><p>Let $G$ be a group with subgroups $H$ and $K$ satisfying the following conditions.</p><ul><li><p>$G = H K = {hk: h\in H , k \in K}$;</p></li><li><p>$H \cap K = {e}$;</p></li><li><p>$hk=kh$ for all $k \in K$ and $h \in H$.</p></li></ul><p>Then $G$ is the <strong>internal direct product</strong> of $H$ and $K$.</p><p><strong>Theorem 9.27.</strong> Let $G$ be the internal direct product of subgroups $H$ and $K$. Then $G$ is isomorphic to $H \times K$. Then $G$ is isomorphic to $H \times K$.</p><p><strong>Theorem 9.29.</strong> Let $G$ be the internal direct product of subgroups $H_i$, where $i = 1,2,…,n$. Then $G$ is isomorphic to $\prod_i H_i$.</p><h4 id="Normal-Subgroups"><a href="#Normal-Subgroups" class="headerlink" title="Normal Subgroups"></a>Normal Subgroups</h4><p>A subgroup $H$ of a group $G$ is <strong>normal</strong> in $G$ if $gH = Hg$ for all $g \in G$. </p><p><strong>Theorem 10.3.</strong> Let $G$ be a group and $N$ be a subgroup of $G$. Then the following statements are equivalent.</p><ol><li><p>The subgroup $N$ is normal in $G$.</p></li><li><p>For all $g \in G$, $g N g^{-1} \subset N$.</p></li><li><p>For all $g \in G$, $gNg^{-1} = N$.</p></li></ol><h4 id="Factor-Groups"><a href="#Factor-Groups" class="headerlink" title="Factor Groups"></a>Factor Groups</h4><p>If $N$ is a normal subgroup of a group $G$, then the cosets of $N$ in $G$ form a group $G/N$ under the operation $(aN)(bN)=abN$. This group is called the <strong>factor</strong> or <strong>quotient group</strong> of $G$ and $N$.</p><p><strong>Theorem 10.4.</strong> Let $N$ be a normal subgroup of a group $G$. The cosets of $N$ in $G$ form a group $G/N$ of order $[G:N]$.</p><h4 id="The-Simplicity-of-the-Alternating-Group"><a href="#The-Simplicity-of-the-Alternating-Group" class="headerlink" title="The Simplicity of the Alternating Group"></a>The Simplicity of the Alternating Group</h4><p>Of special interest are groups with no nontrivial normal subgroups. Such groups are called <strong>simple groups</strong>.</p><p><strong>Lemma 10.8.</strong> The alternating group $A_n$ is generated by $3-$cycles for $n \ge 3$.</p><p><strong>Lemma 10.9.</strong> Let $N$ be a normal subgroup of $A_n$, where $n \ge 3$. If $N$ contains a $3-$cycle, then $N=A_n$.</p><p><strong>Lemma 10.10.</strong> For $n \ge 5$, every nontrivial normal subgroup $N$ of $A_n$ contains a $3-$ cycle.</p><p><strong>Theorem 10.11.</strong> The alternating group, $A_n$, is simple for $n \ge 5$.</p><h4 id="Group-Homomorphisms"><a href="#Group-Homomorphisms" class="headerlink" title="Group Homomorphisms"></a>Group Homomorphisms</h4><p>A <strong>homomorphism</strong> between groups $(G, \cdot)$ and $(H, \circ)$ is a map $\phi: G \rightarrow H$ such that $\phi(g_1 \cdot g_2) = \phi(g_1) \circ \phi(g_2)$ for $g_1, g_2 \in G$. The range of $\phi$ in $H$ is called the <strong>homomorphic image</strong> of $\phi$. </p><p><strong>Proposition 11.4.</strong>  Let $\phi : G_1 \rightarrow G_2$ be a homomorphism of groups. Then </p><ol><li><p>If $e$ is the identity of $G_1$, then $\phi(e)$ is the identity of $G_2$;</p></li><li><p>For any element $g \in G_1$, $\phi(g^{-1}) = [\phi(g)]^{-1}$;</p></li><li><p>If $H_1$ is a subrgoup of $G_1$, then $\phi(H_1)$ is a subrgoup of $G_2$;</p></li><li><p>If $H_2$ is a subgroup of $G_2$, then $\phi^{-1}(H_2) = {g \in G_1 : \phi(g) \in H_2}$ is a subgroup of $G_1$. Furthermore, if $H_2$ is normal in $G_2$, then $\phi^{-1}(H_2)$ is normal in $G_1$.</p></li></ol><p>Let $\phi: G \rightarrow H$ be a group homomorphism and suppose that $e$ is the identity of $H$.  By Proposition 11.4, $\phi^{-1}({e})$ is a subrgoup of $G$. This subgroup is called the <strong>kernel</strong> of $\phi$ and will be denoted by ker $\phi$.</p><p><strong>Theorem 11.5.</strong> Let $\phi : G \rightarrow H$ be a group homomorphism. Then the kernel of $\phi$ is a normal subgroup of $G$.</p><h4 id="The-Isomorphism-Theorems"><a href="#The-Isomorphism-Theorems" class="headerlink" title="The Isomorphism Theorems"></a>The Isomorphism Theorems</h4><p>Let $H$ be a normal subgroup of $G$. Define the <strong>natural</strong> or <strong>canonical homomorphism</strong> $\phi : G \rightarrow G/H$ by $\phi(g) = g H$.</p><p><strong>Theorem 11.10 First Isomorphism Theorem.</strong> If $\psi : G \rightarrow H$ is a group homomorphism with $K = ker \psi$, then $K$ is normal in $G$. Let $\phi: G \rightarrow G/K$ be the canonical homomorphism. Then there exists a unique isomorphism $\eta : G/K \rightarrow \psi(G)$ such that $\psi = \eta \phi$</p><p><strong>Theorem 11.12 Second Isomorphism Theorem.</strong>  Let $H$ be a subgroup of a group $G$ (not necessarily normal in $G$) and $N$ a normal subgroup of $G$. Then $HN$ is a subgroup of $G$, $H \cap N$ is a normal subgroup of $H$, and $H/ H \cap N \cong HN/N$.</p><p><strong>Theorem 11.13 Correspondence Theorem.</strong> Let $N$ be a normal subgroup of a group $G$. Then $H \mapsto H/N$ is a one-to-one correspondence between the set of subgroups $H$ containing $N$ and the set of subgroups of $G/N$. Furthermore, the normal subgroups of $G$ containing $N$ correspond to normal subgroups of $G/N$.</p><p><strong>Theorem 11.14 Third Isomorphism Theorem.</strong> Let $G$ be a group and $N$ and $H$ be normal subgroups of $G$ with $N \subset H.$ Then $G/H \cong \frac{G/N}{H/N}$.</p><h3 id="串匹配"><a href="#串匹配" class="headerlink" title="串匹配"></a>串匹配</h3><h4 id="The-naive-string-matching-algorithm"><a href="#The-naive-string-matching-algorithm" class="headerlink" title="The naive string-matching algorithm"></a>The naive string-matching algorithm</h4>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;问题求解-2019Spring&quot;&gt;&lt;a href=&quot;#问题求解-2019Spring&quot; class=&quot;headerlink&quot; title=&quot;问题求解 2019Spring&quot;&gt;&lt;/a&gt;问题求解 2019Spring&lt;/h1&gt;&lt;h2 id=&quot;4-1线性规划&quot;&gt;&lt;a href=&quot;#4-1线性规划&quot; class=&quot;headerlink&quot; title=&quot;4.1线性规划&quot;&gt;&lt;/a&gt;4.1线性规划&lt;/h2&gt;&lt;p&gt;In linear programming, we do not allow strict inequalities.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;minimization linear program&lt;/strong&gt; and &lt;strong&gt;maximization program&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The simplex algorithm does not run in polynomial time in the worst case, but it is fairly efficient and widely used in practice.&lt;/p&gt;
&lt;p&gt;We use two forms, &lt;strong&gt;standard&lt;/strong&gt; and &lt;strong&gt;slack&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Informally, a linear program in standard form is the maximization of a linear function subject to linear inequalities, whereas a linear program in slack form is the maximization of a linear function subject to linear equalities.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>MATLAB学习笔记</title>
    <link href="https://ricky-ting.github.io/2019/01/19/MATLAB%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>https://ricky-ting.github.io/2019/01/19/MATLAB学习笔记/</id>
    <published>2019-01-19T07:50:56.000Z</published>
    <updated>2019-01-19T11:14:53.890Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MATLAB学习笔记"><a href="#MATLAB学习笔记" class="headerlink" title="MATLAB学习笔记"></a>MATLAB学习笔记</h1> <a id="more"></a><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><ul><li><p>quit: 退出命令</p></li><li><p>clc: 擦除MATLAB工作窗中的所有显示内容，相当于命令行中的clear</p></li><li><p>clf: 擦除MATLAB的当前图形窗中的图形</p></li><li><p>clear: 清除内存中的变量和函数</p></li><li><p>dir: 列出指定目录下的文件和子目录清单</p></li><li><p>cd: 改变当前工作子目录</p></li><li><p>disp: (在运行中)显示变量和文字内容</p></li><li><p>who: 检查内存变量</p></li><li><p>whos: 列出内存变量的详细情况</p></li><li><p>save: 关闭前将变量保存到某一文件中</p></li><li><p>load: 从之前保存的文件中恢复变量</p></li><li><p>help: 非常有用</p></li><li><p>lookfor: 查找相关指令</p></li><li><p>!之后可以加操作系统命令，如 !ls, !vim</p></li></ul><p><img src="/images/MATLAB学习笔记/MATLABop.png" alt=""></p><p>求解方程组时，用除法比用逆矩阵好。</p><h2 id="多项式"><a href="#多项式" class="headerlink" title="多项式"></a>多项式</h2><ul><li><p>用系数行向量表示：p=$[a_0 , a<em>1 , … , a</em>{n-1} , a_n ]$, ($p(x)= a_0 x_n + a<em>1 x</em>{n-1} + … + a<em>{n-1} x + a</em>{n} $).</p></li><li><p>可以用指令产生多项式系数向量: p=poly(AR). 如果AR是方阵，则多项式为特征多项式，如果AR为向量，则AR为多项式的解。</p></li><li><p>poly2str函数</p></li></ul><h3 id="一些常用多项式运算指令"><a href="#一些常用多项式运算指令" class="headerlink" title="一些常用多项式运算指令"></a>一些常用多项式运算指令</h3><ul><li><p>R=roots(p)   求多项式向量p的根</p></li><li><p>PA=polyval(p,S)  按照数组运算规则计算多项式值。 p为多项式，S为矩阵。 相当于求值。</p></li><li><p>PM=polyvalm(p;S) 按照矩阵运算规则计算多项式值。p为多项式，S为矩阵。</p></li><li><p>P=polyfit(x,y,n) 用n阶多项式拟合x,y向量给定的数据</p></li></ul><h2 id="数值积分"><a href="#数值积分" class="headerlink" title="数值积分"></a>数值积分</h2><ul><li><p>S=quad(‘fname’,a,b,tol,trace)  自适用递推Simpson数值积分法</p></li><li><p>S=quad8(‘fname’,a,b,tol,trace) 自适用递推Newton-Cotes数值积分法</p></li><li><p>tol是精度，trace是是否画图</p></li><li><p>quad8比quad有更高的积分精度</p></li></ul><h2 id="非线性方程求解"><a href="#非线性方程求解" class="headerlink" title="非线性方程求解"></a>非线性方程求解</h2><ul><li><p>对于多项式函数求根，r=roots(p)</p></li><li><p>单变量非线性方程求解, z=fzero(‘fname’,x0,tol,trace)</p></li><li><p>一般非线性方程(组)求解， X=fsolve(‘fname’,X0)</p></li></ul><h2 id="文件读写"><a href="#文件读写" class="headerlink" title="文件读写"></a>文件读写</h2><ul><li><p>fopen(“filename”,’specifier’)</p></li><li><p>fread(fd,..)</p></li><li><p>fwrite()</p></li><li><p>fclose</p></li></ul><h2 id="符号计算"><a href="#符号计算" class="headerlink" title="符号计算"></a>符号计算</h2><ul><li><p>可以用sym定义符号,如 sym(‘x’) 也可以用syms定义多个符号 syms a b c d</p></li><li><p>findsym() 来确认符号表达式中的符号</p></li></ul><h3 id="微积分运算"><a href="#微积分运算" class="headerlink" title="微积分运算"></a>微积分运算</h3><ul><li><p>diff(f) 函数f对符号变量x或字母表上最接近字母x的符号变量求导数</p></li><li><p>diff(f,t) 函数f对符号变量t求导数</p></li><li><p>diff(f,2) 和diff(f,t,2)可以用来求二阶导数</p></li><li><p>int(f)</p></li><li><p>int(f,t)</p></li><li><p>int(f,a,b) 和int(f,t,a,b)</p></li><li><p>limit(f) 当符号变量x(或最接近字母x的符号变量) -&gt;0 时，函数f的极限</p></li><li><p>limit(f,t,a)</p></li><li><p>limit(f,t,a,’left’) 左极限 limit(f,t,a,’right’)右极限</p></li><li><p>symsum(s,t,a,b) 表示s中的符号变量t从a到b的级数和(t缺省时，同上)</p></li><li><p>taylor(f,n,a) 函数f对符号变量x(或…)在a点的n-1阶泰勒多项式(n缺省时值为6，a缺省时值为0)</p></li><li><p>solve(f,t) 对f中的符号变量t解方程f=0(t缺省值为x或…)</p></li><li><p>solve(f,g,..)可以求解方程组</p></li><li><p>dsolve(‘S’,’s1’,’s2’,…,’x’)</p></li><li><p>collect 合并同类项</p></li><li><p>expand 将乘积展开为和式</p></li><li><p>horner 把多项式转换为嵌套表示形式</p></li><li><p>simplify 利用各种恒等式化简代数式，更强有力的函数simple</p></li><li><p>subs(S,old,new) 替换</p></li><li><p>subexpr(S) 将表达式S中的公共部分用sigma表示</p></li></ul><h2 id="MATLAB画图"><a href="#MATLAB画图" class="headerlink" title="MATLAB画图"></a>MATLAB画图</h2><ul><li><p>plot(x,y) 以向量x作为X轴，以向量y作为Y轴，绘制X-Y二维曲线</p></li><li><p>plot(x,y1,’k’,x,y2,’b-‘) 每条曲线的线型和颜色由字符串’cs’指定，其中c表示颜色,s表示线型</p></li></ul><p><img src="/images/MATLAB学习笔记/ColorAndLine.png" alt=""></p><ul><li><p>可以加一些图形标记，如title, xlabel, ylabel, text,legend</p></li><li><p>axis([xmin,xmax,ymin,ymax]) 来设定坐标轴范围</p></li><li><p>hold on: 保持原有图形的基础上绘制新的图形</p></li><li><p>fplot(fname,lims,tol) lims为变量取值范围，tol为相对误差</p></li><li><p>loglog(x,y) 绘制双对数坐标图</p></li><li><p>semilogx(x,y) semilogy(x,y) 绘制单对数坐标图</p></li><li><p>polar(theta,rho) 用来绘制极坐标图</p></li></ul><p><img src="/images/MATLAB学习笔记/2D.png" alt=""></p><ul><li><p>plot3(x1,y1,z1,c1,x2,y2,z2,c2,…)</p></li><li><p>mesh(x,y,z,c)绘制三维网格图</p></li><li><p>surf(x,y,z) 绘制三维曲面图</p></li><li><p>view 指定视点</p></li><li><p>contour3 绘制等高线图</p></li></ul><h2 id="MATLAB程序设计"><a href="#MATLAB程序设计" class="headerlink" title="MATLAB程序设计"></a>MATLAB程序设计</h2><p>MATLAB有两种工作方式：一种是交互式的命令行工作方式，另一种是M文件的程序工作方式</p><h3 id="M文件"><a href="#M文件" class="headerlink" title="M文件"></a>M文件</h3><p>M文件有两类：命令文件和函数文件。区别在于：命令文件没有输入参数，也不返回输出参数；而函数文件可以输入参数，也可以返回输出参数。</p><ul><li><p>input函数， A=input(提示信息，选项);</p></li><li><p>pause(延迟秒数)    pause()直接暂停程序</p></li><li><p>Disp(输出项)</p></li></ul><h3 id="if选择语句"><a href="#if选择语句" class="headerlink" title="if选择语句"></a>if选择语句</h3><ul><li><p>结束时要加end，不需要加begin</p></li><li><p>else +if = elseif</p></li></ul><h3 id="switch语句"><a href="#switch语句" class="headerlink" title="switch语句"></a>switch语句</h3><ul><li><p>结束要加end</p></li><li><p>default改为otherwise</p></li><li><p>case 值 后面没有冒号</p></li></ul><h3 id="for循环结构"><a href="#for循环结构" class="headerlink" title="for循环结构"></a>for循环结构</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">for 循环变量= 表达式1: 表达式2 : 表达式3</span><br><span class="line">    循环体</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">% 表达式1为初值， 表达式2为步长，表达式3为终值</span><br><span class="line"></span><br><span class="line">for 循环变量=矩阵表达式 则遍历矩阵元素</span><br></pre></td></tr></table></figure><h3 id="while循环结构"><a href="#while循环结构" class="headerlink" title="while循环结构"></a>while循环结构</h3><ul><li>结尾加end</li></ul><h3 id="函数文件"><a href="#函数文件" class="headerlink" title="函数文件"></a>函数文件</h3><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> 输出形参表=函数名<span class="params">(输入形参表)</span></span></span><br><span class="line">    注释说明部分</span><br><span class="line">    函数体</span><br></pre></td></tr></table></figure><ul><li><p>当输出形参多余1个时，则应该用方括号括起来</p></li><li><p>参数可调， 用nargin和nargout实现</p></li><li><p>支持嵌套调用和递归</p></li><li><p>加global可以声明全局变量</p></li></ul><p>参考资料：MATLAB 数学工具软件实例简明教程</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;MATLAB学习笔记&quot;&gt;&lt;a href=&quot;#MATLAB学习笔记&quot; class=&quot;headerlink&quot; title=&quot;MATLAB学习笔记&quot;&gt;&lt;/a&gt;MATLAB学习笔记&lt;/h1&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>文章集锦</title>
    <link href="https://ricky-ting.github.io/2019/01/18/%E6%96%87%E7%AB%A0%E9%9B%86%E9%94%A6/"/>
    <id>https://ricky-ting.github.io/2019/01/18/文章集锦/</id>
    <published>2019-01-18T14:01:01.000Z</published>
    <updated>2019-02-12T13:54:36.358Z</updated>
    
    <content type="html"><![CDATA[<ul><li>什么是真正的程序员 <a href="https://www.cnblogs.com/xueweihan/p/5220513.html" target="_blank" rel="noopener">原文链接</a> （<a href="https://github.com/Ricky-Ting/ArticleCollection/blob/master/2019.1/什么是真正的程序员？%20-%20削微寒%20-%20博客园.pdf" target="_blank" rel="noopener">文章存档</a>）</li><li>信息消费：从入门到放弃 | 2018 年度征文 <a href="https://sspai.com/post/52832" target="_blank" rel="noopener">原文链接</a> (<a href="https://github.com/Ricky-Ting/ArticleCollection/blob/master/2019.2/信息消费：从入门到放弃%20%7C%202018%20年度征文%20-%20少数派.pdf" target="_blank" rel="noopener">文章存档</a>)</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;什么是真正的程序员 &lt;a href=&quot;https://www.cnblogs.com/xueweihan/p/5220513.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原文链接&lt;/a&gt; （&lt;a href=&quot;https://gith
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>mac下ssh打开X11转发</title>
    <link href="https://ricky-ting.github.io/2019/01/17/mac%E4%B8%8Bssh%E6%89%93%E5%BC%80X11%E8%BD%AC%E5%8F%91/"/>
    <id>https://ricky-ting.github.io/2019/01/17/mac下ssh打开X11转发/</id>
    <published>2019-01-17T07:13:44.000Z</published>
    <updated>2019-01-17T07:17:15.003Z</updated>
    
    <content type="html"><![CDATA[<h1 id="mac下ssh打开X11转发"><a href="#mac下ssh打开X11转发" class="headerlink" title="mac下ssh打开X11转发"></a>mac下ssh打开X11转发</h1><p>1.首先确认linux下已开启X11转发：</p><pre><code><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/ssh/sshd_config</span><br><span class="line"></span><br><span class="line">X11Forwarding yes</span><br><span class="line">X11DisplayOffset 10</span><br><span class="line"></span><br><span class="line">service ssh restart</span><br></pre></td></tr></table></figure></code></pre><p>2.安装XQuartz</p><p>3.在mac端下开启：</p><pre><code><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/ssh/ssh_config</span><br><span class="line"></span><br><span class="line">ForwardX11 yes</span><br></pre></td></tr></table></figure></code></pre><p>4.ssh登陆</p><pre><code><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -X username@ip</span><br></pre></td></tr></table></figure></code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;mac下ssh打开X11转发&quot;&gt;&lt;a href=&quot;#mac下ssh打开X11转发&quot; class=&quot;headerlink&quot; title=&quot;mac下ssh打开X11转发&quot;&gt;&lt;/a&gt;mac下ssh打开X11转发&lt;/h1&gt;&lt;p&gt;1.首先确认linux下已开启X11转发：&lt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>2019寒假计划(flag)</title>
    <link href="https://ricky-ting.github.io/2019/01/16/2019%E5%AF%92%E5%81%87%E8%AE%A1%E5%88%92-flag/"/>
    <id>https://ricky-ting.github.io/2019/01/16/2019寒假计划-flag/</id>
    <published>2019-01-16T09:32:32.000Z</published>
    <updated>2019-01-16T09:33:26.543Z</updated>
    
    <content type="html"><![CDATA[<h1 id="2019-寒假计划-flag"><a href="#2019-寒假计划-flag" class="headerlink" title="2019 寒假计划(flag)"></a>2019 寒假计划(flag)</h1><h2 id="必做"><a href="#必做" class="headerlink" title="必做"></a>必做</h2><ul><li><p>学习数学建模，参加美赛</p></li><li><p>完成经典阅读论文</p></li><li><p>读Spark源码</p></li><li><p>学习线性代数、代数学引论</p></li><li><p>寒假HK项目准备</p></li><li><p>学习MATLAB</p></li></ul><h2 id="可选"><a href="#可选" class="headerlink" title="可选"></a>可选</h2><ul><li><p>学习IOS开发</p></li><li><p>机器学习导论、人工智能、深度学习</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;2019-寒假计划-flag&quot;&gt;&lt;a href=&quot;#2019-寒假计划-flag&quot; class=&quot;headerlink&quot; title=&quot;2019 寒假计划(flag)&quot;&gt;&lt;/a&gt;2019 寒假计划(flag)&lt;/h1&gt;&lt;h2 id=&quot;必做&quot;&gt;&lt;a href=&quot;#必
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>如何解决项目子模块git冲突</title>
    <link href="https://ricky-ting.github.io/2019/01/03/%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E9%A1%B9%E7%9B%AE%E5%AD%90%E6%A8%A1%E5%9D%97git%E5%86%B2%E7%AA%81/"/>
    <id>https://ricky-ting.github.io/2019/01/03/如何解决项目子模块git冲突/</id>
    <published>2019-01-03T15:02:20.000Z</published>
    <updated>2019-01-03T15:03:36.198Z</updated>
    
    <content type="html"><![CDATA[<h1 id="如何解决项目子模块git冲突"><a href="#如何解决项目子模块git冲突" class="headerlink" title="如何解决项目子模块git冲突"></a>如何解决项目子模块git冲突</h1><h2 id="起因"><a href="#起因" class="headerlink" title="起因"></a>起因</h2><p>在将这学期做的PA提交到github时，因为ics2018中原有git与github上创建的git冲突，因此上传之后ics2018的图标为灰。</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><ul><li><p>git rm –cache ics2018</p></li><li><p>git add ics2018/</p></li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://upupming.site/2018/05/31/git-submodules/#解决方案" target="_blank" rel="noopener">参考链接</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;如何解决项目子模块git冲突&quot;&gt;&lt;a href=&quot;#如何解决项目子模块git冲突&quot; class=&quot;headerlink&quot; title=&quot;如何解决项目子模块git冲突&quot;&gt;&lt;/a&gt;如何解决项目子模块git冲突&lt;/h1&gt;&lt;h2 id=&quot;起因&quot;&gt;&lt;a href=&quot;#起因&quot;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Records for Environment Setup for Spark</title>
    <link href="https://ricky-ting.github.io/2018/11/02/Records-for-Environment-Setup-for-Spark/"/>
    <id>https://ricky-ting.github.io/2018/11/02/Records-for-Environment-Setup-for-Spark/</id>
    <published>2018-11-02T15:29:21.000Z</published>
    <updated>2018-11-02T15:42:07.389Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Spark搭建记录-2018-11-2"><a href="#Spark搭建记录-2018-11-2" class="headerlink" title="Spark搭建记录(2018.11.2)"></a>Spark搭建记录(2018.11.2)</h1><p>建立在Hadoop的基础上。</p><p><a href="https://www.cnblogs.com/zyrblog/p/8527048.html" target="_blank" rel="noopener">参考教程</a></p><p>Spark版本：2.1.3.</p><p>在官网上下的直接编译好的文件。</p><p>Spark装之前需要装Scala。我的Scala版本是2.11.6。</p><p>然后解压spark压缩包，修改conf目录下的spark-env.sh(备份到github)。 修改slaves文件。</p><p>注意启动后报错，需要加入JAVA_HOME环境变量，也在spark-env.sh中.</p><h1 id="Spark编译记录"><a href="#Spark编译记录" class="headerlink" title="Spark编译记录"></a>Spark编译记录</h1><p><a href="https://blog.csdn.net/babyhuang/article/details/78656093" target="_blank" rel="noopener">参考教程</a></p><p>在官网下载Spark源码，安装maven(我安装的版本是3.3.9) ，添加maven镜像(已备份)，修改dev目录下的make-distribution.sh文件，将Spark，Hadoop，Scala版本都换为自己的。</p><p>然后用README里的命令编译。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Spark搭建记录-2018-11-2&quot;&gt;&lt;a href=&quot;#Spark搭建记录-2018-11-2&quot; class=&quot;headerlink&quot; title=&quot;Spark搭建记录(2018.11.2)&quot;&gt;&lt;/a&gt;Spark搭建记录(2018.11.2)&lt;/h1&gt;&lt;p&gt;
      
    
    </summary>
    
    
      <category term="记录" scheme="https://ricky-ting.github.io/tags/%E8%AE%B0%E5%BD%95/"/>
    
      <category term="创新项目" scheme="https://ricky-ting.github.io/tags/%E5%88%9B%E6%96%B0%E9%A1%B9%E7%9B%AE/"/>
    
      <category term="大数据" scheme="https://ricky-ting.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>Records for Environment Setup for Hadoop</title>
    <link href="https://ricky-ting.github.io/2018/10/24/Records-for-Environment-Setup-for-Hadoop/"/>
    <id>https://ricky-ting.github.io/2018/10/24/Records-for-Environment-Setup-for-Hadoop/</id>
    <published>2018-10-24T03:20:25.000Z</published>
    <updated>2019-07-27T02:21:55.200Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Hadoop环境搭建记录"><a href="#Hadoop环境搭建记录" class="headerlink" title="Hadoop环境搭建记录"></a>Hadoop环境搭建记录</h1><h2 id="安装系统"><a href="#安装系统" class="headerlink" title="安装系统"></a>安装系统</h2><p>安装系统的时候出了很多问题，找不到引导，硬盘被锁啊，感觉不懂的还是很多，最后还是请学长帮忙装好了系统。</p><a id="more"></a><h2 id="Hadoop环境的搭建"><a href="#Hadoop环境的搭建" class="headerlink" title="Hadoop环境的搭建"></a>Hadoop环境的搭建</h2><p>Hadoop版本:2.2.0</p><p><a href="https://blog.csdn.net/fanxin_i/article/details/80425461" target="_blank" rel="noopener">参考教程</a></p><p>教程简版： 1.获取IP，添加解析。2.关闭防火墙 3.安装jdk 4.安装ssh，配置免密通信 5. 安装hadoop，在hdfs目录下创建文件夹(tmp,name,data). 6.修改Hadoop配置文件包括以下几个文件(core-site.xml hadoop-env.sh hdfs-site.xml yarn-env.sh yarn-site.xml slaves).(这些配置文件会备份在github中) 7.用scp将文件夹传到slave上。 然后在master上初始化namenode(hdfs namenode -format)</p><p>设置文件路径的时候尽量要绝对路径，不用加file</p><p>注意hosts, 不要127.0.0.1 master</p><p>我的理解是主要在master里执行namenode初始化就好了，初始化之前最好把master和slave里hdfs目录下删干净(以后可以写个脚本干这个事)。</p><h2 id="写脚本"><a href="#写脚本" class="headerlink" title="写脚本"></a>写脚本</h2><p>写脚本实现只运行MapReduce和在HDFS上运行MapReduce。</p><p>我的理解是只要改改配置文件就好，要运行哪一种方式只要把相应的配置文件拷进去就好。 因为不运行yarn，所以要把yarn的相关配置删除。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env bash</span><br><span class="line"></span><br><span class="line">echo &quot;This is to run mapreduce on hdfs&quot;</span><br><span class="line">rm -rf ~/hadoop-2.2.0/etc/hadoop</span><br><span class="line">echo &quot;Original config files in hadoop-2.2.0/ect/hadoop deleted&quot;</span><br><span class="line">cp -r ~/hadoopconfig/hadoop-distributed ~/hadoop-2.2.0/etc/</span><br><span class="line">echo &quot;Copy config files of hdfs to hadoop-2.2.0/etc/hadoop&quot;</span><br><span class="line">mv ~/hadoop-2.2.0/etc/hadoop-distributed ~/hadoop-2.2.0/etc/hadoop</span><br><span class="line">echo &quot;Rename successfully&quot;</span><br><span class="line">cd ~/hadoop-2.2.0</span><br><span class="line">echo &quot;About to run start-dfs.sh&quot;</span><br><span class="line">start-dfs.sh</span><br><span class="line">echo &quot;About to run an example on hdfs&quot;</span><br><span class="line">hadoop jar /home/hadoop/hadoop-2.2.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar pi 10 10</span><br><span class="line">jps</span><br><span class="line">echo &quot;About to run stop-dfs.sh&quot;</span><br><span class="line">stop-dfs.sh</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env bash</span><br><span class="line"></span><br><span class="line">echo &quot;This is to run mapreduce without hdfs&quot;</span><br><span class="line">rm -rf ~/hadoop-2.2.0/etc/hadoop</span><br><span class="line">cp -r ~/hadoopconfig/hadoop-native ~/hadoop-2.2.0/etc/</span><br><span class="line">mv ~/hadoop-2.2.0/etc/hadoop-native ~/hadoop-2.2.0/etc/hadoop</span><br><span class="line">cd ~/hadoop-2.2.0</span><br><span class="line">./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.2.0.jar pi 10 10</span><br><span class="line">~</span><br><span class="line">~</span><br><span class="line">~</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Hadoop环境搭建记录&quot;&gt;&lt;a href=&quot;#Hadoop环境搭建记录&quot; class=&quot;headerlink&quot; title=&quot;Hadoop环境搭建记录&quot;&gt;&lt;/a&gt;Hadoop环境搭建记录&lt;/h1&gt;&lt;h2 id=&quot;安装系统&quot;&gt;&lt;a href=&quot;#安装系统&quot; class=&quot;headerlink&quot; title=&quot;安装系统&quot;&gt;&lt;/a&gt;安装系统&lt;/h2&gt;&lt;p&gt;安装系统的时候出了很多问题，找不到引导，硬盘被锁啊，感觉不懂的还是很多，最后还是请学长帮忙装好了系统。&lt;/p&gt;
    
    </summary>
    
    
      <category term="记录" scheme="https://ricky-ting.github.io/tags/%E8%AE%B0%E5%BD%95/"/>
    
      <category term="创新项目" scheme="https://ricky-ting.github.io/tags/%E5%88%9B%E6%96%B0%E9%A1%B9%E7%9B%AE/"/>
    
      <category term="大数据" scheme="https://ricky-ting.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>How to make an installation USB for Linux or other OS in Mac OS X</title>
    <link href="https://ricky-ting.github.io/2018/10/17/How-to-make-an-installation-USB-for-Linux-or-other-OS-in-Mac-OS-X/"/>
    <id>https://ricky-ting.github.io/2018/10/17/How-to-make-an-installation-USB-for-Linux-or-other-OS-in-Mac-OS-X/</id>
    <published>2018-10-17T12:55:11.000Z</published>
    <updated>2018-10-17T12:55:47.121Z</updated>
    
    <content type="html"><![CDATA[<h1 id="How-to-make-an-installation-USB-for-Linux-or-other-OS-in-Mac-OS-X"><a href="#How-to-make-an-installation-USB-for-Linux-or-other-OS-in-Mac-OS-X" class="headerlink" title="How to make an installation USB for Linux or other OS in Mac OS X"></a>How to make an installation USB for Linux or other OS in Mac OS X</h1><p>Step1: Download the image(iso) file from the Internet.</p><p>Step2: Open a Terminal(the following command are all completed in a terminal)</p><a id="more"></a><p>Step3: Trun <code>.iso</code> file into <code>.img</code> file by <code>hdiutil convert -format UDRW -o ~/path/to/target.img ~/path/from/src.iso</code>(The file created may end with <code>.dmg</code>)</p><p>Step4: <code>diskutil list</code> to obtain the devices mounted.</p><p>Step5: Insert your USB.</p><p>Step6: <code>diskutil list</code> to see which is added(/dev/diskN).</p><p>Step7: <code>diskutil unmountDisk /dev/diskN</code> to unmount USB</p><p>Step8: <code>sudo dd if=/path/to/target.img of=/dev/rdiskN bs=1m</code> to write the installation file into the USB</p><p>Step9: <code>diskutil eject /dev/diskN</code> to eject your USB.</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;How-to-make-an-installation-USB-for-Linux-or-other-OS-in-Mac-OS-X&quot;&gt;&lt;a href=&quot;#How-to-make-an-installation-USB-for-Linux-or-other-OS-in-Mac-OS-X&quot; class=&quot;headerlink&quot; title=&quot;How to make an installation USB for Linux or other OS in Mac OS X&quot;&gt;&lt;/a&gt;How to make an installation USB for Linux or other OS in Mac OS X&lt;/h1&gt;&lt;p&gt;Step1: Download the image(iso) file from the Internet.&lt;/p&gt;
&lt;p&gt;Step2: Open a Terminal(the following command are all completed in a terminal)&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Summary of definitions and theorems in graph theory</title>
    <link href="https://ricky-ting.github.io/2018/10/15/Summary-of-definitions-and-theorems-in-graph-theory/"/>
    <id>https://ricky-ting.github.io/2018/10/15/Summary-of-definitions-and-theorems-in-graph-theory/</id>
    <published>2018-10-15T14:06:07.000Z</published>
    <updated>2019-01-08T06:11:07.116Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Summary-of-definitions-and-theorems-in-graph-theory"><a href="#Summary-of-definitions-and-theorems-in-graph-theory" class="headerlink" title="Summary of definitions and theorems in graph theory"></a>Summary of definitions and theorems in graph theory</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="1-1-Graphs-and-Graph-Models"><a href="#1-1-Graphs-and-Graph-Models" class="headerlink" title="1.1 Graphs and Graph Models"></a>1.1 Graphs and Graph Models</h3><p>A <strong>Graph</strong> G consists of a finite nonempty set $V$ of objects called <strong>vertices</strong> and a set $E$ of 2-element subsets of $V$ called <strong>edges</strong>. The ses $V$ and $E$ are the <strong>vertex set</strong> and <strong>edge set</strong> of $G$, respectively. Write $G=(V,E)$.</p><p>Two graphs $G$ and $H$ are <strong>equal</strong> if $V(G)=V(H)$ and $E(G)=E(H)$, in which case we write $G=H$.</p><p>If $uv$ is an edge of $G$, then $u$ and $v$ are said to be <strong>adjacent</strong> in $G$.</p><p>The number of vertices in $G$ is often called the <strong>order</strong> of $G$, while the number of edges is its <strong>size</strong>.</p><p>A graph with exactly one vertex is called a <strong>trivial graph</strong>, implying that the order of a <strong>nontrivial graph</strong> is at least 2.</p><p><strong>labeled graph</strong> and <strong>unlabeled graph</strong></p><p>A graph $G$ is called a <strong>word graph</strong> if $G$ is the word graph of some set $S$ of 3-letter words.</p><a id="more"></a><h3 id="1-2-Connected-Graphs"><a href="#1-2-Connected-Graphs" class="headerlink" title="1.2 Connected Graphs"></a>1.2 Connected Graphs</h3><p>The adjacent vertices $u$ and $v$ are said to be <strong>joined</strong> by the edge $e$. The vertices $u$ and $v$ are referred to as <strong>neighbors</strong> of each other. </p><p>Distinct edges incident with a common vertex are <strong>adjacent edges</strong>.</p><p>A graph $H$ is called a <strong>subgraph</strong> of a graph $G$, written $H \subseteq G$, if $V(H) \subseteq V(G)$ and $E(H) \subseteq E(G)$. We also say that $G$ contains $H$ as a subgraph. If $H \subseteq G$ and either $V(H)$ is a proper subset of $V(G)$ or $E(H)$ is a proper subset of $E(G)$, then $H$ is a <strong>proper subgraph</strong> of $G$. If a subgraph of a graph $G$ has the same vertex set as $G$, then it is a <strong>spanning subgraph</strong> of $G$.</p><p>A subgraph $F$ of a graph $G$ is called an <strong>induced subgraph</strong> of $G$ if whenever $u$ and $v$ are vertices of $F$ and $uv$ is an edge of $G$, then $uv$ is an edge of $F$ as well.</p><p>If $S$ is a nonempty set of vertices of a graph $G$, then the <strong>subgraph</strong> of $G$ <strong>induced by</strong> $S$ is the induced subgraph with vertex set $S$. This induced subgraph is denoted by $G[S]$.</p><p>For a nonempty set $X$ of edges, the <strong>subgraph G[X] induced by</strong> $X$ has edge set $X$ and consists of all vertices that are incident with at least one edge in $X$. This subgraph is called an <strong>edge-induced subgraph</strong> of $G$.   </p><p>A $u-v$ <strong>walk</strong> $W$ in $G$ is a sequence of vertices in $G$, beginning with $u$ and ending at $v$ such that consecutives vertices in the sequence are adjacent. If $u=v$, then the walk $W$ is <strong>closed</strong>; while if $u\not=v$, then $W$ is <strong>open</strong>. A walk of length 0 is a <strong>trivial walk</strong>.</p><p>We define a $u-v$ <strong>trial</strong> in a graph $G$ to be a $u-v$ walk in which no edges is traversed more than once.</p><p>A $u-v$ walk in a graph in which no vertices are repeated is a $u-v$ <strong>path</strong>. </p><p>A <strong>circuit</strong> in a graph $G$ is a closed trail of length 3 or more. Hence a circuit begins and ends at the same vertex but repeats no edges.</p><p>A circuit that repeats no vertex, except for the first and last, is a <strong>cycle</strong>.</p><p>If $G$ contains a $u-v$ path, then $u$ and $v$ are said to be <strong>connected</strong> and $u$ is <strong>connected to</strong> $v$.</p><p>A graph $G$ is <strong>connected</strong> if every two vertices of $G$ are connected. A graph that is not connected is called <strong>disconnected</strong>. A connected subgraph of $G$ that is not a proper subgraph of any other connected subgraph of $G$ is a <strong>component</strong> of $G$. The number of components of a graph $G$ is denoted by $k(G)$. Every graph is the union of its components.</p><p>The <strong>distance</strong> between $u$ and $v$ is the smallest length of any $u-v$ path in $G$ and is denoted by $d_{G}(u,v)$ or simply $d(u,v)$. A $u-v$ path of length $d(u,v)$ is called a $u-v$ <strong>geodesic</strong>.</p><p>The greatest distance between any two vertices of a connected graph $G$ is called the <strong>diameter</strong> of $G$ and is denoted by $diam(G)$.</p><p><strong>Theorem 1.10</strong> Let $G$ be a graph of order 3 or more. Then $G$  is connected if and only if $G$ contains two distinct vertices $u$  and $v$  such that $G-u$ and $G-v$ are connected.</p><h3 id="1-3-Common-Classes-of-Graphs"><a href="#1-3-Common-Classes-of-Graphs" class="headerlink" title="1.3 Common Classes of Graphs"></a>1.3 Common Classes of Graphs</h3><p>$G$ is called a <strong>path</strong> if …</p><p>$G$ is called a <strong>cycle</strong> if …</p><p>A graph $G$ is <strong>complete</strong> if every two distinct vertices of $G$ are adjacent. A complete graph of order $n$ is denoted by $K_n$.</p><p>The <strong>complement</strong> $\bar{G}$ of a graph $G$ is that graph whose vertex set is $V(G)$ and such that for each pair $u,v$ of distinct vertices of $G$, $uv$ is an edge of $\bar{G}$ if and only if $uv$ is not an edge of $G$.</p><p>The graph $\bar{K_n}$ has $n$ vertices and no edges, it is called the <strong>empty graph</strong> of order $n$.</p><p><strong>Theorem 1.11</strong> If $G$  is a disconnected graph, then $\bar{G}$ is connected.</p><p><strong>Theorem 1.12</strong> A nontrivial graph $G$ is a bipartite graph if and only if $G$ contains no odd cycles.</p><p>A graph $G$ is a <strong>bipartite graph</strong> if $V(G)$ can be partitioned into two subsets $U$ and $W$, called <strong>partite sets</strong>, such that every edge of $G$ joins a vertex of $U$ and a vertex of $W$.</p><p>If every vertex of $U$  is adjacent to every vertex of $W$ , then we call $G$  a <strong>complete bipartite graph</strong> . A complete graph with $|U|=s$  and $|W|=t$ is denoted by $K<em>{s,t}$ or $K</em>{t,s}$. If either $s=1$ or $t=1$, then $K_{s,t}$ is a <strong>star</strong>.</p><p>A graph $G$  is a $k$<strong>-partite graph</strong> if $V(G)$ can be partitioned into $k$ subsets $V_1$,$V_2$,…,$V_k$,(called <strong>partite sets</strong>) such that if $uv$ is an edge of $G$, then $u$ and $v$ belong to different partite sets. If, in addition, every  two vertices in different partite sets are joined by an edge, then $G$ is a <strong>complete k-partite graph</strong>. If $|V_i|=n<em>i$ for $1 \le i \le k$, then we denote this graph by $K</em>{n1,n2,…,nk}$. </p><p>The <strong>join</strong> $G+H$ consists of $G \cup H$ and all edges joining a vertex of $G$ and a vertex of $H$.</p><p>The <strong>Cartesian product</strong> $G \times H$ has vertex set $V(G \times H) = V(G) \times V(H)$ . Two distinct vertices $(u,v$) and $(x,y)$ are adjacent in $G \times H$ if either (1) $u=x$ and $vy\in E(H)$ or (2) $v=y$ and $ux\in E(G)$.</p><p>We define $Q_1 $ to be $ K<em>2 $ and for $n \ge 2$, define $Q</em>{n}$ to be $Q_{n-1} \times K_2 $. The graphs $Q_n $ are then called $n$<strong>-cubes</strong> or <strong>hypercubes</strong>.</p><h3 id="1-4-Multigraphs-and-Digraphs"><a href="#1-4-Multigraphs-and-Digraphs" class="headerlink" title="1.4 Multigraphs and Digraphs"></a>1.4 Multigraphs and Digraphs</h3><p>A <strong>multigraph</strong> $M$ consists of a finite nonempty set $V$ of vertices and a set $E$ of edges, where every two vertices of M are joined by a finite number of edges(possibly zero). If two or more edges join the same pair of (distinct) vertices, then these edges are called <strong>parallel</strong> edges.</p><p>In a <strong>pseudograph</strong>, not only are parallel edges permitted but an edge is also permitted to join a vertex to itself. Such an edge is called a <strong>loop</strong>.</p><p>A <strong>digraph</strong>(or <strong>directed graph</strong>) $D$ is a finite nonempty set $V$ of objects called <strong>vertices</strong> together with a set $E$ of ordered pairs of distinct vertices. The elements of $E$ are called <strong>directed edges</strong> or <strong>arcs</strong>. If $(u,v)$ is a directed edge, then we indicate this in a diagram representing $D$ by drawing a directed line segment or curve from $u$ to $v$. Then u is said to be <strong>adjacent to</strong> v and v is <strong>adjacent from</strong> u.</p><p>If, in the definition of digraph, for each pair $u,v$ of distinct vertices, at most one of $(u,v)$ and $(v,u)$ is a directed edge, then the resulting digraph is an <strong>oriented graph</strong>  </p><h2 id="Degrees"><a href="#Degrees" class="headerlink" title="Degrees"></a>Degrees</h2><h3 id="2-1-The-Degree-of-a-Vertex"><a href="#2-1-The-Degree-of-a-Vertex" class="headerlink" title="2.1 The Degree of a Vertex"></a>2.1 The Degree of a Vertex</h3><p>The <strong>degree of a vertex</strong> $v$ in a graph $G$ is the number of edges incident with $v$ and is denoted by $deg_G \ v$ or simply by $deg \ v$ if the graph $G$ is clear from the context.  The set $N(v)$ of neighbors of a vertex $v$  is called the <strong>neighborhood</strong> of $v$. Thus $deg \ v = |N(v)|$.</p><p>A vertex of degree 0 is referred to as an <strong>isolated vertex</strong> and a vertex of degree 1 is an <strong>end-vertex</strong>(or a <strong>leaf</strong>). </p><p>The <strong>minimum degree</strong> of $G$  is the minimum degree among the vertices of $G$ and is denoted by $\delta(G)$, the <strong>maximum degree</strong> of $G$ is denoted by $\Delta(G)$.</p><p>For $G$ of order $n$, we have $0 \le \delta(G) \le deg \ v \le \Delta(G) \le n-1$.</p><p><strong>Theorem 2.1(The First Theorem of Graph Theory)</strong>  If $G$  is a graph of size $m$, then $\sum \limits_{v\in V(G)} deg \ v =2m$.</p><p>A vertex of even degree is called an <strong>even vertex</strong>, while a vertex of odd degree is an <strong>odd vertex</strong>.</p><p><strong>Corollary 2.3</strong> Every graph has an even number of odd vertices.</p><p>If a graph $G$ order $n$ contains a vertex of degree $n-1$, then $G$ is connected. However, this is not a necessary condition.</p><p><strong>Theorem 2.4</strong> Let $G$ be a graph of order $n$. If $deg \ u + deg \ v \ge n-1$, for every two nonadjacent vertices $u$ and $v$ of $G$ , then $G$ is connected and $diam(G) \le 2$.</p><ul><li><p>The bound of <strong>Theorem 2.4</strong> is sharp.</p></li><li><p><strong>What if there is only one pair?</strong></p></li></ul><p><strong>Corollary 2.5</strong> If $G$  is a graph of order $n$ with $\delta(G) \ge (n-1)/2$, then $G$ is connected.</p><p><strong>outdegree</strong> and <strong>indegree</strong>.</p><h3 id="2-2-Regular-Graphs"><a href="#2-2-Regular-Graphs" class="headerlink" title="2.2 Regular Graphs"></a>2.2 Regular Graphs</h3><p>If $\delta(G)=\Delta(G)$, then the vertices of $G$  have the same degree and $G$  is called <strong>regular</strong>. If $deg \ r=r$ for every vertex $v$  of $G$, where $0 \le r \le n-1$, then $G$  is $r$ <strong>-regular</strong> or <strong>regular of degree r</strong>.</p><p>A 3-regular graph is also referred to as a <strong>cubic graph</strong>. The best known cubic graph may very well be the <strong>Petersen graph</strong>.</p><p><strong>Theorem 2.6</strong> Let $r$ and $n$  be integers with $0 \le r \le n-1$. There exists an r-regular graph of order $n$  if and only if at least one of $r$ and $n$  is even.</p><ul><li><p>How to construct this graph?  </p></li><li><p>The graphs $H_{r,n}$ are called <strong>Harary graph</strong></p></li></ul><p><strong>Theorem 2.7</strong> For every graph $G$ and every integer $r \ge \Delta(G)$, there exists an r-regular graph $H$ containing $G$ as an induced subgraph.</p><h3 id="2-3-Degree-Sequences"><a href="#2-3-Degree-Sequences" class="headerlink" title="2.3 Degree Sequences"></a>2.3 Degree Sequences</h3><p>If the degrees of the vertices of a graph $G$ are listed in a sequence $s$, then $s$  is called a <strong>degree sequence</strong> of $G$.</p><p>A finite sequence of nonnegative integers is called <strong>graphical</strong> if it is a degree sequence of some graph.</p><p><strong>Theorem 2.10</strong> A non-increasing sequence $s$: $d_1 ,d_2 ,…,d_n (n\ge 2)$ of non-negative integers, where $d_1 \ge 1$, is graphical if and only if the sequence $s_1：d<em>2 -1,d</em> 3-1,…,d<em>{d</em> 1 + 1}-1,d<em>{d</em> 1+1}-1,d<em>{d</em> 1+2},…d_ n $ is graphical.</p><h2 id="Isomorphic-Graphs"><a href="#Isomorphic-Graphs" class="headerlink" title="Isomorphic Graphs"></a>Isomorphic Graphs</h2><h3 id="3-1-The-Definition-of-Isomorphism"><a href="#3-1-The-Definition-of-Isomorphism" class="headerlink" title="3.1 The Definition of Isomorphism"></a>3.1 The Definition of Isomorphism</h3><p>We call two graphs $G$ and $H$ “isomorphic” if they have the same structure and write $G \cong H$ to indicate this. </p><p>Formally, two (labeled) graphs $G$ and $H$  are <strong>isomorphic</strong> (have the same structure) if there exists a one-to-one correspondence $\phi$ from $V(G)$ to $V(H)$ such that $uv \in E(G)$ if and only if $\phi(u)\phi(v) \in E(H)$. In this case, $\phi$  is called an <strong>isomorphism</strong> from $G$ to $H$.</p><p><strong>Theorem 3.1</strong> Two graphs $G$ and $H$ are isomorphic if and only if their complements $\bar{G}$ and $\bar{H}$ are isomorphic.</p><p>A graph $G$ is <strong>self-complementary</strong> if $G\cong \bar{G}$ . </p><p><strong>Theorem 3.2</strong> If $G$ and $H$ are isomorphic graphs, then the degrees of the vertices of $G$ are the same as the degrees of the vertices of $H$.</p><p><strong>Note</strong>: Having the same degree sequences don’t necessarily mean two graph are isomorphic.</p><h2 id="Trees"><a href="#Trees" class="headerlink" title="Trees"></a>Trees</h2><h3 id="4-1-Bridges"><a href="#4-1-Bridges" class="headerlink" title="4.1 Bridges"></a>4.1 Bridges</h3><p>An edge $e=uv$ of a connected graph $G$ is called a <strong>bridge</strong> of $G$ if $G-e$ is disconnected.</p><p>An edge $e$ is a <strong>bridge</strong> of a disconnected graph if $e$ is a bridge of some component of $G$.</p><p>An edge $e$ is a bridge of a graph $G$ if and only if $k(G-e)=k(G)+1$</p><p>End-vertice: vertice with degree $1$.</p><p><strong>Theorem 4.1</strong>: <em>An edge $e$ of a graph $G$ is a bridge if and only if $e$ lies on no cycle of $G$</em> </p><h3 id="4-2-Trees"><a href="#4-2-Trees" class="headerlink" title="4.2 Trees"></a>4.2 Trees</h3><p>A graph G is called <strong>acyclic</strong> if it has no cycles.</p><p>A <strong>tree</strong> is an acyclic connected graph.</p><p>Every edge in a tree is a bridge.</p><p>A tree containing exactly two vertices that are not end-vertices(which are necessarily adjacent) is called a <strong>double star</strong>.</p><p>A <strong>caterpillar</strong> is a tree of order 3 or more, the removal of whose end-vertices produces a path called <strong>spine</strong> of the caterpillar.</p><p>Choose a vertex of a tree $T$, and designate this vertex as the <strong>root</strong> of $T$. The tree $T$ then becomes a <strong>rooted tree</strong>. </p><p>Acyclic graphs are also referred to as <strong>forests</strong>. Therefore each component of a forest is a tree.</p><p>The one fact that distinguishes trees from forests is that a tree is required to be connected, while a forest is not required to be connected.</p><p><strong>Theorem 4.2</strong> <em>A graph $G$ is a tree if and only if every two vertices of G are connected by a unique path</em>.</p><p><strong>Theorem 4.3</strong> <em>Every nontrivial tree has at least two end-vertices</em>.</p><p><strong>Theorem 4.4</strong> <em>Every tree of order n has size $n-1$</em></p><p><strong>Corollary 4.6</strong> <em>Every forest of order n with k components has size $n-k$</em></p><p><strong>Theorem 4.7</strong> <em>The size of every connected graph of order $n$ is at least $n-1$</em>.</p><p><strong>Theorem 4.8</strong> <em>Let $G$ be a graph of order $n$ and size $m$. If $G$ satisfies any two of the properties: (1) $G$ is connected, (2)$G$ is acyclic, (3)$m=n-1$, then $G$ is a tree.</em></p><p><strong>Theorem 4.9</strong> <em>Let $T$ be a tree of order $k$. If $G$ is a graph with $\delta(G) \ge k-1$, then $T$ is isomorphic to some subgraph of $G$</em></p><h3 id="4-3-The-Minimum-Spanning-Tree-Problem"><a href="#4-3-The-Minimum-Spanning-Tree-Problem" class="headerlink" title="4.3 The Minimum Spanning Tree Problem"></a>4.3 The Minimum Spanning Tree Problem</h3><p>A spanning subgraph $H$ of a connected graph $G$ such that $H$ is a tree is called a <strong>spanning tree</strong> of $G$.</p><p><strong>Theorem 4.10</strong> <em>Every connected graph contains a spanning tree</em>.</p><p>The <strong>weight</strong> $w(H)$ of $H$ is defined as the sum of the weights of its edges.</p><p>A spanning tree with the minimum weight is called a <strong>minimum spanning tree</strong>.</p><p>The problem of finding a minimum spanning tree in a connected weighted graph is called the <strong>Minimum Spanning Tree Problem</strong>. </p><p><strong>Kruskal’s Algorithm</strong>: For a connected weighted graph $G$, a spanning tree $T$ of $G$ is constructed as follows: For the first edge $e_1$ of $T$, we select any edge of $G$ of minimum weight and for the second edge $e_2$ of $T$, we select any remaining edge of $G$ of minimum weight. For the thrid edge $e_3$ of T, we choose any remaining edge of $G$ of minimum weight that does not produce a cycle with the previously selected edges. We continue in the manner until a spanning tree is produced.</p><p><strong>Theorem 4.11</strong> <em>Kruskal’s Algorithm produces a minimum spanning tree in a connected weighted graph</em>.</p><ul><li>证明思路：取与T共同边数最多的最小生成树为H，取其中第一条不在T的边，构造新的生成树，构造关系，证明相等，矛盾</li></ul><p><strong>Prim’s Algorithm</strong>: For a connected weighted graph $G$, a spanning tree $T$ of $G$ is constructed as follows: For an arbitrary vertex $u$ for $G$, an edge of minimum weight incident with $u$ is selected as the first edge $e_1$ of $T$. For subsequent edges $e_2$, $e<em>3$, ..,$e</em>{n-1}$, we select an edge of minimum weight among those edges having exactly one of its vertices incident with an edge already selected.</p><p><strong>Theorem 4.12</strong> <em>Prim’s Algorithm produces a minimum spanning tree in a connected weighted graph.</em></p><h3 id="4-4-Excursion-The-Number-of-Spanning-Trees"><a href="#4-4-Excursion-The-Number-of-Spanning-Trees" class="headerlink" title="4.4 Excursion: The Number of Spanning Trees"></a>4.4 Excursion: The Number of Spanning Trees</h3><p><strong>THeorem 4.15</strong> <em>The number of distinct trees of order n with a specified vertex set is $n^{n-2}$</em>.</p><p><strong>Matrix Tree Theorem</strong> (to be continued).</p><h2 id="Connectivity"><a href="#Connectivity" class="headerlink" title="Connectivity"></a>Connectivity</h2><h3 id="5-1-Cut-Vertices"><a href="#5-1-Cut-Vertices" class="headerlink" title="5.1 Cut-Vertices"></a>5.1 Cut-Vertices</h3><p>A vertex $v$ in a connected graph $G$ is a <strong>cut-vertex</strong> of $G$ if $G-v$  is disconnected. More generally, a vertex $v$ is a cut-vertex in a graph $G$  if $v$  is a cut-vertex of a component of $G$.</p><p><strong>Theorem 5.1</strong> Let $v$ be a vertex incident with a bridge in a connected graph $G$. Then $v$ is a cut-vertex of $G$ if and only if $deg \ v \ge 2$. </p><p><strong>Corollary 5.2</strong> Let $G$ be a connected graph of order 3 or more. If $G$ contains a bridge, then $G$  contains a cut-vertex.</p><p><strong>Theorem 5.3</strong> Let $v$ be a cut-vertex in a connected graph $G$ and let $u$ and $w$ be vertices in distinct components of $G-v$ . Then $v$ lies on every $u-w$ path in $G$.</p><p><strong>Corollary 5.4</strong> A vertex $v$ of a connected graph $G$  is a cut-vertex of $G$ if and only if there exist vertices $u$ and $w$ distinct from $v$ such that $v$ lies on every $u-w$ path of $G$.</p><p><strong>Theorem 5.5</strong> Let $G$ be a nontrivial connected graph and let $u\in V(G)$ . If $v$ is a vertex that is farthest from $u$ in $G$, then $v$ is not a cut-vertex of $G$.</p><p><strong>Corollary 5.6</strong> Every nontrivial connected graph contains at least two vertices that are not cut-vertices.</p><h3 id="5-2-Blocks"><a href="#5-2-Blocks" class="headerlink" title="5.2 Blocks"></a>5.2 Blocks</h3><p>A nontrivial connected graph with no cut-vertices is called a <strong>nonseparable graph</strong>.</p><p><strong>Theorem 5.7</strong> A graph of order at least 3 is nonseparable if and only if every two vertices lie on a common cycle.</p><p><strong>Theorem 5.8</strong> Let $R$ be the relation defined on the edge set of a nontrivial connected graph $G$ by $e \ R \ f$, where $e,f \in E(G)$, if $e=f$ or $e$ and $f$ lie on a common cycle of $G$. Then $R$ is an equivalence relation.</p><p><strong>Corollary 5.9</strong> Every two distinct blocks $B_1$ and $B_2$ in a nontrivial connected graph $G$ have the following properties: </p><ul><li><p>(a) The blocks $B_1$ and $B_2$ are edge-disjoint.</p></li><li><p>(b) The blocks $B_1$ and $B_2$ have at most one vertex in common.</p></li><li><p>(c) If $B_1$ and $B_2$ have a vertex $v$ in common, then $v$ is a cut-vertex of $G$.</p></li></ul><h3 id="5-3-Connectivity"><a href="#5-3-Connectivity" class="headerlink" title="5.3 Connectivity"></a>5.3 Connectivity</h3><p>By a <strong>vertex-cut</strong> in a graph $G$, we mean a set $U$ of vertices of $G$ such that $G-U$ is disconnected. A vertex-cut of minimum cardinality in $G$ is called a <strong>minimum vertex-cut</strong>.</p><p><strong>Note</strong>: A connected graph contains a vertex-cut if and only if $G$ is not complete.</p><p>For a graph $G$ that is not complete, the <strong>vertex-connectivity</strong>(or simply the <strong>connectivity</strong>) $\kappa(G)$ of $G$ is defined as the cardinality of a minimum vertex-cut of $G$; if $G=K_n$ for some positive integer $n$, then $\kappa(G)$ is defined to be $n-1$. $$0 \le \kappa(G) \le n-1$$.</p><p>For a nonnegative integer $k$, a graph $G$ is said to be $k$<strong>-connected</strong> if $\kappa(G) \ge k$.</p><p>An <strong>edge-cut</strong> in a nontrivial graph $G$  is a set $X$ of edges of $G$ such that $G-X$ is disconnected.</p><p>An edge-cut $X$  of a connected graph $G$  is <strong>minimal</strong> if no proper subset of $X$ is an edge-cut of $G$. If $X$ is a minimal edge-cut of a connected graph $G$, then $G-X$ contains exactly two components $G_1$ and $G_2$. Necessarily  then , $X$ consists of all those edges of $G$  joining $G_1$ and $G_2$.  </p><p>An edge-cut of minimum cardinality is called a <strong>minimum edge-cut</strong>.</p><p>The <strong>edge-connectivity</strong> …….</p><p>For a nonnegative integer $k$, …</p><p><strong>Theorem 5.11</strong> For every graph $G$, $$ \kappa(G) \le \lambda(G) \le \delta(G) $$</p><p><strong>Theorem 5.12</strong> If $G$ is a cubic graph, then $\kappa(G) = \lambda(G)$.</p><p><strong>Theorem 5.13</strong> If $G$ is a graph of order $n$ and size $m \le n-1$, then $\kappa(G) \le \lfloor \frac{2m}{n} \rfloor$ .</p><p>$\kappa(T)=1$</p><p>Let $G$ be a connected graph of diameter $d$. For an integer $k$ with $1 \le k \le d$, the $k$<strong>th power</strong> $G^k $ of $G$  is the graph with $V(G^k ) = V(G)$ such that $uv$ is an edge of $G^k$ if $1 \le d_{G} (u,v) \le k$.</p><p><strong>Theorem 5.14</strong> If $G$ is a connected graph of order at least 3, then its square $G^2$  is 2-connected.</p><p><strong>Theorem 5.15</strong> For every two integers $r$ and $n$ with $2 \le r \le n$, $$\kappa(H_{r,n})=r$$.</p><h3 id="5-4-Menger’s-Theorem"><a href="#5-4-Menger’s-Theorem" class="headerlink" title="5.4 Menger’s Theorem"></a>5.4 Menger’s Theorem</h3><p>TBC.</p><h2 id="Traversability"><a href="#Traversability" class="headerlink" title="Traversability"></a>Traversability</h2><h3 id="6-1-Eulerian-Graphs"><a href="#6-1-Eulerian-Graphs" class="headerlink" title="6.1 Eulerian Graphs"></a>6.1 Eulerian Graphs</h3><p>A circuit $C$ in a graph $G$ is called an <strong>Eulerian circuit</strong> if $C$ contains every edge of $G$. Since no edges is repeated in a circuit, every edge appears exactly once in an Eulerian circuit. A connected graph that contains an Eulerian circuit is called an <strong>Eulerian graph</strong>.</p><p>For a connected graph $G$, we refer to an open trial that contains every edge of $G$ as an <strong>Eulerian trial</strong>.</p><p><strong>Theorem 6.1</strong> A nontrivial connected graph $G$ is Eulerian if and only if every vertex of $G$ has even degree.</p><p><strong>Theorem 6.2</strong> A connected graph $G$ contains an Eulerian trial if and only if exactly two vertices of $G$ have odd degree. Furthermore, each Eulerian trial of $G$ begins at one of these odd vertices and ends at the other.</p><p>We have a conclusion: Let $G$ and $H$ be nontrivial connected graphs. Then $G \times H$ is Eulerian if and only if both $G$ and $H$ are Eulerian or every vertex of $G$ and $H$  is odd.</p><h3 id="6-2-Hamiltonian-Graphs"><a href="#6-2-Hamiltonian-Graphs" class="headerlink" title="6.2 Hamiltonian Graphs"></a>6.2 Hamiltonian Graphs</h3><p>A cycle in a graph $G$ that contains every vertex of $G$ is called a <strong>Hamiltonian cycle</strong> of $G$. A <strong>Hamiltonian graph</strong> is a graph that contains a Hamiltonian cycle.</p><p>A path in a graph $G$ that contains every vertex of $G$ is called a <strong>Hamiltonian path</strong> in $G$.</p><p><strong>Theorem 6.4</strong> The Petersen graph is non-Hamiltonian.</p><p><strong>Theorem 6.5</strong> If $G$ is a Hamiltonian graph, then for every nonempty proper set $S$ of vertices of $G$, $$\kappa(G-S) \le |S|$$</p><p><strong>Theorem 6.6</strong> Let $G$ be a graph of order $n \ge 3$. If $deg \ u + deg \ v \ge n$ for each pair $u$, $v$ of nonadjacent vertices of $G$, then $G$ is Hamiltonian.</p><p><strong>Corollary 6.7</strong> Let $G$ be graph of order $n \ge 3$. If $deg \ v \ge n/2$  for each vertex $v$ of $G$, then $G$ is Hamiltonian.</p><p><strong>Theorem 6.8</strong> Let $u$ and $v$ be nonadjacent vertices in a graph $G$ of order $n$ such that $deg \ u + deg \ v \ge n$ . Then $G+uv$ is Hamiltonian if and only if $G$ is Hamiltonian.</p><p>The <strong>closure</strong> $C(G)$ of a graph $G$ of order $n$ is the graph obtained from $G$ by recursively joining pairs of nonadjacent vertices whose degree sum is at least $n$ (in the resulting graph at each stage) until no such pair remains.</p><p><strong>Theorem 6.9</strong> A graph is Hamiltonian if and only if its closure is Hamiltonian.</p><p><strong>Corollary 6.10</strong> If $G$ is a graph of order at least 3 such that $C(G)$ is complete, the n $G$ is Hamiltonian.</p><p><strong>Theorem 6.11</strong> Let $G$ be a graph of order $n \ge 3$. If for every integer $j$ with $ 1 \le j &lt; \frac{n}{2}$, the number of vertices of $G$ with degree at most $j$ is less than $j$, then $G$ is Hamiltonian.</p><h3 id="6-3-Hamiltonian-Walks"><a href="#6-3-Hamiltonian-Walks" class="headerlink" title="6.3 Hamiltonian Walks"></a>6.3 Hamiltonian Walks</h3><h2 id="Matchings-and-Factorization"><a href="#Matchings-and-Factorization" class="headerlink" title="Matchings and Factorization"></a>Matchings and Factorization</h2><h3 id="8-1-Matchings"><a href="#8-1-Matchings" class="headerlink" title="8.1 Matchings"></a>8.1 Matchings</h3><p>A set of edges in a graph is <strong>independent</strong> if no two edges in the set are adjacent.</p><p>By a <strong>macthing</strong> in a graph $G$ , we mean an independent set of edges in $G$.</p><p>The graph $G$ is said to satisfy <strong>Hall’s condition</strong> if $|N(X)| \ge|X|$ for every nonempty subset $X$ of $U$.</p><p><strong>Theorem 8.3</strong> Let $G$ be a bipartite graph with partite sets $U$ and $W$ such that $r= |U| \le |W|$. Then $G$ contains a matching of cardinality $r$ if and only if $G$ satisfies Hall’s condition.</p><p><strong>Theorem 8.4</strong> A collection ${ S_1 , S_2 , … , S_n}$ of nonempty finite sets has a system of distinct representatives if and only if for each integer $k$ with $1 \le k \le n$, the union of any $k$ of these sets contains at elast $k$ elements.</p><p><strong>Theorem 8.5(The Marriage Theorem)</strong> In a collection of $r$ women and $r$ men, a total of $r$ marriages between acquainted couples is possible if and only if for each integer $k$ with $1 \le k \le r$, every subset of $k$ women is collectively acquainted with at least $k$ men.</p><p>A matching of maximum cardinality is called a <strong>maximum matching</strong>.  </p><p>If a graph $G$ of order $2k$ has a matching $M$ of cardinality $k$, then this (necessarily maximum)  matching $M$ is called a <strong>perfect matching</strong> as $M$ matches every vertex of $G$ to some vertex of $G$ .</p><p><strong>Theorem 8.6</strong> Every r-regular bipartite graph($r \ge 1$)  has a perfect matching.</p><p>The <strong>edge independence number</strong> $\alpha’(G)$ of a graph $G$  is the maximum cardinality of an independent set of edges.</p><p>Furthermore, a graph $G$ of order $n$ has a perfect matching if and only if $n$ is even and $\alpha ‘(G) = n/2$.</p><p>A vertex and an incident edge are said to <strong>cover</strong> each other.</p><p>An <strong>edge cover</strong> of a graph $G$ without isolated vertices is a set of edges of $G$ that covers all vertices of $G$.</p><p>The <strong>edge covering number</strong> $\beta’(G)$ of a graph $G$ is the minimum cardlinality of an edge cover of $G$.  An edge cover of $G$ of cardinality $\beta’(G)$ is a <strong>minimum edge cover</strong> of $G$.</p><p><strong>Theorem 8.7</strong> For every graph $G$ of order $n$ containing no isolated vertices, $$\alpha(G’)+ \beta(G’)=n$$.</p><p>A set of vertices in a graph is <strong>independent</strong> if  no two vertices in the set are adjacent. The <strong>vertex independence number</strong> (or the <strong>independence number</strong>) $\alpha(G)$ of a graph $G$ is the maximum cardinality of an independent set of vertices in $G$. An independent set in $G$ of cardinality $\alpha(G)$ is called a <strong>maximum independent set</strong>. </p><p>A <strong>vertex cover</strong> in a graph $G$ is a set of vertices that covers all edges of $G$. The minimum number of vertices in a vertex cover of $G$  is the <strong>vertex covering number</strong> $\beta(G)$  of $G$. A vertex cover of cardinality $\beta(G)$ is a <strong>minimum vertex cover</strong> in $G$.</p><p><strong>Theorem 8.8</strong> For every graph $G$ of order $n$ containing no isolated vertices, $$\alpha(G) + \beta(G) =n$$. </p><h3 id="8-2-Factorization"><a href="#8-2-Factorization" class="headerlink" title="8.2 Factorization"></a>8.2 Factorization</h3><p>A 1-regular spanning subgraph of a graph $G$ is also called a <strong>1-factor</strong> of $G$. </p><p>A graph $G$ has a 1-factor if and only if $G$ has a perfect matching.</p><p>A component of a graph is <strong>odd</strong> or <strong>even</strong> according to whether its order is odd or even. We write $k_O (G)$ for the number of odd components of a graph $G$.</p><p><strong>Theorem 8.10</strong> A graph $G$ contains a 1-factor if and only if $k_O (G-S) \le |S|$ for every proper subset $S$ of $V(G)$.</p><p><strong>Theorem 8.11(Petersen’s Theorem)</strong> Every 3-regular bridgeless graph contains a 1-factor.</p><p><strong>Theorem 8.12</strong> Every 3-regular graph with at most two bridges contains a 1-factor.</p><p>A graph $G$ is said to be <strong>1-factorable</strong> if there exists 1-factors $F_1,F_2,…,F_r$ of $G$ such that ${E(F_1),E(F_2),..,E(F_r)}$ is a partition of $E(G)$.  We then say that $G$ is <strong>factored</strong> into the 1-factors $F_1.F_2,…,F_r$ , which form a <strong>1-factorization</strong> of $G$.</p><p>Every 1-factorable graph is regular.</p><p><strong>Theorem 8.13</strong> The Petersen graph is not 1-factorable.</p><p><strong>Theorem 8.14</strong> For each positive integer $k$, the complete graph $K_{2k}$ is 1-factorable.</p><p><strong>Theorem 8.15</strong> Every r-regular bipartite graph , $r\ge 1$, is factorable.</p><p>A <strong>2-factor</strong> in a graph $G$ is a spanning 2-regular subgraph of $G$. Every component of a 2-factor is therefore a cycle. A graph $G$ is said to be <strong>2-factorable</strong> if there exist 2-factors $F_1,F_2,..,F_k$ such that ${E(F_1),E(F_2),…,E(F_k)}$ is a partition of $E(G)$.</p><p><strong>Theorem 8.16</strong> A graph $G$ is 2-factorable if and only if $G$ is r-regular for some positive even integer $r$.</p><p>A spanning subgraph $F$ of a graph $G$ is called a <strong>factor</strong> of $G$. The graph $G$ is said to be <strong>factorable</strong> into the factors $F_1,F_2,…,F_k$ if ${E(F_1),E(F_2),…,E(F_k)}$ is a partition of $E(G)$. If each factor $F_i$ is isomorphic to some graph $G$, then $G$ is <strong>F-factorable</strong>.</p><p>TBC.</p><h3 id="8-3-Decompositions-and-Graceful-Labelings"><a href="#8-3-Decompositions-and-Graceful-Labelings" class="headerlink" title="8.3 Decompositions and Graceful Labelings"></a>8.3 Decompositions and Graceful Labelings</h3><p>A graph $G$ is said to be <strong>decomposable</strong> into the subgraphs $H_1,H_2,…,H_k$ if ${E(H_1),E(H_2),…,E(H_k)}$ is a partition of $E(G)$. Such a partition produces a <strong>decomposition</strong> of $G$.  If each $H_i$ is isomorphic to some graph $H$, then the graph $G$ is $H-$ <strong>decomposable</strong>  and the decomposition is an $H-$ <strong>decomposition</strong>. </p><p>A <strong>Steiner triple system</strong> of order $n$ is a set $S$ of cardinality $n$ and a collection $T$ of 3-element subsets, called <strong>triples</strong>, such that every two distinct elements of $S$ belong to a unique triple in $T$.</p><p>TBC</p><h2 id="Planarity"><a href="#Planarity" class="headerlink" title="Planarity"></a>Planarity</h2><h3 id="9-1-Planar-Graphs"><a href="#9-1-Planar-Graphs" class="headerlink" title="9.1 Planar Graphs"></a>9.1 Planar Graphs</h3><p>A graph $G$  is called a <strong>planar graph</strong> if $G$  can be drawn in the plane so that no two of its edges cross each other. A graph that is not planar is called <strong>nonplanar</strong>. A graph $G$ is called a <strong>plane graph</strong>  if it is drawn in the plane so that no two edges of $G$ cross. </p><p>A plane graph divides the plane into connected pieces called <strong>regions</strong>. In every plane graph, there is always one region that is unbounded. This is the <strong>exterior region</strong>.  The subgraph of a plane graph whose vertices and edges are incident with a given region $R$  is the <strong>boundary</strong> of $R$. </p><p><strong>Theorem 9.1(The Euler Identity)</strong> If $G$ is a connected plane graph of order $n$, size $m$ and having $r$ regions, then $n-m+r=2$.</p><p><strong>Theorem 9.2</strong> If $G$ is a planar graph of order $n \ge 3$ and size $m$, then $$m \le 3n-6$$.</p><p><strong>Corollary 9.3</strong> Every planar graph contains a vertex of degree 5 or less.</p><p><strong>Corollary 9.4</strong> The complete graph $K_5$ is nonplanar.</p><p><strong>Theorem 9.5</strong> The graph $K_{3,3}$ is nonplanar.</p><p>A graph $G$ is <strong>maximal planar</strong> if $G$ is planar but the addition of an edge between any two nonadjacent vertices of $G$  results in a nonplanar graph.</p><p>More formally, a graph is called a <strong>subdivision</strong> of a graph $G$ if $G’=G$ or one or more vertices of degree 2 are inserted into one or more edges of $G$.</p><p><strong>Theorem 9.7(Kuratowski’s Theorem)</strong> A graph $G$ is planar if and only if $G$ does not contain a subdivision of $K<em>5$ or $K</em>{3,3}$ as a subgraph. </p><h2 id="Coloring-Graphs"><a href="#Coloring-Graphs" class="headerlink" title="Coloring Graphs"></a>Coloring Graphs</h2><h3 id="10-2-Vertex-Coloring"><a href="#10-2-Vertex-Coloring" class="headerlink" title="10.2 Vertex Coloring"></a>10.2 Vertex Coloring</h3><p>With each map, there is associated a graph $G$  called the  <strong>dual</strong> of the map, whose vertices are the regions of the map and such that two vertices of $G$  are adjacent if the corresponding regions are neighboring regions.</p><p>By a <strong>proper coloring</strong> (or, more simply, a <strong>coloring</strong>)  of a graph $G$  ,  we mean an assignment of colors (elements of some set) to the vertices of $G$ , one color to each vertex, such that adjacent vertices are colored differently.  </p><p>The smallest number of colors in any coloring of a graph $G$  is called the <strong>chromatic number</strong>  of $G$  and is denoted by $\chi(G)$.  If it is possible to color $G$ from a set of $k$  colors, then $G$  is said to be <strong>k-colorable</strong>. A coloring that uses $k$ colors is called a <strong>k-coloring</strong>. If $\chi(G)=k$, then $G$ is said to be <strong>k-chromatic</strong> and every $k-coloring$ of $G$ is a <strong>minimum coloring</strong> of $G$. </p><p><strong>Theorem 10.1(The Four Color Theorem)</strong> The chromatic number of every planargraph is at most 4.</p><p>If $G$ is a k-chromatic graph, then it is possible to partition $V(G)$ into  $k-1$ independent sets $V_1 , V_2 , …., V_k $, called <strong>color classes</strong>, but it is not possible to partition $V(G)$ into $k-1$ independent sets.</p><p><strong>Theorem 10.2</strong> A graph $G$ has chromantic number 2 if and only if $G$ is a nonempty bipartite graph.</p><p>A graph $G$ of order $n$ has chromatic number $n$ if and only if $G =K_n$.</p><p>If $H$ is a subgraph of $G$, then $\chi(H) \le \chi(G)$.</p><p>A <strong>clique</strong> in a graph $G$ is a complete subgraph of $G$. The order of the largest clique ina graph $G$ is its <strong>clique number</strong>, which is denoted by $\omega(G)$.</p><p>In fact,  $\alpha(G)=k$ if and only if $\omega(\bar{G})=k$.</p><p><strong>Theorem 10.5</strong> For every graph $G$ of order $n$, $\chi(G \ge \omega(G))$ and $\chi(G) \ge \frac{n}{\alpha(G)}$.</p><p><strong>Theorem 10.7</strong> For every graph $G$, $$\chi(G) \le 1 + \Delta(G)$$ </p><p><strong>Theorem 10.8(Brooks’ Theorem)</strong> For every connected graph $G$ that is not an odd cycle or a complete graph, $\chi(G) \le \Delta(G)$.</p><p><strong>Theorem 10.9</strong> For every graph $G$, $\chi(G) \le 1+ max{\delta(H)}$, where the maximum is taken over all induced subgraphs $H$ of $G$.</p><p>The <strong>shadow graph</strong> $S(G)$ of a graph $G$ is obtained from $G$ by adding, for each vertex $v$ of $G$, a new vertex $v’$, called the <strong>shadow vertex</strong> of $v$ , and joining $v’$ to the neighbors of $v$ in $G$. Observe that (1) a vertex of $G$ and its shadow vertex are not adjacent in $S(G)$ and (2) no two shadow vertices are adjacent in $S(G)$.</p><p><strong>Theorem 10.10</strong> For every integer $k \ge 3$, there exists a triangle-free graph with chromatic number $k$.</p><p>A graph $G$ is called <strong>perfect</strong> if $\chi(H)=\omega(H)$ for every induced subgraph $H$ of $G$.</p><p><strong>The Perfect Graph Theorem</strong> A graph is perfect if and only if its complement is perfect.</p><p><strong>The Strong Perfect Graph T</strong> A graph $G$ is perfect if and only if neither $G$ nor $\bar{G}$ contains an induced odd cycle of length 5 or more.</p><p>Reference:</p><p>[1] G.Chartrand and P.Zhang, First Course in Graph Theory, New York: Dover Publications, 2012.</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Summary-of-definitions-and-theorems-in-graph-theory&quot;&gt;&lt;a href=&quot;#Summary-of-definitions-and-theorems-in-graph-theory&quot; class=&quot;headerlink&quot; title=&quot;Summary of definitions and theorems in graph theory&quot;&gt;&lt;/a&gt;Summary of definitions and theorems in graph theory&lt;/h1&gt;&lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h2&gt;&lt;h3 id=&quot;1-1-Graphs-and-Graph-Models&quot;&gt;&lt;a href=&quot;#1-1-Graphs-and-Graph-Models&quot; class=&quot;headerlink&quot; title=&quot;1.1 Graphs and Graph Models&quot;&gt;&lt;/a&gt;1.1 Graphs and Graph Models&lt;/h3&gt;&lt;p&gt;A &lt;strong&gt;Graph&lt;/strong&gt; G consists of a finite nonempty set $V$ of objects called &lt;strong&gt;vertices&lt;/strong&gt; and a set $E$ of 2-element subsets of $V$ called &lt;strong&gt;edges&lt;/strong&gt;. The ses $V$ and $E$ are the &lt;strong&gt;vertex set&lt;/strong&gt; and &lt;strong&gt;edge set&lt;/strong&gt; of $G$, respectively. Write $G=(V,E)$.&lt;/p&gt;
&lt;p&gt;Two graphs $G$ and $H$ are &lt;strong&gt;equal&lt;/strong&gt; if $V(G)=V(H)$ and $E(G)=E(H)$, in which case we write $G=H$.&lt;/p&gt;
&lt;p&gt;If $uv$ is an edge of $G$, then $u$ and $v$ are said to be &lt;strong&gt;adjacent&lt;/strong&gt; in $G$.&lt;/p&gt;
&lt;p&gt;The number of vertices in $G$ is often called the &lt;strong&gt;order&lt;/strong&gt; of $G$, while the number of edges is its &lt;strong&gt;size&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;A graph with exactly one vertex is called a &lt;strong&gt;trivial graph&lt;/strong&gt;, implying that the order of a &lt;strong&gt;nontrivial graph&lt;/strong&gt; is at least 2.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;labeled graph&lt;/strong&gt; and &lt;strong&gt;unlabeled graph&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A graph $G$ is called a &lt;strong&gt;word graph&lt;/strong&gt; if $G$ is the word graph of some set $S$ of 3-letter words.&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
</feed>
